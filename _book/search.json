[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hands-On Exploratory Data Analytics",
    "section": "",
    "text": "Vorwort",
    "crumbs": [
      "Vorwort"
    ]
  },
  {
    "objectID": "01-background/empirical-research.html",
    "href": "01-background/empirical-research.html",
    "title": "1  Empirische Forschung",
    "section": "",
    "text": "1.1 Datenerhebung\nEmpirische Forschung verwendet strukturierte Beobachtungen (structured observations), um Antworten auf Forschungsfragen zu finden. Wie kommen wir zu diesen Beobachtungen? Mit der passenden Datenerhebungsmethode. Es gibt viele Möglichkeiten, Daten zu erheben. Dazu zählen:\nIn diesem Buch geht es nur indirekt um Datenerhebungsmethoden. Sie sind insofern relevant, als dass wir sie berücksichtigen müssen, wenn wir die Ergebniss analysieren und interpretieren. Es ist ein Unterschied, ob ich ein Phänomen nur beobachtet habe, oder ob ich es in einem kontrollierten Experiment isoliert habe. Es hat Auswirkungen auf meine Ergebnisse, wie viele und welche Menschen ich in einer Umfrage befragt habe. Es ist wichtig zu wissen, wir gut ein Simulationsmodell wir Wirklichkeit abbildet, bevor ich Entscheidungen aus den Daten ableite. Weil die Entstehung der Daten wichtig für die Analyse ist, ist auch die Datenerhebung indirekt Thema dieses Buches.",
    "crumbs": [
      "Hintergründe",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Empirische Forschung</span>"
    ]
  },
  {
    "objectID": "01-background/empirical-research.html#datenerhebung",
    "href": "01-background/empirical-research.html#datenerhebung",
    "title": "1  Empirische Forschung",
    "section": "",
    "text": "Empirical research is any research that uses structured observations from the real world to attempt to answer questions. (Huntington-Klein 2026)\n\n\n\nUmfragen: Ihr könnt Menschen direkt befragen, zum Beispiel mit einem Online-Fragebogen. Das ist eine der häufigsten Methoden, um Daten zu erheben, und sie eignet sich besonders gut, wenn ihr viele Menschen erreichen wollt.\nInterviews: Hierbei sprecht ihr direkt mit Menschen, um tiefere Einblicke zu bekommen.\nBeobachtungen: Manchmal ist es am besten, einfach zu beobachten, was Menschen tun, ohne sie zu stören. Das kann zum Beispiel in einem Café sein, um herauszufinden, wie Menschen ihren Kaffee trinken.\nExperimente: In einem Experiment könnt ihr gezielt Bedingungen verändern, um zu sehen, wie sich das auf die Ergebnisse auswirkt. Das ist besonders nützlich, wenn ihr Ursache-Wirkungs-Beziehungen untersuchen wollt.\nSimulationen: Manchmal könnt ihr auch Computermodelle verwenden, um komplexe Systeme zu simulieren und Daten zu generieren.\nSekundärdatenanalyse: Manchmal ist es nicht nötig, nicht möglich, oder zu teuer, selbst Daten zu erheben. In dem Fall könnt ihr auf Daten zurückgreifen, die bereits erhoben sind.",
    "crumbs": [
      "Hintergründe",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Empirische Forschung</span>"
    ]
  },
  {
    "objectID": "01-background/empirical-research.html#von-daten-zu-wissen",
    "href": "01-background/empirical-research.html#von-daten-zu-wissen",
    "title": "1  Empirische Forschung",
    "section": "1.2 Von Daten zu Wissen",
    "text": "1.2 Von Daten zu Wissen\nDas Ziel dieses Buches ist es, der Leserin oder dem Leser wichtige Werkzeuge der Datenanalyse im Kontext empirischer Forschung näherzubringen. Es soll mit vielen praktischen Anwendungen dazu befähigen, eigene Analysen auf neuen Daten durchzuführen und die richtigen Schlüsse zu ziehen, also Wissen zu erzeugen.\nDer Begriff “Werkzeuge der Datenanalyse” ist abstrakt. Was meinen wir ganz allgemein und im Kontext dieses Buches damit? Ganz allgemein meinen wir damit Methoden oder Techniken, die wir auf Daten anwenden können, um Daten in Wissen zu transformieren.\nWas aber sind Daten? Was sind Informationen? Und was unterscheidet das von Wissen? Abbildung 1.1 stellt die Beziehung zwischen den Begriffen dar.\n\n\n\n\n\n\nAbbildung 1.1: Der Zusammenhang zwischen Daten, Informationen und Wissen.\n\n\n\nDemnach sind Daten zunächst nur aus Symbolen zusammengesetzte Abfolgen, die für sich genommen noch keine Bedeutung haben. Informationen entstehen erst, wenn wir Daten in einen Kontext setzen und sie interpretieren. Wissen entsteht schließlich, wenn wir Informationen verwenden und in Handlungen oder Entscheidungen umsetzen. Und der Begriff Informationen verwenden beschreibt das, was wir in diesem Buch erlernen wollen. Wir lernen, Informationen zu verwenden, um daraus Wissen zu geneieren, um unsere Forschungsfragen zu beantworten. Und mit verwenden meinen wir konkret die Anwendung von Werkzeugen der Datenanalyse.\n\nData, when placed into a relationship with other information, can be synthesized into knowledge. Although knowledge is an element of most human endeavors, it is the central goal of science. In this model, data are the raw materials, much like grain or metal ores. Although data have potential value, they require refinement by aggregating value in combination with other data, just as grains become bread and metal ores become steel. (Hewitt 2019)\n\nDie Tabelle unten zeigt eine Analogie aus der realen Welt, um den Unterschied zwischen Daten, Informationen und Werkzeugen zu verdeutlichen:\n\nAnalogie zu Symbolen, Daten, Information und Wissen.\n\n\n\n\n\n\n\nEbene\nAnalogie\nBeispiel\n\n\n\n\nSymbole\nEisenatome\nZahlen von 0 bis 9 und das Komma\n\n\nDaten\nEine feste Struktur von Eisenatomen, die eine längliche Form mit einer Spitze und einem Kopf bilden.\nEine Abfolge von beliebig vielen Zahlen, gefolgt von einem Komma, gefolgt von zwei Zahlen.\n\n\nInformation\nDie Struktur aus Eisenatomen ist ein Nagel.\nDie Abfolge von Zahlen ist ein Umsatz eines Kassenbons.\n\n\nWissen\nWir hängen etwas am Nagel auf, den wir zuvor in die Wand geschlagen haben.\nDer Jahresumsatz ist im Vergleich zum Vorjahr um 2% gestiegen.\n\n\n\nDie Analyse von Daten ist die notwendige Zutat, die wir brauchen, um aus den erhobenen Daten neues Wissen oder Antworten auf Forschungsfragen zu erzeugen. Dabei gehen wir immer davon aus, dass uns die Daten bereits vorliegen und dass wir außerdem den Kontext der Daten kennen. Die erhobenen Daten sind somit genau genommen Informationen, vorausgesetzt wir kennne die Bedeutung der gemessenen Variablen und den Kontext der Erhebung. Aus diesem Grund ist die Datenerhebung immer relevant für die Datenanalyse, wie eingangs bereits erwähnt.",
    "crumbs": [
      "Hintergründe",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Empirische Forschung</span>"
    ]
  },
  {
    "objectID": "01-background/empirical-research.html#werkzeuge",
    "href": "01-background/empirical-research.html#werkzeuge",
    "title": "1  Empirische Forschung",
    "section": "1.3 Werkzeuge",
    "text": "1.3 Werkzeuge\nEs gibt viele konkrete Werzeuge, mit dem wir unsere Analysen erstellen, ist R in Kombination mit dem Tidyverse. Für manche Aufgaben im Buch verwenden wir auch Python, insbesondere für die Anwendung von Werkzeugen aus dem Bereich des maschinellen Lernens.",
    "crumbs": [
      "Hintergründe",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Empirische Forschung</span>"
    ]
  },
  {
    "objectID": "01-background/empirical-research.html#forschung-oder-praxis",
    "href": "01-background/empirical-research.html#forschung-oder-praxis",
    "title": "1  Empirische Forschung",
    "section": "1.4 Forschung oder Praxis?",
    "text": "1.4 Forschung oder Praxis?\nDie Methoden der empirischen Forschung sind gleichermaßen für die akademische Forschung wie für die Praxis relevant. Schließlich streben auch Unternehmen nach besserem Wissen für ihre Entscheidungen. Ein systematischer, wissenschaftlicher Ansatz, ist der einzige Weg, um die Belastbarkeit des gewonnenen Wissens sicherzustellen. Häufig wird dieser aus pragmatischen Gründen vernachlässigt mit den Argumenten, wissenschaftliche Methoden seien zu aufwändig und damit zu teuer, oder sie seien für eine bestimmte Fragestellung nicht notwendig. Das ist zu kurz gedacht.\nIn der Lehre an der Hochschule Osnabrück vertreten wir die Auffassung, das ein strukturiertes Vorgehen zur Gewinnung von Wissen auch in der Praxis wichtig ist. Um das in diesem Buch zum Ausdruck zu bringen, sind die Projekte bewusst sowohl aus akademischden als auch aus praktischen Kontexten gewählt. Für eine Hochschule angewandter Wissenschaften ist die Schnittstelle zwischen der Forschung und der Praxis besonders im Fokus.\n\n\n\n\nHewitt, Stephen M. 2019. „Data, Information, and Knowledge“. Journal of Histochemistry & Cytochemistry 67 (4): 227–28. https://doi.org/10.1369/0022155419836995.\n\n\nHuntington-Klein, Nick. 2026. The effect: an introduction to research design and causality. Second edition. A Chapman & Hall Book. CRC Press.",
    "crumbs": [
      "Hintergründe",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Empirische Forschung</span>"
    ]
  },
  {
    "objectID": "02-r-basics/ide.html",
    "href": "02-r-basics/ide.html",
    "title": "\n2  Entwicklungsumgebung\n",
    "section": "",
    "text": "2.1 Positron installieren\nZum Programmieren reicht theoretisch ein einfacher Texteditor, denn Code ist am Ende nur Text. In der Praxis wollt ihr aber Unterstützung beim Schreiben und Ausführen von Code und beim Organisieren eurer Dateien. Genau dafür gibt es integrierte Entwicklungsumgebungen, kurz IDEs (das steht für Integrated Development Environment).\nIn diesem Buch arbeiten wir mit Positron. Das ist eine moderne Entwicklungsumgebung für Data Science, die sich in vielen Dingen wie Visual Studio Code anfühlt. Installiert Positron jetzt einmal, dann nutzen wir es direkt für eure ersten Schritte in R.\nLadet Positron in der neuesten Version herunter und installiert es auf eurem Rechner: positron.posit.co/download.html. Startet Positron danach direkt. Wenn es geöffnet ist, geht es mit dem nächsten Abschnitt weiter.",
    "crumbs": [
      "Erste Schritte mit R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Entwicklungsumgebung</span>"
    ]
  },
  {
    "objectID": "02-r-basics/ide.html#projekte-und-ordner",
    "href": "02-r-basics/ide.html#projekte-und-ordner",
    "title": "\n2  Entwicklungsumgebung\n",
    "section": "\n2.2 Projekte und Ordner",
    "text": "2.2 Projekte und Ordner\nIn Positron arbeitet ihr in Projekten. Ein Projekt ist schlicht ein Ordner, in dem alles liegt, was zusammengehört: Skripte, Daten, Abbildungen und Ergebnisse.\nEine einfache Regel hilft euch, sauber zu bleiben: Legt für jedes neue Vorhaben einen eigenen Projektordner an. Viele erstellen dafür einen übergeordneten Ordner wie R-Projekte und legen darin pro Projekt einen Unterordner an. So findet ihr Dinge schneller wieder und mischt Dateien nicht aus Versehen.\n\n\n\n\n\n\nTippSicherung eurer Projekte\n\n\n\nWenn ihr regelmäßig an Projekten arbeitet, lohnt sich eine Strategie für Backups. Eine gute Kombination ist ein Ordner, der automatisch synchronisiert wird, plus Versionsverwaltung für wichtige Projekte. Ich nutze dafür einen Projektordner in OneDrive und lege wichtige Codeprojekte zusätzlich auf GitHub ab.\n\n\n\n\nMeine Projekte liegen in einem gemeinsamen Ordner.",
    "crumbs": [
      "Erste Schritte mit R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Entwicklungsumgebung</span>"
    ]
  },
  {
    "objectID": "02-r-basics/ide.html#projekt-öffnen",
    "href": "02-r-basics/ide.html#projekt-öffnen",
    "title": "\n2  Entwicklungsumgebung\n",
    "section": "\n2.3 Projekt öffnen",
    "text": "2.3 Projekt öffnen\nLegt zuerst euren Projektordner im Datei-Explorer an. Öffnet anschließend diesen Ordner in Positron. Sobald der Ordner geöffnet ist, seht ihr links die Projektstruktur, in der Mitte euren Editor und unten die Konsole.\nAb jetzt gilt: Alles, was zu eurem Projekt gehört, landet in diesem Ordner. Wenn ihr später mit Daten arbeitet, speichert ihr sie ebenfalls dort oder ihr ladet sie aus einer Quelle, die ihr nachvollziehbar dokumentiert.",
    "crumbs": [
      "Erste Schritte mit R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Entwicklungsumgebung</span>"
    ]
  },
  {
    "objectID": "02-r-basics/ide.html#dateien-anlegen",
    "href": "02-r-basics/ide.html#dateien-anlegen",
    "title": "\n2  Entwicklungsumgebung\n",
    "section": "\n2.4 Dateien anlegen",
    "text": "2.4 Dateien anlegen\nIn Positron könnt ihr neue Dateien über das Menü (File &gt; New File) oder über das Kontextmenü im Projektbaum anlegen. Wählt einen sprechenden Namen und achtet auf die Dateiendung, denn daran erkennt Positron, welche Sprache ihr nutzt und welche Funktionen es anbieten soll:\n\n\n.R für R-Skripte\n\n.qmd für Quarto-Dateien\n\n.py für Python-Skripte\n\nFür den Start genügt ein leeres R-Skript. Legt es an, öffnet es im Editor und schreibt diesen Code hinein:\n\nsqrt(64)",
    "crumbs": [
      "Erste Schritte mit R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Entwicklungsumgebung</span>"
    ]
  },
  {
    "objectID": "02-r-basics/ide.html#hilfe-beim-tippen",
    "href": "02-r-basics/ide.html#hilfe-beim-tippen",
    "title": "\n2  Entwicklungsumgebung\n",
    "section": "\n2.5 Hilfe beim Tippen",
    "text": "2.5 Hilfe beim Tippen\nWenn ihr Code schreibt, unterstützt euch Positron mit Autovervollständigung. Tippt einmal sqr und achtet auf das Vorschlagsfenster. Mit den Pfeiltasten könnt ihr einen Vorschlag auswählen und mit der Tab-Taste vervollständigen.\nNach dem Einfügen von sqrt() springt der Cursor in die Klammern. Oft blendet Positron zusätzlich Hinweise zu Funktionsargumenten ein. Bei sqrt() ist das nur x, bei anderen Funktionen sind es mehrere. Das spart Zeit und verhindert Tippfehler.\n\n\n\n\n\n\nTippAutovervollständigung öffnen\n\n\n\nWenn keine Vorschläge erscheinen, öffnet ihr sie manuell mit Strg+Space unter Windows oder mit Cmd+Space unter macOS.",
    "crumbs": [
      "Erste Schritte mit R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Entwicklungsumgebung</span>"
    ]
  },
  {
    "objectID": "02-r-basics/ide.html#speichern",
    "href": "02-r-basics/ide.html#speichern",
    "title": "\n2  Entwicklungsumgebung\n",
    "section": "\n2.6 Speichern",
    "text": "2.6 Speichern\nSobald ihr eine Datei verändert, markiert Positron sie als noch nicht gespeichert. Speichert regelmäßig, zum Beispiel über das Disketten-Symbol oder mit Strg+S unter Windows oder Cmd+S unter macOS. Danach ist der aktuelle Stand sicher in eurem Projektordner.",
    "crumbs": [
      "Erste Schritte mit R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Entwicklungsumgebung</span>"
    ]
  },
  {
    "objectID": "02-r-basics/ide.html#code-ausführen",
    "href": "02-r-basics/ide.html#code-ausführen",
    "title": "\n2  Entwicklungsumgebung\n",
    "section": "\n2.7 Code ausführen",
    "text": "2.7 Code ausführen\nUm einen Befehl auszuführen, setzt den Cursor in die Zeile und nutzt Strg+Enter unter Windows oder Cmd+Enter unter macOS. Das Ergebnis erscheint unten in der Konsole. Probiert es mit sqrt(64) aus. Dort sollte 8 ausgegeben werden.\nFür ganze Skripte gibt es im Editor außerdem ein Start-Symbol. Dahinter stecken typischerweise diese Optionen:\n\n\nSource R File with Echo: Führt das gesamte Skript aus und zeigt den Code in der Konsole.\n\nSource R File: Führt das gesamte Skript aus, ohne den Code in der Konsole zu zeigen.\n\nExecute Code: Führt nur den aktuellen Befehl aus, wie Strg+Enter oder Cmd+Enter.\n\n\n\n\n\n\n\nTippDateien und Ordner organisieren\n\n\n\nIm Projektbaum könnt ihr Dateien und Ordner anlegen, umbenennen, verschieben und löschen. Wenn ihr einmal ein Projekt sauber angelegt habt, müsst ihr Positron dafür meist nicht mehr verlassen.",
    "crumbs": [
      "Erste Schritte mit R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Entwicklungsumgebung</span>"
    ]
  },
  {
    "objectID": "02-r-basics/programming-with-r.html",
    "href": "02-r-basics/programming-with-r.html",
    "title": "3  Programmieren mit R",
    "section": "",
    "text": "Hinweis auf das Buch Grolemund (2014)\nGrundlegende Konzepte des Programmierens in R\n\nKontrollstrukturen\nSchleifen\nFunktionen\nFehlerbehandlung\n\nWas sonst? Bitte schreibe ein vollständiges Kapitel\nZu Ende hin: Fokus auf praktische Beispiele im Zusammenhang mit Datenanalyse und dem Tidyverse\nReferenz auf das Kapitel Datenrepräsentation wo sinnvoll für die Frage, wie man Daten in R abbildet\n\n\n\n\n\nGrolemund, Garrett. 2014. Hands-on programming with R. First edition. O’Reilly.",
    "crumbs": [
      "Erste Schritte mit R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Programmieren mit R</span>"
    ]
  },
  {
    "objectID": "02-r-basics/data-representation.html",
    "href": "02-r-basics/data-representation.html",
    "title": "4  Datenrepräsentation",
    "section": "",
    "text": "4.1 Skalare Werte\nBevor ihr Daten analysieren könnt, müsst ihr verstehen, wie R Daten überhaupt speichert und organisiert. Denn R bietet euch eine ganze Reihe von Datenstrukturen, und jede hat ihren eigenen Zweck. Stellt euch vor, ihr zieht in eine neue Wohnung und habt einen Haufen Sachen. Manche kommen in Schubladen, manche in Regale, manche in Ordner. Genauso ist es in R: Je nachdem, was ihr mit euren Daten vorhabt, braucht ihr die passende Struktur.\nIn diesem Kapitel starten wir ganz unten, bei einzelnen Werten, und arbeiten uns Schritt für Schritt nach oben. Am Ende steht der Tibble, die Datenstruktur, die euch im Rest des Buches überall begegnen wird.\nWas passiert, wenn ihr R einfach eine Zahl gebt?\n42\n\n[1] 42\nR gibt die Zahl zurück. Aber was ist das eigentlich? In vielen Programmiersprachen nennt man einen einzelnen Wert einen Skalar. Das ist der einfachste Baustein, mit dem ihr arbeiten könnt. In R ist ein Skalar intern ein Vektor der Länge 1, aber dazu kommen wir gleich. Erst einmal reicht es zu wissen: Ein einzelner Wert ist das Fundament.\nIhr könnt skalare Werte in Variablen speichern, um sie später wiederzuverwenden:\nage &lt;- 23\nname &lt;- \"Anna\"\nDer Pfeil &lt;- ist der Zuweisungsoperator in R. Er legt den Wert rechts unter dem Namen links ab. Wenn ihr danach den Variablennamen eingebt, bekommt ihr den Wert zurück:\nage\n\n[1] 23\n\nname\n\n[1] \"Anna\"\nAber nicht jeder Wert ist gleich. Eine Zahl ist etwas anderes als ein Text, und das bringt uns zum nächsten Thema.",
    "crumbs": [
      "Erste Schritte mit R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Datenrepräsentation</span>"
    ]
  },
  {
    "objectID": "02-r-basics/data-representation.html#datentypen",
    "href": "02-r-basics/data-representation.html#datentypen",
    "title": "4  Datenrepräsentation",
    "section": "\n4.2 Datentypen",
    "text": "4.2 Datentypen\nWarum ist es wichtig, ob ein Wert eine Zahl oder ein Text ist? Weil R mit verschiedenen Typen unterschiedlich umgeht. Ihr könnt zwei Zahlen addieren, aber ihr könnt nicht einen Text und eine Zahl addieren. Wenn R die Typen durcheinanderbringt, bekommt ihr entweder einen Fehler oder ein unerwartetes Ergebnis.\nGrundlegende Datentypen\nR kennt vier grundlegende Datentypen, die euch im Alltag ständig begegnen:\n\n\nDatentyp\nBeschreibung\nBeispiel\n\n\n\n\nnumeric / double\n\nDezimalzahlen\n\n3.14, 42.0\n\n\n\ninteger\nGanzzahlen\n\n1L, 100L\n\n\n\ncharacter\nText (Zeichenketten)\n\n\"Hallo\", \"2024\"\n\n\n\nlogical\nWahrheitswerte\n\nTRUE, FALSE\n\n\n\n\nMit der Funktion class() könnt ihr den Typ eines Werts herausfinden:\n\nclass(3.14)\n\n[1] \"numeric\"\n\nclass(1L)\n\n[1] \"integer\"\n\nclass(\"Hallo\")\n\n[1] \"character\"\n\nclass(TRUE)\n\n[1] \"logical\"\n\n\nBeachtet das L hinter der 1. Ohne dieses L behandelt R jede Zahl als numeric, also als Dezimalzahl. Erst das L sagt R: Das ist eine Ganzzahl. In der Praxis spielt der Unterschied zwischen numeric und integer selten eine große Rolle, aber es ist gut zu wissen, dass es ihn gibt.\nTypumwandlung\nWas passiert, wenn ihr versucht, einen Text wie \"42\" als Zahl zu verwenden?\n\n\"42\" + 1\n\nError in `\"42\" + 1`:\n! non-numeric argument to binary operator\n\n\nR beschwert sich, weil es einen Text und eine Zahl nicht addieren kann. Ihr müsst den Typ erst umwandeln:\n\nas.numeric(\"42\") + 1\n\n[1] 43\n\n\nR bietet für jeden Datentyp eine passende Umwandlungsfunktion:\n\n\nFunktion\nWandelt um in\n\n\n\nas.numeric()\nDezimalzahl\n\n\nas.integer()\nGanzzahl\n\n\nas.character()\nText\n\n\nas.logical()\nWahrheitswert\n\n\n\nUmwandlungen funktionieren nicht immer. Wenn ihr versucht, den Text \"Hallo\" in eine Zahl umzuwandeln, gibt R eine Warnung aus und liefert NA, also einen fehlenden Wert:\n\nas.numeric(\"Hallo\")\n\nWarning: NAs introduced by coercion\n\n\n[1] NA\n\n\n\n\n\n\n\n\nTippFehlende Werte: NA\n\n\n\nNA steht für Not Available und bedeutet, dass ein Wert fehlt. Fehlende Werte begegnen euch in der Datenanalyse ständig. R markiert damit Stellen, an denen keine Information vorhanden ist. Merkt euch NA gut, denn ihr werdet es noch oft sehen.\n\n\nDatum und Uhrzeit\nNeben den vier Grundtypen gibt es noch einen Typ, der euch in der Datenanalyse besonders häufig begegnet: Datums- und Zeitwerte. R speichert Datumswerte intern als Zahl, die die Anzahl der Tage seit dem 1. Januar 1970 angibt, zeigt sie euch aber in einem lesbaren Format an:\n\ntoday &lt;- Sys.Date()\ntoday\n\n[1] \"2026-02-26\"\n\nclass(today)\n\n[1] \"Date\"\n\n\nFür die Arbeit mit Datumswerten gibt es im Tidyverse das Paket lubridate, das euch viele hilfreiche Funktionen bereitstellt. Darauf gehen wir in späteren Kapiteln genauer ein.",
    "crumbs": [
      "Erste Schritte mit R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Datenrepräsentation</span>"
    ]
  },
  {
    "objectID": "02-r-basics/data-representation.html#vektoren",
    "href": "02-r-basics/data-representation.html#vektoren",
    "title": "4  Datenrepräsentation",
    "section": "\n4.3 Vektoren",
    "text": "4.3 Vektoren\nWas aber, wenn ihr nicht nur eine einzelne Zahl speichern wollt, sondern gleich fünf Prüfungsnoten? Oder die Namen aller Teilnehmenden eines Kurses?\nDafür gibt es den Vektor. Ein Vektor ist eine geordnete Sammlung von Werten desselben Typs. Ihr erstellt ihn mit der Funktion c(), was für combine steht:\n\ngrades &lt;- c(1.3, 2.0, 1.7, 3.0, 2.3)\ngrades\n\n[1] 1.3 2.0 1.7 3.0 2.3\n\n\nVektoren sind so grundlegend für R, dass sogar ein einzelner Wert wie 42 im Hintergrund ein Vektor der Länge 1 ist. Das [1], das R euch bei der Ausgabe immer anzeigt, ist der Index des ersten Elements in diesem Vektor.\nZugriff auf Elemente\nWie greift ihr auf ein bestimmtes Element eines Vektors zu? Über eckige Klammern und die Position:\n\ngrades[1]\n\n[1] 1.3\n\ngrades[3]\n\n[1] 1.7\n\n\nIhr könnt auch mehrere Positionen auf einmal angeben:\n\ngrades[c(1, 3, 5)]\n\n[1] 1.3 1.7 2.3\n\n\nOder einen Bereich:\n\ngrades[2:4]\n\n[1] 2.0 1.7 3.0\n\n\nRechnen mit Vektoren\nDas Besondere an R ist, dass Berechnungen automatisch auf alle Elemente eines Vektors angewendet werden. Dieses Prinzip nennt man Vektorisierung:\n\ngrades * 100\n\n[1] 130 200 170 300 230\n\n\nDas funktioniert auch mit zwei Vektoren derselben Länge:\n\nscores &lt;- c(90, 75, 85, 60, 70)\nweights &lt;- c(0.3, 0.2, 0.2, 0.15, 0.15)\nscores * weights\n\n[1] 27.0 15.0 17.0  9.0 10.5\n\n\nJedes Element des ersten Vektors wird mit dem entsprechenden Element des zweiten Vektors multipliziert. Das ist ein mächtiges Prinzip, das euch viele Schleifen erspart.\nAbbildung: Zwei Vektoren liegen nebeneinander, jeweils mit fünf Elementen. Zwischen den Vektoren steht ein Multiplikationszeichen. Pfeile verbinden jeweils das erste Element des linken Vektors mit dem ersten des rechten, das zweite mit dem zweiten, und so weiter. Rechts daneben steht der Ergebnisvektor mit den fünf Produkten. Die Beschriftung lautet: „Vektorisierung: Elementweise Verknüpfung”.\nNützliche Funktionen für Vektoren\nR bringt viele eingebaute Funktionen mit, die mit Vektoren arbeiten:\n\nlength(grades)\n\n[1] 5\n\nsum(grades)\n\n[1] 10.3\n\nmean(grades)\n\n[1] 2.06\n\nmin(grades)\n\n[1] 1.3\n\nmax(grades)\n\n[1] 3\n\nsort(grades)\n\n[1] 1.3 1.7 2.0 2.3 3.0\n\n\nGleicher Datentyp für alle\nEine wichtige Regel bei Vektoren ist: Alle Elemente müssen denselben Typ haben. Was passiert, wenn ihr einen Text und eine Zahl in denselben Vektor packt?\n\nmix &lt;- c(1, \"two\", 3)\nmix\n\n[1] \"1\"   \"two\" \"3\"  \n\nclass(mix)\n\n[1] \"character\"\n\n\nR wandelt stillschweigend alles in Text um, weil Text der allgemeinste Typ ist. Aus den Zahlen 1 und 3 werden die Texte \"1\" und \"3\". Das kann zu überraschenden Fehlern führen, wenn ihr später mit diesen Werten rechnen wollt.\n\n\n\n\n\n\nTippAutomatische Typumwandlung\n\n\n\nWenn R verschiedene Typen in einem Vektor findet, wandelt es alle Werte in den allgemeinsten Typ um. Die Reihenfolge ist: logical → integer → numeric → character. Das nennt man Coercion. Achtet darauf, nur gleichartige Werte in einen Vektor zu packen.",
    "crumbs": [
      "Erste Schritte mit R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Datenrepräsentation</span>"
    ]
  },
  {
    "objectID": "02-r-basics/data-representation.html#faktoren",
    "href": "02-r-basics/data-representation.html#faktoren",
    "title": "4  Datenrepräsentation",
    "section": "\n4.4 Faktoren",
    "text": "4.4 Faktoren\nManche Werte sehen zwar aus wie Text, sind aber eigentlich Kategorien. Denkt an Antworten in einer Umfrage: „stimme zu”, „neutral”, „stimme nicht zu”. Oder an Schulnoten. Es gibt nur bestimmte erlaubte Werte, und manchmal haben sie eine Reihenfolge. Wir sprechen auch von kategorialen Daten.\nGenau dafür gibt es Faktoren. Ein Faktor ist ein Vektor, bei dem R weiß, welche Werte überhaupt möglich sind (die sogenannten Levels oder Kategorien) und in welcher Reihenfolge sie stehen.\nEinen Faktor erstellen\n\nsatisfaction &lt;- factor(\n  c(\"satisfied\", \"neutral\", \"dissatisfied\", \"satisfied\", \"neutral\"),\n  levels = c(\"dissatisfied\", \"neutral\", \"satisfied\")\n)\nsatisfaction\n\n[1] satisfied    neutral      dissatisfied satisfied    neutral     \nLevels: dissatisfied neutral satisfied\n\n\nBeachtet die Zeile Levels: in der Ausgabe. Sie zeigt die möglichen Werte und ihre Reihenfolge. Das ist wichtig, weil R diese Reihenfolge zum Beispiel bei Diagrammen verwendet, die wir später mit ggplot2 erstellen.\nWarum nicht einfach Text?\nWenn ihr Kategorien als einfachen Text speichert, hat R keine Ahnung, dass es nur bestimmte erlaubte Werte gibt. Faktoren geben euch drei Vorteile:\n\n\nValidierung: R warnt euch, wenn ein Wert auftaucht, der kein definiertes Level ist.\n\nReihenfolge: Ihr kontrolliert, in welcher Reihenfolge Kategorien in Grafiken und Tabellen erscheinen.\n\nEffizienz: Intern speichert R Faktoren als Ganzzahlen, was bei großen Datensätzen Speicher spart.\n\nPrüfen wir Punkt 1: Was passiert, wenn ein Wert kein definiertes Level ist?\n\nrating &lt;- factor(\n  c(\"good\", \"medium\", \"super\"),\n  levels = c(\"bad\", \"medium\", \"good\")\n)\nrating\n\n[1] good   medium &lt;NA&gt;  \nLevels: bad medium good\n\n\nDer Wert \"super\" ist kein definiertes Level. R ersetzt ihn daher durch NA. Das ist eine nützliche Schutzfunktion, denn in der Analyse merkt ihr sofort, wenn unerwartete Werte auftauchen.\nGeordnete Faktoren\nManchmal ist die Reihenfolge der Kategorien inhaltlich wichtig. Dann könnt ihr einen geordneten Faktor erstellen. Wir sprechen auch von einer ordinalen Variable:\n\nrating_ordered &lt;- factor(\n  c(\"good\", \"medium\", \"bad\", \"good\"),\n  levels = c(\"bad\", \"medium\", \"good\"),\n  ordered = TRUE\n)\nrating_ordered\n\n[1] good   medium bad    good  \nLevels: bad &lt; medium &lt; good\n\n\nBei einem geordneten Faktor könnt ihr Vergleiche mit &lt; und &gt; anstellen:\n\nrating_ordered &gt; \"medium\"\n\n[1]  TRUE FALSE FALSE  TRUE\n\n\nIn der Praxis begegnen euch Faktoren vor allem bei der Datenvisualisierung und bei statistischen Modellen. Das Tidyverse bietet mit dem Paket forcats viele hilfreiche Funktionen für die Arbeit mit Faktoren.",
    "crumbs": [
      "Erste Schritte mit R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Datenrepräsentation</span>"
    ]
  },
  {
    "objectID": "02-r-basics/data-representation.html#matrizen",
    "href": "02-r-basics/data-representation.html#matrizen",
    "title": "4  Datenrepräsentation",
    "section": "\n4.5 Matrizen",
    "text": "4.5 Matrizen\nVektoren sind eindimensional. Aber was, wenn eure Daten zwei Dimensionen haben, also Zeilen und Spalten? Dann kommt die Matrix ins Spiel.\nEine Matrix ist im Grunde ein Vektor, der in Zeilen und Spalten angeordnet ist. Wie beim Vektor gilt: Alle Elemente müssen denselben Typ haben, typischerweise Zahlen.\n\nm &lt;- matrix(\n  c(85, 72, 91, 68, 79, 95),\n  nrow = 2,\n  ncol = 3\n)\nm\n\n     [,1] [,2] [,3]\n[1,]   85   91   79\n[2,]   72   68   95\n\n\nIhr seht, dass R die Werte spaltenweise auffüllt. Das ist die Voreinstellung. Wenn ihr die Werte zeilenweise einfüllen wollt, setzt ihr byrow = TRUE:\n\nm2 &lt;- matrix(\n  c(85, 72, 91, 68, 79, 95),\n  nrow = 2,\n  ncol = 3,\n  byrow = TRUE\n)\nm2\n\n     [,1] [,2] [,3]\n[1,]   85   72   91\n[2,]   68   79   95\n\n\nZeilen und Spalten benennen\nUm eine Matrix lesbarer zu machen, könnt ihr Zeilen und Spalten benennen:\n\nrownames(m2) &lt;- c(\"Exam 1\", \"Exam 2\")\ncolnames(m2) &lt;- c(\"Math\", \"Statistics\", \"Programming\")\nm2\n\n       Math Statistics Programming\nExam 1   85         72          91\nExam 2   68         79          95\n\n\nZugriff auf Elemente\nDer Zugriff funktioniert über [Zeile, Spalte]:\n\nm2[1, 2]\n\n[1] 72\n\nm2[\"Exam 1\", \"Statistics\"]\n\n[1] 72\n\n\nEine ganze Zeile oder Spalte bekommt ihr, indem ihr die andere Dimension leer lasst:\n\nm2[1, ]\n\n       Math  Statistics Programming \n         85          72          91 \n\nm2[, \"Math\"]\n\nExam 1 Exam 2 \n    85     68 \n\n\nRechnen mit Matrizen\nGenau wie bei Vektoren könnt ihr mit Matrizen rechnen. Eine einfache Multiplikation mit einem Skalar funktioniert elementweise:\n\nm2 / 100\n\n       Math Statistics Programming\nExam 1 0.85       0.72        0.91\nExam 2 0.68       0.79        0.95\n\n\nMatrizen spielen in der Statistik und im maschinellen Lernen eine zentrale Rolle, zum Beispiel bei der linearen Algebra. Für die explorative Datenanalyse braucht ihr sie eher selten direkt, weil Data Frames und Tibbles flexibler sind. Aber es ist gut zu wissen, dass es sie gibt.\nAbbildung: Eine Matrix als Gitter dargestellt, mit beschrifteten Zeilen (Exam 1, Exam 2) und Spalten (Math, Statistics, Programming). Daneben ein Vektor als einzelne Spalte. Ein Pfeil zeigt, dass die Matrix aus mehreren gleichartigen Vektoren zusammengesetzt ist. Untertitel: „Eine Matrix ist ein zweidimensionaler Vektor.”",
    "crumbs": [
      "Erste Schritte mit R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Datenrepräsentation</span>"
    ]
  },
  {
    "objectID": "02-r-basics/data-representation.html#data-frames",
    "href": "02-r-basics/data-representation.html#data-frames",
    "title": "4  Datenrepräsentation",
    "section": "\n4.6 Data Frames",
    "text": "4.6 Data Frames\nVektoren können nur einen Typ enthalten, Matrizen genauso. In der Praxis sehen eure Daten aber anders aus: Eine Spalte enthält Namen (Text), eine andere Alter (Zahlen), eine dritte, ob eine Zustimmung vorliegt (Wahrheitswert). Ihr braucht also eine Struktur, die verschiedene Typen in verschiedenen Spalten erlaubt.\nGenau das ist ein Data Frame. Ein Data Frame ist die klassische tabellarische Datenstruktur in R. Jede Spalte ist ein Vektor, und die Spalten dürfen unterschiedliche Typen haben.\n\ndf &lt;- data.frame(\n  name = c(\"Anna\", \"Ben\", \"Cleo\"),\n  age = c(23, 21, 25),\n  passed = c(TRUE, FALSE, TRUE)\n)\ndf\n\n  name age passed\n1 Anna  23   TRUE\n2  Ben  21  FALSE\n3 Cleo  25   TRUE\n\n\nDas sieht schon sehr nach einer Tabelle aus. Jede Spalte hat einen Namen, und die Zeilen repräsentieren einzelne Beobachtungen. Dieses Prinzip heißt Tidy Data: Jede Zeile ist eine Beobachtung, jede Spalte ist eine Variable.\nZugriff auf Spalten\nAuf eine einzelne Spalte greift ihr mit dem Dollar-Zeichen zu:\n\ndf$name\n\n[1] \"Anna\" \"Ben\"  \"Cleo\"\n\ndf$age\n\n[1] 23 21 25\n\n\nDas Ergebnis ist jeweils ein Vektor. Ihr könnt damit genauso arbeiten wie mit jedem anderen Vektor:\n\nmean(df$age)\n\n[1] 23\n\n\nDas Problem mit Data Frames\nData Frames funktionieren zuverlässig, haben aber ein paar Eigenheiten, die im Alltag nerven können:\n\ndf\n\n  name age passed\n1 Anna  23   TRUE\n2  Ben  21  FALSE\n3 Cleo  25   TRUE\n\n\nSchaut euch die Ausgabe genau an. Wenn ein Data Frame viele Zeilen hat, zeigt R alle an. Bei einem Datensatz mit zehntausenden Beobachtungen überflutet das eure Konsole. Außerdem wandelt data.frame() Textspalten manchmal automatisch in Faktoren um, was zu unerwarteten Ergebnissen führen kann.\nEs gibt also Raum für Verbesserungen. Und genau hier kommen Tibbles ins Spiel.",
    "crumbs": [
      "Erste Schritte mit R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Datenrepräsentation</span>"
    ]
  },
  {
    "objectID": "02-r-basics/data-representation.html#tibbles",
    "href": "02-r-basics/data-representation.html#tibbles",
    "title": "4  Datenrepräsentation",
    "section": "\n4.7 Tibbles",
    "text": "4.7 Tibbles\nTibbles sind die moderne Version des Data Frames. Sie kommen aus dem Tidyverse und sind so gebaut, dass sie im Arbeitsalltag angenehmer und sicherer sind. Alles, was ein Data Frame kann, kann auch ein Tibble. Aber ein Tibble macht ein paar Dinge cleverer.\nWas ist anders?\nSchauen wir uns den Unterschied direkt an. Wir laden den Tweets-Datensatz als Tibble:\n\ntweets\n\n# A tibble: 58,421 × 22\n   id             screen_name text  retweet_count favorite_count is_quote_status\n   &lt;chr&gt;          &lt;chr&gt;       &lt;chr&gt;         &lt;dbl&gt;          &lt;dbl&gt; &lt;lgl&gt;          \n 1 1642251945732… cem_oezdem… \"RT …            23              0 FALSE          \n 2 1642416819003… W_Schmidt_  \"RT …         10659              0 FALSE          \n 3 1642082629796… lisapaus    \"@Ha…             1              3 FALSE          \n 4 1642090111700… lisapaus    \"@an…             1             11 FALSE          \n 5 1642532741366… Wissing     \"\\U0…             6             25 FALSE          \n 6 1642532736740… Wissing     \"Wir…             9             93 FALSE          \n 7 1642463874896… Wissing     \"Wes…            15            154 FALSE          \n 8 1642411368216… c_lindner   \"202…            56            448 TRUE           \n 9 1643126817555… lisapaus    \"RT …            29              0 FALSE          \n10 1643018993815… lisapaus    \"@SB…             1              1 FALSE          \n# ℹ 58,411 more rows\n# ℹ 16 more variables: is_retweet &lt;lgl&gt;, retweeted_status_id &lt;chr&gt;,\n#   retweeted_user &lt;chr&gt;, lang &lt;chr&gt;, hashtags &lt;list&gt;, urls &lt;list&gt;,\n#   user_mentions &lt;list&gt;, photos &lt;list&gt;, source &lt;chr&gt;, insert_timestamp &lt;chr&gt;,\n#   created_at &lt;dttm&gt;, quote_count &lt;dbl&gt;, reply_count &lt;dbl&gt;,\n#   in_reply_to_screen_name &lt;chr&gt;, in_reply_to_status_id &lt;chr&gt;,\n#   quoted_status_id &lt;chr&gt;\n\n\nWas fällt euch auf? Der Tibble zeigt euch automatisch nur die ersten zehn Zeilen und passt die Spalten an die Breite eurer Konsole an. Außerdem seht ihr unter jedem Spaltennamen den Datentyp: &lt;chr&gt; für Text, &lt;dbl&gt; für Dezimalzahlen, &lt;lgl&gt; für Wahrheitswerte, &lt;dttm&gt; für Zeitstempel.\nVergleichen wir das mit einem Data Frame. Wenn wir den Tibble in einen klassischen Data Frame umwandeln und ausgeben, sehen wir den Unterschied sofort:\n\ntweets_df &lt;- as.data.frame(tweets)\n\nWürden wir tweets_df jetzt ausgeben, würde R versuchen, alle Zeilen und Spalten in der Konsole darzustellen. Bei einem Datensatz mit 58.421 Zeilen wäre das eine ziemliche Flut.\nEinen Tibble erstellen\nIhr könnt einen Tibble genau wie einen Data Frame von Hand erstellen. Statt data.frame() verwendet ihr tibble():\n\nstudents &lt;- tibble(\n  name = c(\"Anna\", \"Ben\", \"Cleo\", \"David\"),\n  age = c(23, 21, 25, 22),\n  major = c(\"Business\", \"CS\", \"Business\", \"Media\"),\n  passed = c(TRUE, FALSE, TRUE, TRUE)\n)\nstudents\n\n# A tibble: 4 × 4\n  name    age major    passed\n  &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;lgl&gt; \n1 Anna     23 Business TRUE  \n2 Ben      21 CS       FALSE \n3 Cleo     25 Business TRUE  \n4 David    22 Media    TRUE  \n\n\nBeachtet, dass der Tibble im Gegensatz zum Data Frame den Datentyp unter jedem Spaltennamen anzeigt. Das ist eine kleine, aber wertvolle Hilfe, weil ihr sofort seht, womit ihr arbeitet.\nDie Vorteile im Überblick\nFassen wir die Unterschiede zusammen:\n\n\n\n\n\n\n\nEigenschaft\ndata.frame()\ntibble()\n\n\n\nAusgabe\nZeigt alle Zeilen\nZeigt nur die ersten 10 Zeilen\n\n\nDatentypen anzeigen\nNein\nJa, unter jedem Spaltennamen\n\n\nText zu Faktor\nManchmal automatisch\nNie automatisch\n\n\nPartielle Spaltennamen\nErlaubt (df$n findet name)\nNicht erlaubt, verhindert Fehler\n\n\nSubsetting\nGibt manchmal Vektor zurück\nGibt immer Tibble zurück\n\n\n\nDer letzte Punkt ist subtil, aber wichtig. Wenn ihr bei einem klassischen Data Frame eine einzelne Spalte mit eckigen Klammern auswählt, gibt R manchmal einen Vektor statt eines Data Frames zurück. Das kann zu schwer auffindbaren Fehlern führen. Tibbles geben in diesem Fall immer einen Tibble zurück, was das Verhalten berechenbarer macht.\nDen Tweets-Datensatz erkunden\nLasst uns den Tweets-Datensatz etwas genauer anschauen. Mit glimpse() bekommt ihr einen kompakten Überblick über alle Spalten:\n\ntweets |&gt;\n  glimpse()\n\nRows: 58,421\nColumns: 22\n$ id                      &lt;chr&gt; \"1642251945732653057\", \"1642416819003707397\", …\n$ screen_name             &lt;chr&gt; \"cem_oezdemir\", \"W_Schmidt_\", \"lisapaus\", \"lis…\n$ text                    &lt;chr&gt; \"RT @BriHasselmann: Endlich! Wir sind drangebl…\n$ retweet_count           &lt;dbl&gt; 23, 10659, 1, 1, 6, 9, 15, 56, 29, 1, 1, 1, 10…\n$ favorite_count          &lt;dbl&gt; 0, 0, 3, 11, 25, 93, 154, 448, 0, 1, 2, 2, 58,…\n$ is_quote_status         &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n$ is_retweet              &lt;lgl&gt; TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE,…\n$ retweeted_status_id     &lt;chr&gt; \"1642158717113081856\", \"1641976869460275201\", …\n$ retweeted_user          &lt;chr&gt; \"BriHasselmann\", \"aakashg0\", NA, NA, NA, NA, N…\n$ lang                    &lt;chr&gt; \"de\", \"en\", \"de\", \"de\", \"qme\", \"de\", \"de\", \"de…\n$ hashtags                &lt;list&gt; &lt;\"Tierhaltungskennzeichnung\", \"Wettbewerb\"&gt;, …\n$ urls                    &lt;list&gt; [&lt;data.frame[0 x 0]&gt;], [&lt;data.frame[0 x 0]&gt;],…\n$ user_mentions           &lt;list&gt; \"BriHasselmann\", \"aakashg0\", &lt;\"HassoSuliak\", …\n$ photos                  &lt;list&gt; [&lt;data.frame[0 x 0]&gt;], [&lt;data.frame[0 x 0]&gt;],…\n$ source                  &lt;chr&gt; \"&lt;a href=\\\"http://twitter.com/download/iphone\\…\n$ insert_timestamp        &lt;chr&gt; \"2023-04-02 03:00:04.749 UTC\", \"2023-04-02 07:…\n$ created_at              &lt;dttm&gt; 2023-04-01 19:45:50, 2023-04-02 06:40:58, 202…\n$ quote_count             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reply_count             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ in_reply_to_screen_name &lt;chr&gt; NA, NA, \"HassoSuliak\", \"andiewoerle\", \"Wissing…\n$ in_reply_to_status_id   &lt;chr&gt; NA, NA, \"1642059841169502210\", \"16420886499603…\n$ quoted_status_id        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, \"16424095440462397…\n\n\nIhr seht hier alle Variablen mit ihrem Typ und den ersten Werten. Das ist meistens der erste Befehl, den ihr nach dem Laden eines Datensatzes ausführt, um euch zu orientieren.\nWie viele Zeilen und Spalten hat der Datensatz?\n\nnrow(tweets)\n\n[1] 58421\n\nncol(tweets)\n\n[1] 22\n\n\nUnd welche Spaltennamen gibt es?\n\nnames(tweets)\n\n [1] \"id\"                      \"screen_name\"            \n [3] \"text\"                    \"retweet_count\"          \n [5] \"favorite_count\"          \"is_quote_status\"        \n [7] \"is_retweet\"              \"retweeted_status_id\"    \n [9] \"retweeted_user\"          \"lang\"                   \n[11] \"hashtags\"                \"urls\"                   \n[13] \"user_mentions\"           \"photos\"                 \n[15] \"source\"                  \"insert_timestamp\"       \n[17] \"created_at\"              \"quote_count\"            \n[19] \"reply_count\"             \"in_reply_to_screen_name\"\n[21] \"in_reply_to_status_id\"   \"quoted_status_id\"       \n\n\nAll diese Informationen bekommt ihr auch, indem ihr einfach den Tibble ausgebt. Aber glimpse(), nrow() und names() sind nützlich, wenn ihr gezielt eine bestimmte Information braucht, zum Beispiel in einem Skript.\nUmwandlung zwischen Data Frame und Tibble\nManchmal bekommt ihr von einer Funktion einen klassischen Data Frame zurück und wollt ihn in einen Tibble umwandeln. Das geht mit as_tibble():\n\ndf &lt;- data.frame(\n  x = 1:3,\n  y = c(\"a\", \"b\", \"c\")\n)\n\ndf_tibble &lt;- as_tibble(df)\ndf_tibble\n\n# A tibble: 3 × 2\n      x y    \n  &lt;int&gt; &lt;chr&gt;\n1     1 a    \n2     2 b    \n3     3 c    \n\n\nUnd umgekehrt, wenn eine Funktion einen Data Frame erwartet, nutzt ihr as.data.frame(). In der Praxis braucht ihr das aber selten, weil Tibbles überall dort funktionieren, wo Data Frames erwartet werden.\nIn der Praxis werden wir die gezeigten Datenstrukturen nicht per Hand erzeugen, sondern aus Dateien laden. Und für die Arbeit in diesem Buch werden wir zu 99% mit Tibbles arbeiten, die standardmäßige Darstellung von Daten im Tidyverse. An manchen Stellen verlassen wir jedoch da Tidyverse und brauchen dann auch das Verständnis der anderen Datenstrukturen, speziell Vektoren udn Skalarwerte.\nWie wir Tibbles aus Dateien laden und was wir dabei beachten müssen, zeigen wir im nächsten Kapitel 5.",
    "crumbs": [
      "Erste Schritte mit R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Datenrepräsentation</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/loading-data.html",
    "href": "03-data-transformation/loading-data.html",
    "title": "5  Daten laden",
    "section": "",
    "text": "5.1 Dateiformate\nJeder Analyseprozess beginnt mit dem Laden der Daten (s. Abbildung 5.1). In diesem Kapitel schauen wir uns an, wie ihr die gängigsten Datenformate in R laden könnt. Wir starten mit textbasierten Formaten wie CSV und JSON, gehen dann über zu binären Formaten wie Excel und RDS und werfen zuletzt einen Blick auf das Laden von Daten direkt aus Google Sheets.\nZu wissen, wie man Daten aus verschiedenen Quellen importiert, ist grundlegend für jede Analyseaufgabe. In der Realität liegen Daten selten im perfekten R-Format vor, sondern verteilen sich über verschiedene Systeme, Dateitypen und Cloud-Dienste. Wer diese Formate souverän in R überführen kann, spart sich von Anfang an viel Zeit und frustrierende manuelle Zwischenschritte.\nDie folgende Tabelle zeigt die Funktionen, die wir in diesem Abschnitt kennenlernen.\nZunächst beschäftigen wir uns mit den grundlegenden Dateiformaten, aus denen wir Daten laden können.\nDaten im Computer speichern wir üblicherweise in Dateien. Ein Datensatz kann dabei aus einer oder mehreren Dateien bestehen. Auf der untersten Ebene enthält eine Datei Daten in Form von Nullen und Einsen, denn der Computer arbeitet mit Bits und dem Binärsystem.\nIn der Arbeit mit Daten unterscheiden wir zwei grundlegende Ideen, wie wir einen Datensatz als Datei speichern:\nWas ist der Unterschied? Eine Textdatei speichert die Daten in einem Format, das für Menschen lesbar ist. Die Daten werden als Zeichenfolge gespeichert, die über ein gängiges Kodierungssystem wie UTF-8 in lesbare Zeichen übersetzt werden kann. Beispiele für textbasierte Formate sind CSV (Comma-Separated Values), TSV (Tab-Separated Values) und JSON (JavaScript Object Notation). Ihr könnt solche Dateien in jedem beliebigen Texteditor öffnen und lesen. Das ist der große Vorteil: Sie sind einfach zu verstehen und zu bearbeiten.\nBinäre Formate kodieren die Daten nicht als Text, sondern in einem Format, das für den Computer effizienter zu lesen und zu schreiben ist. Beispiele sind Excel-Dateien (.xlsx), RDS-Dateien (.rds) und Parquet-Dateien (.parquet). Binäre Formate sind in der Regel schneller zu lesen und benötigen weniger Speicherplatz. Allerdings sind sie nicht direkt von Menschen lesbar und erfordern spezielle Software.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten laden</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/loading-data.html#sec-loading-data-dateiformate",
    "href": "03-data-transformation/loading-data.html#sec-loading-data-dateiformate",
    "title": "5  Daten laden",
    "section": "",
    "text": "Als Textdatei\nAls Binärdatei\n\n\n\nDateiformate für Daten sind entweder textbasierte Formate oder proprietäre binäre Formate.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten laden</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/loading-data.html#sec-loading-data-csv",
    "href": "03-data-transformation/loading-data.html#sec-loading-data-csv",
    "title": "5  Daten laden",
    "section": "\n5.2 CSV-Dateien",
    "text": "5.2 CSV-Dateien\nEines der gängigsten Datenformate ist CSV. CSV steht für “Comma-Separated Values” und ist ein einfaches textbasiertes Format, das Daten in tabellarischer Form speichert. Jede Zeile in einer CSV-Datei entspricht einer Zeile in der Tabelle, und die Werte werden durch Kommas getrennt. CSV-Dateien können von vielen Anwendungen erstellt und gelesen werden, einschließlich Tabellenkalkulationsprogrammen wie Microsoft Excel und Google Sheets.\nIn R könnt ihr CSV-Dateien mit der Funktion read_csv() aus dem readr-Paket laden. Hier ein Beispiel:\n\norders &lt;- read_csv(\"data/orders.csv\")\norders |&gt; \n    head(5)\n\n# A tibble: 5 × 68\n      order_id name  order_number app_id created_at          updated_at         \n         &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;             \n1      1.13e12 B1014         1014 580111 2019-05-24 12:59:16 2019-06-19 13:23:26\n2      1.13e12 B1015         1015 580111 2019-05-24 13:09:08 2019-06-21 14:40:07\n3      1.13e12 B1016         1016 580111 2019-05-24 13:22:41 2019-06-21 12:35:23\n4      1.13e12 B1017         1017 580111 2019-05-24 13:27:43 2019-06-21 14:27:18\n5      1.13e12 B1018         1018 580111 2019-05-24 13:36:46 2019-06-21 12:11:57\n# ℹ 62 more variables: test &lt;lgl&gt;, current_subtotal_price &lt;dbl&gt;,\n#   current_total_price &lt;dbl&gt;, current_total_discounts &lt;dbl&gt;,\n#   current_total_duties_set &lt;dbl&gt;, total_discounts &lt;dbl&gt;,\n#   total_line_items_price &lt;dbl&gt;, total_outstanding &lt;dbl&gt;, total_price &lt;dbl&gt;,\n#   total_tax &lt;dbl&gt;, total_tip_received &lt;dbl&gt;, taxes_included &lt;lgl&gt;,\n#   discount_codes &lt;chr&gt;, financial_status &lt;chr&gt;, fulfillment_status &lt;chr&gt;,\n#   source_name &lt;chr&gt;, landing_site &lt;chr&gt;, landing_site_ref &lt;chr&gt;, …\n\n\nDas hat funktioniert. Aber bei CSV-Dateien gibt es einige Dinge, die sich unterscheiden können und die ihr beim Laden berücksichtigen müsst.\nTrennzeichen\nIn einigen Ländern, zum Beispiel in Deutschland, wird anstelle eines Kommas häufig ein Semikolon als Trennzeichen verwendet. Für diesen Fall gibt es die Funktion read_csv2(). Ob das Trennzeichen falsch eingestellt ist, erkennt ihr sofort am Ergebnis: Alle Werte werden in einer einzigen Spalte zusammengefasst, anstatt in mehreren Spalten verteilt zu sein. Schauen wir uns das kurz an:\n\norders_wrong &lt;- read_csv2(\"data/orders.csv\")\n\nWie in der Ausgabe zu sehen, wurde nur eine Spalte erkannt. Wenn wir uns Beispielwerte ausgeben lassen, sehen wir, dass alle Werte in dieser einen Spalte zusammengefasst wurden:\n\nhead(orders_wrong)\n\n# A tibble: 6 × 1\n  order_id,name,order_number,app_id,created_at,updated_at,test,current_subtota…¹\n  &lt;chr&gt;                                                                         \n1 \"1130007101519,B1014,1014,580111,2019-05-24T14:59:16+02:00,2019-06-19T15:23:2…\n2 \"1130014965839,B1015,1015,580111,2019-05-24T15:09:08+02:00,2019-06-21T16:40:0…\n3 \"1130026958927,B1016,1016,580111,2019-05-24T15:22:41+02:00,2019-06-21T14:35:2…\n4 \"1130030563407,B1017,1017,580111,2019-05-24T15:27:43+02:00,2019-06-21T16:27:1…\n5 \"1130038853711,B1018,1018,580111,2019-05-24T15:36:46+02:00,2019-06-21T14:11:5…\n6 \"1130045964367,B1019,1019,580111,2019-05-24T15:44:41+02:00,2019-06-21T16:37:2…\n# ℹ abbreviated name:\n#   ¹​`order_id,name,order_number,app_id,created_at,updated_at,test,current_subtotal_price,current_total_price,current_total_discounts,current_total_duties_set,total_discounts,total_line_items_price,total_outstanding,total_price,total_tax,total_tip_received,taxes_included,discount_codes,financial_status,fulfillment_status,source_name,landing_site,landing_site_ref,location_id,note,tags,processed_at,processing_method,payment_details_gateway,payment_details_credit_card_company,customer_id,customer_accepts_marketing,customer_accepts_marketing_updated_at,customer_marketing_opt_in_level,customer_sms_marketing_consent,customer_created_at,customer_updated_at,customer_gender,customer_is_hsos,customer_state,customer_orders_count,customer_total_spent,customer_last_order_id,customer_note,customer_verified_email,customer_tax_exempt,customer_tags,customer_last_order_name,campaign_tag,shipping_address_city,shipping_address_zip,shipping_address_country,shipping_address_latitude,shipping_address_longitude,billing_address_city,billing_address_zip,billing_address_country,billing_address_company,billing_address_latitude,billing_address_longitude,client_details_browser_ip,client_details_browser_height,client_details_browser_width,client_details_user_agent,cancel_reason,cancelled_at,closed_at`\n\n\nDie Funktion read_csv2() verwenden wir nur, wenn wirklich ein Semikolon als Trennzeichen verwendet wird. Bei einem Komma als Trennzeichen müssen wir read_csv() verwenden, damit die Werte korrekt in Spalten aufgeteilt werden.\nNeben dem Tabulator-Zeichen als weiterem gängigem Trennzeichen gibt es die allgemeine Funktion read_delim(), bei der ihr das Trennzeichen explizit angeben könnt. Die Tabelle gibt einen Überblick:\n\n\nFunktion\nTrennzeichen\n\n\n\nread_csv()\nKomma (,)\n\n\nread_csv2()\nSemikolon (;)\n\n\nread_tsv()\nTabulator (\\t)\n\n\nread_delim()\nBeliebiges Trennzeichen (muss angegeben werden)\n\n\n\nHier ein Beispiel für read_delim(), wenn das Trennzeichen ein Pipe-Symbol wäre:\n\norders_delim &lt;- read_delim(\"data/orders.csv\", delim = \"|\")\n\nZeichenkodierung\nTextdateien speichern die Daten in einem bestimmten Kodierungsformat. In Deutschland war es lange üblich, das Kodierungsformat “ISO-8859-1” (auch “Latin-1” genannt) zu verwenden, während international “UTF-8” der Standard ist. Wenn die CSV-Datei in einem anderen Kodierungsformat vorliegt als erwartet, müssen wir dies beim Laden angeben.\nDa die meisten Dateien heute im UTF-8-Format vorliegen, ist dies auch die Standardeinstellung in den Funktionen von readr. Mit UTF-8 könnt ihr auch das ältere, aber immer noch verwendete ASCII-Zeichenset abdecken, weil UTF-8 rückwärtskompatibel ist. Liegt die CSV-Datei jedoch in einem anderen Format vor, gebt ihr es explizit an:\n\norders_iso &lt;- read_csv(\n    \"data/orders.csv\", \n    locale = locale(encoding = \"ISO-8859-1\")\n)\n\nDas ISO-8859-1-Format ist eine Erweiterung des ASCII-Zeichensatzes und unterstützt die meisten westeuropäischen Sprachen, einschließlich Deutsch mit seinen Umlauten. UTF-8 ist leider nicht vollständig rückwärtskompatibel mit ISO-8859-1: Wenn also ein Datensatz mit ISO-8859-1 kodiert wurde und ihr ihn als UTF-8 ladet, können Umlaute und Sonderzeichen kaputt gehen.\nDezimaltrennzeichen\nIn Deutschland wird anstelle eines Punktes häufig ein Komma als Dezimaltrennzeichen verwendet. Die Funktion read_csv2() berücksichtigt das automatisch. Ihr könnt das Dezimaltrennzeichen aber auch explizit über den Parameter locale angeben.\nOb das Dezimaltrennzeichen falsch eingestellt ist, erkennt ihr wieder am Ergebnis: Alle Zahlen, die ein Dezimaltrennzeichen enthalten, werden als Text (Strings) interpretiert, anstatt als numerische Werte.\nHier ein Beispiel, bei dem wir absichtlich ein falsches Dezimaltrennzeichen angeben:\n\norders_wrong_decimal &lt;- read_csv(\n    \"data/orders.csv\", \n    locale = locale(decimal_mark = \",\")\n)\n\nSchauen wir uns jetzt die Spalte total_price an, die eigentlich eine Dezimalzahl sein müsste:\n\norders_wrong_decimal |&gt; \n    select(total_price) |&gt; \n    head(5)\n\n# A tibble: 5 × 1\n  total_price\n  &lt;chr&gt;      \n1 94.66      \n2 32.22      \n3 30.22      \n4 32.22      \n5 30.22      \n\n\nAchtet auf die Angabe des Datentyps chr, was für “character” steht, also Text. Wir sollten also schleunigst das richtige Dezimaltrennzeichen verwenden.\nManchmal hat nur eine einzelne Spalte ein anderes Dezimaltrennzeichen als die übrigen Spalten. Dann könnt ihr euch damit behelfen, die Spalte nachträglich in den korrekten Datentyp umzuwandeln:\n\norders_fixed_decimal &lt;- orders_wrong_decimal |&gt; \n    mutate(total_price = as.double(total_price))\n\nPrüfen wir, ob es geklappt hat:\n\norders_fixed_decimal |&gt; \n    select(total_price) |&gt; \n    head(5)\n\n# A tibble: 5 × 1\n  total_price\n        &lt;dbl&gt;\n1        94.7\n2        32.2\n3        30.2\n4        32.2\n5        30.2\n\n\nDie Funktion as.double() sucht standardmäßig nach einem Punkt als Dezimaltrennzeichen. Sollte es in der Spalte tatsächlich ein Komma als Dezimaltrennzeichen geben, müsst ihr parse_number() verwenden und das Dezimaltrennzeichen explizit angeben:\n\norders_fixed_decimal &lt;- orders_wrong_decimal |&gt; \n    mutate(total_price = parse_number(total_price, locale = locale(decimal_mark = \",\")))\n\nKopfzeilen\nCSV-Dateien enthalten in der Regel eine Kopfzeile, die die Namen der Spalten angibt. Die Funktionen aus readr gehen davon aus, dass diese Zeile vorhanden ist. Wenn die CSV-Datei keine Kopfzeile enthält, müsst ihr dies beim Laden angeben:\n\norders_no_header &lt;- read_csv(\n    \"data/orders.csv\", \n    col_names = FALSE\n)\n\nSchaut euch das Ergebnis an:\n\norders_no_header |&gt; \n    head(5)\n\n# A tibble: 5 × 68\n  X1     X2    X3    X4    X5    X6    X7    X8    X9    X10   X11   X12   X13  \n  &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 order… name  orde… app_… crea… upda… test  curr… curr… curr… curr… tota… tota…\n2 11300… B1014 1014  5801… 2019… 2019… False 94.66 94.66 2.0   0.0   2.0   96.66\n3 11300… B1015 1015  5801… 2019… 2019… False 32.22 32.22 0.0   0.0   0.0   32.22\n4 11300… B1016 1016  5801… 2019… 2019… False 30.22 30.22 2.0   0.0   2.0   32.22\n5 11300… B1017 1017  5801… 2019… 2019… False 32.22 32.22 0.0   0.0   0.0   32.22\n# ℹ 55 more variables: X14 &lt;chr&gt;, X15 &lt;chr&gt;, X16 &lt;chr&gt;, X17 &lt;chr&gt;, X18 &lt;chr&gt;,\n#   X19 &lt;chr&gt;, X20 &lt;chr&gt;, X21 &lt;chr&gt;, X22 &lt;chr&gt;, X23 &lt;chr&gt;, X24 &lt;chr&gt;,\n#   X25 &lt;chr&gt;, X26 &lt;chr&gt;, X27 &lt;chr&gt;, X28 &lt;chr&gt;, X29 &lt;chr&gt;, X30 &lt;chr&gt;,\n#   X31 &lt;chr&gt;, X32 &lt;chr&gt;, X33 &lt;chr&gt;, X34 &lt;chr&gt;, X35 &lt;chr&gt;, X36 &lt;chr&gt;,\n#   X37 &lt;chr&gt;, X38 &lt;chr&gt;, X39 &lt;chr&gt;, X40 &lt;chr&gt;, X41 &lt;chr&gt;, X42 &lt;chr&gt;,\n#   X43 &lt;chr&gt;, X44 &lt;chr&gt;, X45 &lt;chr&gt;, X46 &lt;chr&gt;, X47 &lt;chr&gt;, X48 &lt;chr&gt;,\n#   X49 &lt;chr&gt;, X50 &lt;chr&gt;, X51 &lt;chr&gt;, X52 &lt;chr&gt;, X53 &lt;chr&gt;, X54 &lt;chr&gt;, …\n\n\nWas ist passiert? Die Spalten wurden automatisch mit generischen Namen wie X1, X2, X3 benannt, weil keine Kopfzeile vorhanden war. Oder zumindest haben wir das behauptet. Zusätzlich wurde die erste Zeile der CSV-Datei als Datenzeile interpretiert, anstatt als Kopfzeile.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten laden</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/loading-data.html#sec-loading-data-json",
    "href": "03-data-transformation/loading-data.html#sec-loading-data-json",
    "title": "5  Daten laden",
    "section": "\n5.3 JSON und JSONL",
    "text": "5.3 JSON und JSONL\nNeben CSV gibt es ein weiteres textbasiertes Format, das euch in der Datenanalyse immer häufiger begegnet: JSON. JSON steht für “JavaScript Object Notation” und wurde ursprünglich für den Datenaustausch im Web entwickelt. Heute ist JSON weit über das Web hinaus verbreitet und wird oft für APIs, Konfigurationsdateien und hierarchisch strukturierte Daten verwendet.\nWas unterscheidet JSON von CSV? In einer CSV-Datei sind die Daten flach und tabellarisch. JSON erlaubt dagegen verschachtelte Strukturen. Ein einzelner JSON-Eintrag kann so aussehen:\n{\n  \"name\": \"Anna\",\n  \"age\": 23,\n  \"courses\": [\"Statistics\", \"Programming\", \"Data Analytics\"]\n}\nHier hat die Person ein Feld courses, das selbst eine Liste enthält. In CSV wäre das nur umständlich abzubilden.\nJSON-Dateien laden\nZum Laden von JSON-Dateien nutzt ihr das Paket jsonlite. Es wandelt die JSON-Struktur automatisch in ein tibble-ähnliches Objekt um, wenn die Daten tabellarisch interpretierbar sind:\n\nlibrary(jsonlite)\ndata &lt;- fromJSON(\"data/example.json\")\n\nDie Funktion fromJSON() erkennt, ob die JSON-Datei ein einzelnes Objekt oder eine Liste von Objekten enthält, und versucht, die Daten intelligent in einen Data Frame umzuwandeln. Bei einfachen, flachen JSON-Strukturen funktioniert das problemlos.\nJSONL\nIn der Praxis begegnet euch häufig auch das Format JSONL (JSON Lines). Dabei enthält jede Zeile der Datei genau ein JSON-Objekt. Das ist besonders bei großen Datensätzen praktisch, weil die Datei zeilenweise gelesen und verarbeitet werden kann.\nEine JSONL-Datei sieht zum Beispiel so aus:\n{\"name\": \"Anna\", \"age\": 23, \"passed\": true}\n{\"name\": \"Ben\", \"age\": 21, \"passed\": false}\n{\"name\": \"Cleo\", \"age\": 25, \"passed\": true}\nZum Laden von JSONL-Dateien könnt ihr stream_in() aus dem Paket jsonlite verwenden:\n\ndata &lt;- stream_in(file(\"data/example.jsonl\"))\n\nDie Funktion stream_in() liest die Datei zeilenweise und liefert am Ende einen Data Frame. Das ist besonders bei sehr großen Dateien effizienter als fromJSON(), weil nicht die gesamte Datei auf einmal in den Arbeitsspeicher geladen werden muss.\n\n\n\n\n\n\nTippJSON oder CSV?\n\n\n\nFür tabellarische Daten ist CSV oft die einfachere Wahl. JSON spielt seine Stärken bei verschachtelten oder hierarchischen Daten aus, zum Beispiel bei Antworten von Web-APIs. Wenn ihr Daten von einer API bekommt, liegen sie fast immer im JSON-Format vor.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten laden</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/loading-data.html#sec-loading-data-excel",
    "href": "03-data-transformation/loading-data.html#sec-loading-data-excel",
    "title": "5  Daten laden",
    "section": "\n5.4 Excel-Dateien",
    "text": "5.4 Excel-Dateien\nExcel-Dateien gehören zu den binären Formaten. Sie sind in der Praxis extrem verbreitet, weil viele Menschen mit Microsoft Excel oder Google Sheets arbeiten. Das Format .xlsx ist kein einfacher Text, sondern ein komprimiertes Archiv, das die Daten zusammen mit Formatierungen, Formeln und Metadaten speichert.\nZum Laden von Excel-Dateien in R nutzt ihr das Paket readxl, das ebenfalls zum Tidyverse-Ökosystem gehört:\n\nlibrary(readxl)\ndata &lt;- read_excel(\"data/example.xlsx\")\n\nDie Funktion read_excel() erkennt automatisch, ob es sich um eine .xls- oder .xlsx-Datei handelt. Das Ergebnis ist ein Tibble, genau wie bei read_csv().\nArbeitsblätter auswählen\nEine Besonderheit von Excel-Dateien ist, dass sie mehrere Arbeitsblätter (Sheets) enthalten können. Standardmäßig liest read_excel() das erste Arbeitsblatt. Wenn ihr ein anderes Blatt laden wollt, gebt ihr es über den Parameter sheet an:\n\n# Über den Namen\ndata &lt;- read_excel(\"data/example.xlsx\", sheet = \"Sales\")\n\n# Oder über die Position\ndata &lt;- read_excel(\"data/example.xlsx\", sheet = 2)\n\nWenn ihr nicht wisst, welche Arbeitsblätter eine Excel-Datei enthält, hilft euch excel_sheets():\n\nexcel_sheets(\"data/example.xlsx\")\n\nBereiche und Kopfzeilen\nManchmal beginnen die eigentlichen Daten in einer Excel-Datei nicht in der ersten Zeile, weil darüber ein Titel oder Erläuterungen stehen. In diesem Fall könnt ihr Zeilen überspringen:\n\ndata &lt;- read_excel(\"data/example.xlsx\", skip = 3)\n\nOder ihr gebt einen konkreten Zellbereich an, wie ihr es aus Excel kennt:\n\ndata &lt;- read_excel(\"data/example.xlsx\", range = \"B2:F100\")\n\nGenau wie bei CSV könnt ihr auch angeben, dass keine Kopfzeile vorhanden ist:\n\ndata &lt;- read_excel(\"data/example.xlsx\", col_names = FALSE)\n\n\n\n\n\n\n\nTippreadxl braucht kein Excel\n\n\n\nDas Paket readxl liest Excel-Dateien direkt, ohne dass Microsoft Excel installiert sein muss. Das ist besonders praktisch auf Servern oder in automatisierten Pipelines, wo kein Excel vorhanden ist.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten laden</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/loading-data.html#sec-loading-data-google",
    "href": "03-data-transformation/loading-data.html#sec-loading-data-google",
    "title": "5  Daten laden",
    "section": "\n5.5 Google Sheets",
    "text": "5.5 Google Sheets\nWas ist, wenn eure Daten gar nicht als Datei auf eurem Rechner liegen, sondern in der Cloud? Google Sheets ist einer der verbreitetsten Orte, an denen Teams gemeinsam Daten sammeln und pflegen. Zum Beispiel, wenn ihr eine Umfrage über Google Forms durchführt: Die Antworten landen automatisch in einem Google Sheet.\nDas Paket googlesheets4 erlaubt es euch, Daten direkt aus Google Sheets in R zu laden, ohne sie erst herunterladen zu müssen:\n\nlibrary(googlesheets4)\ndata &lt;- read_sheet(\"https://docs.google.com/spreadsheets/d/...\")\n\nIhr übergebt einfach die URL oder die ID eures Google Sheets an read_sheet(). Das Ergebnis ist ein Tibble.\nAuthentifizierung\nBeim ersten Aufruf fragt euch googlesheets4 nach einer Berechtigung, auf euer Google-Konto zuzugreifen. Es öffnet sich ein Browserfenster, in dem ihr euch anmeldet und die Berechtigung erteilt. R speichert diese Berechtigung dann lokal, sodass ihr euch nicht jedes Mal neu anmelden müsst.\nWenn ihr auf öffentlich zugängliche Sheets zugreifen wollt, könnt ihr die Authentifizierung auch komplett abschalten:\n\ngs4_deauth()\ndata &lt;- read_sheet(\"https://docs.google.com/spreadsheets/d/...\")\n\nArbeitsblätter und Bereiche\nGenau wie bei Excel-Dateien könnt ihr bei Google Sheets das Arbeitsblatt und den Zellbereich angeben:\n\n# Bestimmtes Arbeitsblatt laden\ndata &lt;- read_sheet(\"https://docs.google.com/spreadsheets/d/...\", sheet = \"Responses\")\n\n# Bestimmten Bereich laden\ndata &lt;- read_sheet(\"https://docs.google.com/spreadsheets/d/...\", range = \"A1:E100\")\n\n\n\n\n\n\n\nTippWann Google Sheets, wann CSV?\n\n\n\nGoogle Sheets ist praktisch, wenn Daten laufend aktualisiert werden und ihr immer den neuesten Stand laden wollt. Für statische Datensätze, die sich nicht mehr ändern, ist eine heruntergeladene CSV-Datei meistens die einfachere und reproduzierbarere Lösung.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten laden</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/loading-data.html#sec-loading-data-rds",
    "href": "03-data-transformation/loading-data.html#sec-loading-data-rds",
    "title": "5  Daten laden",
    "section": "\n5.6 RDS-Dateien",
    "text": "5.6 RDS-Dateien\nZum Schluss schauen wir uns ein Format an, das speziell für R entwickelt wurde: RDS. RDS steht für “R Data Serialization” und ist ein binäres Format, mit dem ihr einzelne R-Objekte speichern und wieder laden könnt.\nWarum ist das nützlich? Stellt euch vor, ihr habt einen Datensatz aufwendig bereinigt und transformiert. Wenn ihr ihn als CSV speichert, gehen dabei Informationen verloren, zum Beispiel Datentypen, Faktor-Levels oder die Zeitzone von Datumswerten. RDS bewahrt all das, weil es das R-Objekt exakt so speichert, wie es im Arbeitsspeicher vorliegt.\nRDS-Dateien laden\nZum Laden nutzt ihr read_rds():\n\ntweets &lt;- read_rds(\"data/tweets_ampel.rds\")\ntweets |&gt;\n    head(5)\n\n# A tibble: 5 × 22\n  id              screen_name text  retweet_count favorite_count is_quote_status\n  &lt;chr&gt;           &lt;chr&gt;       &lt;chr&gt;         &lt;dbl&gt;          &lt;dbl&gt; &lt;lgl&gt;          \n1 16422519457326… cem_oezdem… \"RT …            23              0 FALSE          \n2 16424168190037… W_Schmidt_  \"RT …         10659              0 FALSE          \n3 16420826297962… lisapaus    \"@Ha…             1              3 FALSE          \n4 16420901117005… lisapaus    \"@an…             1             11 FALSE          \n5 16425327413662… Wissing     \"\\U0…             6             25 FALSE          \n# ℹ 16 more variables: is_retweet &lt;lgl&gt;, retweeted_status_id &lt;chr&gt;,\n#   retweeted_user &lt;chr&gt;, lang &lt;chr&gt;, hashtags &lt;list&gt;, urls &lt;list&gt;,\n#   user_mentions &lt;list&gt;, photos &lt;list&gt;, source &lt;chr&gt;, insert_timestamp &lt;chr&gt;,\n#   created_at &lt;dttm&gt;, quote_count &lt;dbl&gt;, reply_count &lt;dbl&gt;,\n#   in_reply_to_screen_name &lt;chr&gt;, in_reply_to_status_id &lt;chr&gt;,\n#   quoted_status_id &lt;chr&gt;\n\n\nDas Ergebnis ist exakt das Objekt, das gespeichert wurde, einschließlich aller Datentypen und Attribute.\nRDS-Dateien speichern\nUmgekehrt könnt ihr jedes R-Objekt als RDS-Datei speichern:\n\nwrite_rds(tweets, \"data/tweets_backup.rds\")\n\nEin wichtiger Unterschied zu anderen Formaten: RDS speichert genau ein Objekt pro Datei. Wenn ihr mehrere Objekte speichern wollt, erstellt ihr entweder mehrere RDS-Dateien oder nutzt das verwandte Format .RData (auch .rda), das mehrere Objekte auf einmal speichern kann.\nWann RDS verwenden?\nRDS ist die beste Wahl, wenn ihr innerhalb von R arbeitet und sicherstellen wollt, dass keine Informationen verloren gehen. In diesem Buch laden wir den Tweets-Datensatz als RDS-Datei, weil so alle Spaltentypen und Metadaten erhalten bleiben. Wenn ihr Daten dagegen mit anderen Tools oder Personen teilen wollt, die kein R verwenden, ist CSV oder ein anderes offenes Format die bessere Wahl.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten laden</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/loading-data.html#sec-loading-data-zusammenfassung",
    "href": "03-data-transformation/loading-data.html#sec-loading-data-zusammenfassung",
    "title": "5  Daten laden",
    "section": "\n5.7 Kurz zusammengefasst",
    "text": "5.7 Kurz zusammengefasst\n\n\n\nCSV ist das verbreitetste textbasierte Format. Ihr ladet es mit read_csv() aus dem readr-Paket. Achtet auf Trennzeichen, Zeichenkodierung und Dezimaltrennzeichen.\n\nJSON eignet sich für hierarchische oder verschachtelte Daten und kommt oft von Web-APIs. Ihr nutzt fromJSON() oder stream_in() aus dem Paket jsonlite.\n\nExcel-Dateien ladet ihr mit read_excel() aus dem Paket readxl. Ihr könnt Arbeitsblätter, Bereiche und Kopfzeilen gezielt ansteuern.\n\nGoogle Sheets lassen sich direkt mit read_sheet() aus dem Paket googlesheets4 laden, ohne die Datei herunterladen zu müssen.\n\nRDS ist das R-eigene Binärformat. Es bewahrt alle Datentypen und Attribute und eignet sich perfekt für die Arbeit innerhalb von R.\n\n\nDaten laden ist der Startpunkt jeder Analyse. Im nächsten Kapitel lernt ihr mit dem Pipe-Operator |&gt; ein Werkzeug kennen, das euch dabei hilft, die geladenen Daten Schritt für Schritt weiterzuverarbeiten (siehe Kapitel 6).\nAbbildung: Ein Flussdiagramm mit einem zentralen Kasten “Daten laden in R”. Von dort gehen fünf Pfeile ab zu je einem Format-Kasten: CSV (mit Icon einer Textdatei), JSON (mit geschweiften Klammern), Excel (mit einem grünen Tabellen-Icon), Google Sheets (mit einem Cloud-Icon), RDS (mit dem R-Logo). Unter jedem Format-Kasten steht die zugehörige R-Funktion: read_csv(), fromJSON(), read_excel(), read_sheet(), read_rds(). Die Format-Kästen sind in zwei Gruppen aufgeteilt: links “Textbasiert” (CSV, JSON), rechts “Binär / Cloud” (Excel, Google Sheets, RDS).",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Daten laden</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/pipe.html",
    "href": "03-data-transformation/pipe.html",
    "title": "6  Pipe-Operator",
    "section": "",
    "text": "6.1 Funktionsweise\nNachdem ihr im vorherigen Kapitel gelernt habt, wie Daten in R geladen werden, schauen wir uns nun das wichtigste Werkzeug an, um diese Daten effizient weiterzuverarbeiten: den Pipe-Operator |&gt;. In diesem Kapitel lernt ihr, wie die Pipe funktioniert, wie sie Ergebnisse von einer Funktion an die nächste weiterreicht und wie ihr Code schreibt, der sich wie ein flüssiger Text liest.\nWenn ihr Daten analysiert, arbeitet ihr fast nie mit einem einzigen Befehl, sondern baut eine kleine Kette aus vielen Einzelschritten. Ohne die Pipe müsstet ihr entweder sehr viele Zwischenergebnisse speichern oder Funktionen unübersichtlich ineinander verschachteln. Mit der Pipe schreibt ihr eure Analyse stattdessen so, dass ihr sie von oben nach unten lesen könnt, was euren Code deutlich verständlicher und leichter anpassbar macht.\nDie wichtigste Regel ist kurz: Die Pipe nimmt das Ergebnis links und setzt es rechts als erstes Argument ein.\nDas sieht zum Beispiel so aus:\nund bedeutet:\nSchauen wir uns das in einem kleinen Beispiel an. Die Funktion nrow() gibt euch die Anzahl Zeilen eines Datensatzes zurück. Ohne Pipe schreibt ihr:\nnrow(tweets)\n\n[1] 58421\nMit Pipe rückt der Datensatz nach links und wird rechts automatisch in nrow() eingesetzt:\ntweets |&gt;\n  nrow()\n\n[1] 58421\nDas Ergebnis einer Pipe muss übrigens nicht immer ein Tibble bleiben. Nach nrow() ist das Ergebnis eine Zahl, in diesem Datensatz also 58.421. Diese Zahl könnt ihr direkt in den nächsten Schritt weiterreichen:\ntweets |&gt;\n  nrow() |&gt;\n  sqrt()\n\n[1] 241.7044\nInhaltlich ist das Beispiel etwas künstlich. Es zeigt aber gut, dass die Pipe einfach Ergebnisse weiterreicht, egal ob es ein Tibble, eine Zahl oder ein Text ist.\nIn Abbildung 6.1 seht ihr das typische Muster, das euch im ganzen Buch immer wieder begegnet: Am Anfang steht ein Datensatz als Tibble, danach folgen mehrere Schritte, am Ende kommt oft eine kurze Ausgabe zur Kontrolle.\nListing 6.1: Am Anfang steht immer ein Tibble, der durch die Pipe weitergereicht wird.\n\ntweets |&gt;\n  select(screen_name, favorite_count, retweet_count) |&gt;\n  glimpse()\n\n\n\n\nRows: 58,421\nColumns: 3\n$ screen_name    &lt;chr&gt; \"cem_oezdemir\", \"W_Schmidt_\", \"lisapaus\", \"lisapaus\", \"…\n$ favorite_count &lt;dbl&gt; 0, 0, 3, 11, 25, 93, 154, 448, 0, 1, 2, 2, 58, 103, 266…\n$ retweet_count  &lt;dbl&gt; 23, 10659, 1, 1, 6, 9, 15, 56, 29, 1, 1, 1, 10, 13, 26,…\nIn Listing 6.1 ist tweets der Startpunkt. select() nimmt den Tibble und reduziert ihn auf die gewünschten Spalten. glimpse() bekommt dann das Ergebnis und zeigt euch schnell Struktur und erste Werte.\nWenn ihr es formeller mögt, könnt ihr euch eine Pipe-Kette wie eine verschachtelte Funktionsanwendung vorstellen:",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pipe-Operator</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/pipe.html#sec-pipe-funktionsweise",
    "href": "03-data-transformation/pipe.html#sec-pipe-funktionsweise",
    "title": "6  Pipe-Operator",
    "section": "",
    "text": "x |&gt; f(a, b)\n\nf(x, a, b)\n\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 6.1: Die Pipe leitet das Ergebnis des ersten Befehls an den zweiten Befehl weiter.\n\n\n\n\n\n\n\n\nOhne Pipe\nMit Pipe\n\n\nf(g(h(x)))\nx |&gt; h() |&gt; g() |&gt; f()",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pipe-Operator</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/pipe.html#sec-pipe-vorteile",
    "href": "03-data-transformation/pipe.html#sec-pipe-vorteile",
    "title": "6  Pipe-Operator",
    "section": "\n6.2 Vorteile der Pipe",
    "text": "6.2 Vorteile der Pipe\nDie Pipe hilft euch vor allem bei drei Dingen:\n\n\nLesbarkeit: Ihr könnt den Code von oben nach unten lesen.\n\nWartbarkeit: Ihr könnt einzelne Schritte leicht austauschen.\n\nStruktur: Jeder Schritt steht in einer eigenen Zeile.\n\nDas merkt ihr spätestens dann, wenn eine Transformation etwas länger wird. Ohne Pipe wird daraus schnell ein Klammermonster:\n\n\n\nListing 6.2: Ohne die Pipe werden komplexe Transformationen schnell unübersichtlich.\n\nhead(\n  arrange(\n    select(\n      filter(\n        mutate(\n          filter(tweets, !is_retweet),\n          is_top_tweet = retweet_count &gt;= quantile(retweet_count, 0.99)\n        ),\n        is_top_tweet\n      ),\n      retweet_count, screen_name, text\n    ),\n    -retweet_count\n  ),\n  5\n)\n\n\n\n\n# A tibble: 5 × 3\n  retweet_count screen_name     text                                            \n          &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;                                           \n1         12652 Bundeskanzler   Der russische Überfall markiert eine Zeitenwend…\n2          8032 Bundeskanzler   The Russian invasion marks a turning point. It …\n3          7152 ABaerbockArchiv Klimakrise ist jetzt. Hören wir auf, nur zu red…\n4          5407 ABaerbock       #MohammadMehdiKarami &amp; #MohammadHosseini - …\n5          5363 Karl_Lauterbach Ich möchte mich bei allen bedanken, die mich al…\n\n\nBeim ersten Blick wirkt das wie ein Rätsel. Der Code funktioniert, aber um zu verstehen, was passiert, müsst ihr von innen nach außen lesen. Die eigentliche Schrittfolge ist:\nfilter (6) → mutate (5) → filter (4) → select (3) → arrange (2) → head (1)\nMit Pipe schreibt ihr genau diese Reihenfolge direkt so auf, wie ihr sie gedanklich sowieso abarbeitet:\n\n\n\nListing 6.3: Die Pipe gibt eine klare Struktur, macht den Code lesbar und erlaubt schnelle Änderungen.\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  mutate(is_top_tweet = retweet_count &gt;= quantile(retweet_count, 0.99)) |&gt;\n  filter(is_top_tweet) |&gt;\n  select(retweet_count, screen_name, text) |&gt;\n  arrange(-retweet_count) |&gt;\n  head(5)\n\n\n\n\n# A tibble: 5 × 3\n  retweet_count screen_name     text                                            \n          &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;                                           \n1         12652 Bundeskanzler   Der russische Überfall markiert eine Zeitenwend…\n2          8032 Bundeskanzler   The Russian invasion marks a turning point. It …\n3          7152 ABaerbockArchiv Klimakrise ist jetzt. Hören wir auf, nur zu red…\n4          5407 ABaerbock       #MohammadMehdiKarami &amp; #MohammadHosseini - …\n5          5363 Karl_Lauterbach Ich möchte mich bei allen bedanken, die mich al…\n\n\nDas Ergebnis ist identisch, aber ihr könnt jetzt jeden Schritt einzeln lesen. Außerdem könnt ihr sehr schnell ausprobieren, welchen Effekt ein Schritt hat. Kommentiert ihn dafür einfach temporär aus:\n\ntweets |&gt;\n  # filter(!is_retweet) |&gt;\n  mutate(is_top_tweet = retweet_count &gt;= quantile(retweet_count, 0.99)) |&gt;\n  filter(is_top_tweet) |&gt;\n  select(retweet_count, screen_name, text) |&gt;\n  arrange(-retweet_count) |&gt;\n  head(5)\n\n# A tibble: 5 × 3\n  retweet_count screen_name     text                                            \n          &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;                                           \n1        434571 cem_oezdemir    RT @Schwarzenegger: I love the Russian people. …\n2        276452 klara_geywitz   RT @Twitter: Twitter is built by immigrants of …\n3        271059 SteffiLemke     RT @KamalaHarris: While I may be the first woma…\n4        188454 ABaerbockArchiv RT @verygooster: every woman in this pic tho ht…\n5        169437 W_Schmidt_      RT @MarcusRashford: https://t.co/bs9lksGM4q     \n\n\nWenn ihr Retweets nicht herausfiltert, landet ein geteilter Tweet von Cem Özdemir auf Platz 1. Genau solche schnellen Checks sind in der explorativen Datenanalyse Gold wert.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pipe-Operator</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/pipe.html#sec-pipe-speichern",
    "href": "03-data-transformation/pipe.html#sec-pipe-speichern",
    "title": "6  Pipe-Operator",
    "section": "\n6.3 Ergebnis speichern",
    "text": "6.3 Ergebnis speichern\nIn den bisherigen Beispielen haben wir das Ergebnis der Pipe-Kette einfach ausgeben lassen. In der Praxis wollt ihr es aber oft in einer Variablen speichern, um damit weiterzuarbeiten. Das funktioniert genauso wie bei jeder anderen Zuweisung:\n\ntop_tweets &lt;- tweets |&gt;\n  filter(!is_retweet) |&gt;\n  arrange(-retweet_count) |&gt;\n  head(10)\n\nDanach ist top_tweets ein neues Tibble mit den zehn am häufigsten retweeteten Original-Tweets. Beachtet, dass der Zuweisungspfeil &lt;- ganz am Anfang steht, vor der Pipe-Kette. Das Ergebnis des letzten Schritts wird in der Variable gespeichert.\nEin häufiger Anfängerfehler ist, die Zuweisung zu vergessen. Dann seht ihr das Ergebnis zwar in der Konsole, aber es ist nirgendwo gespeichert. Das ist beim Erkunden kein Problem, aber sobald ihr mit dem Ergebnis weiterarbeiten wollt, braucht ihr die Zuweisung.\n\n\n\n\n\n\nTippÜberschreiben oder neues Objekt?\n\n\n\nIhr könnt das Ergebnis auch in die gleiche Variable zurückschreiben: tweets &lt;- tweets |&gt; filter(...). Das spart Variablen, aber ihr verliert den Originalzustand. Beim Experimentieren ist es oft sicherer, ein neues Objekt anzulegen.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pipe-Operator</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/pipe.html#sec-pipe-spezialfaelle",
    "href": "03-data-transformation/pipe.html#sec-pipe-spezialfaelle",
    "title": "6  Pipe-Operator",
    "section": "\n6.4 Spezialfälle",
    "text": "6.4 Spezialfälle\nIm Tidyverse klappt die Pipe fast immer reibungslos, weil die Funktionen so gestaltet sind, dass der Datensatz als erstes Argument kommt. Manchmal ist das aber anders, vor allem bei Base-R-Funktionen.\nNehmen wir an, ihr wollt einen Text aus einem Online-Fragebogen bereinigen. Da entstehen schnell doppelte Leerzeichen, die euch später beim Auswerten nerven können.\n\ntext &lt;- \"Jemand  hat unsaubere Werte   eingegeben. \"\n\ntext |&gt;\n  trimws() |&gt;\n  tolower() |&gt;\n  (\\(x) gsub(\"[[:punct:]]+\", \"\", x))() |&gt;\n  (\\(x) gsub(\"[[:space:]]+\", \" \", x))()\n\n[1] \"jemand hat unsaubere werte eingegeben\"\n\n\ngsub() (global substitute) ersetzt alle Vorkommnisse eines gesuchten Teilstrings durch einen anderen String. Im Beispiel entfernt die erste Ersetzung Satzzeichen. Die zweite fasst mehrere Leerzeichen zu einem einzelnen zusammen.\nDer Haken ist: Bei gsub() ist der Text, in dem ersetzt werden soll, das dritte Argument. Die Pipe kann ihn also nicht automatisch als erstes Argument einsetzen. Die Lösung ist eine anonyme Funktion \\(x) ..., in der ihr selbst festlegt, wo x eingesetzt wird.\nBenannte Funktionen statt anonymer Funktionen\nWenn eure anonymen Funktionen länger oder schwerer lesbar werden, könnt ihr sie auch vorab als benannte Funktion definieren. Das macht den Code übersichtlicher, vor allem wenn ihr denselben Schritt an mehreren Stellen braucht:\n\nremove_punctuation &lt;- function(x) {\n  gsub(\"[[:punct:]]+\", \"\", x)\n}\n\ncollapse_spaces &lt;- function(x) {\n  gsub(\"[[:space:]]+\", \" \", x)\n}\n\ntext |&gt;\n  trimws() |&gt;\n  tolower() |&gt;\n  remove_punctuation() |&gt;\n  collapse_spaces()\n\n[1] \"jemand hat unsaubere werte eingegeben\"\n\n\nDas Ergebnis ist identisch, aber jeder Schritt hat jetzt einen sprechenden Namen. Wenn ihr den Code Wochen später noch einmal lest, versteht ihr sofort, was passiert. Außerdem könnt ihr remove_punctuation() und collapse_spaces() in anderen Pipe-Ketten wiederverwenden.\nTidyverse-Alternativen\nWenn ihr solche Textbereinigungen häufiger macht, lohnt sich der Griff zu einer Tidyverse-Variante. Das Paket stringr bietet Funktionen, bei denen der zu bearbeitende Text als erstes Argument kommt:\n\ntext |&gt;\n  str_trim() |&gt;\n  str_to_lower() |&gt;\n  str_remove_all(\"[[:punct:]]+\") |&gt;\n  str_replace_all(\"[[:space:]]+\", \" \")\n\n[1] \"jemand hat unsaubere werte eingegeben\"\n\n\nMerkt euch: Wenn es eine passende Tidyverse-Funktion gibt, ist das Piping meistens am angenehmsten. Wenn nicht, helfen euch anonyme oder benannte Funktionen.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pipe-Operator</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/pipe.html#sec-pipe-debugging",
    "href": "03-data-transformation/pipe.html#sec-pipe-debugging",
    "title": "6  Pipe-Operator",
    "section": "\n6.5 Debugging",
    "text": "6.5 Debugging\nWas tut ihr, wenn eine Pipe-Kette nicht das liefert, was ihr erwartet? Der einfachste Trick: Baut die Kette schrittweise auf. Startet mit dem Datensatz und fügt einen Schritt nach dem anderen hinzu. Nach jedem Schritt schaut ihr euch das Zwischenergebnis an.\nIn der Praxis sieht das so aus:\n\n# Schritt 1: Nur Original-Tweets\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  nrow()\n\n[1] 35757\n\n\n\n# Schritt 2: Davon die mit vielen Retweets\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  filter(retweet_count &gt;= 100) |&gt;\n  nrow()\n\n[1] 4562\n\n\nSo seht ihr nach jedem Schritt, wie viele Zeilen übrig bleiben und ob das Ergebnis plausibel ist. Wenn die Zahl plötzlich auf null fällt oder unerwartet groß wird, wisst ihr genau, welcher Schritt das Problem verursacht.\nEin weiterer hilfreicher Trick ist glimpse() als Zwischenschritt. Es zeigt euch die Struktur und die ersten Werte, ohne den Fluss der Pipe zu unterbrechen:\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  select(screen_name, retweet_count) |&gt;\n  glimpse()\n\nRows: 35,757\nColumns: 2\n$ screen_name   &lt;chr&gt; \"lisapaus\", \"lisapaus\", \"Wissing\", \"Wissing\", \"Wissing\",…\n$ retweet_count &lt;dbl&gt; 1, 1, 6, 9, 15, 56, 1, 1, 1, 10, 13, 26, 4, 176, 21, 169…\n\n\nAutomatisches Logging mit tidylog\n\nWenn ihr es leid seid, nach jedem Schritt manuell nrow() oder glimpse() einzufügen, gibt es eine elegante Abkürzung: das Paket tidylog.\n\nlibrary(tidylog)\n\nSobald ihr es geladen habt, gibt euch jeder dplyr-Befehl automatisch eine kurze Rückmeldung, was er getan hat.\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  select(screen_name, retweet_count, text) |&gt;\n  filter(retweet_count &gt;= 100) |&gt;\n  head(5)\n\nfilter: removed 22,664 rows (39%), 35,757 rows remaining\nselect: dropped 19 variables (id, favorite_count, is_quote_status, is_retweet, retweeted_status_id, …)\nfilter: removed 31,195 rows (87%), 4,562 rows remaining\n\n\n# A tibble: 5 × 3\n  screen_name   retweet_count text                                              \n  &lt;chr&gt;                 &lt;dbl&gt; &lt;chr&gt;                                             \n1 ABaerbock               176 \"Journalismus ist kein Verbrechen. Russland muss …\n2 Bundeskanzler           169 \"Moldau ist Teil der europäischen Familie und EU-…\n3 Bundeskanzler           100 \"\\U0001f1f7\\U0001f1f4und \\U0001f1e9\\U0001f1easind…\n4 ABaerbock               438 \"Russia’s strategy of violent land-grabs and nucl…\n5 ABaerbock              1585 \"Bewohner*innen von Kiew in Todesangst im Morgenv…\n\n\nOhne dass ihr etwas an eurem Code ändern müsst, berichtet tidylog nach jedem Schritt, wie viele Zeilen entfernt oder behalten wurden und welche Spalten ausgewählt wurden. Das ist besonders bei längeren Pipe-Ketten Gold wert, weil ihr sofort seht, wo sich etwas unerwartet verändert.\nWenn ihr das Logging wieder abschalten wollt, entfernt ihr einfach die Zeile library(tidylog) oder ladet dplyr erneut, um die Originalfunktionen wiederherzustellen:\n\nlibrary(dplyr)\n\n\n\n\n\n\n\nTipptidylog nur beim Entwickeln\n\n\n\ntidylog ist ein reines Entwicklungswerkzeug. In fertigen Skripten oder Berichten entfernt ihr es wieder, damit die Ausgabe sauber bleibt. Beim Erkunden und Debuggen ist es aber ein echter Zeitsparer.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pipe-Operator</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/pipe.html#sec-pipe-zusammenfassung",
    "href": "03-data-transformation/pipe.html#sec-pipe-zusammenfassung",
    "title": "6  Pipe-Operator",
    "section": "\n6.6 Kurz zusammengefasst",
    "text": "6.6 Kurz zusammengefasst\n\nDie Pipe |&gt; reicht das Ergebnis links an den nächsten Schritt rechts weiter.\nStandardmäßig wird der linke Wert als erstes Argument eingesetzt.\nIn längeren Transformationen bringt die Pipe Lesbarkeit und macht Experimente leicht.\nMit &lt;- speichert ihr das Ergebnis einer Pipe-Kette in einer Variable.\nWenn eine Funktion den Wert nicht als erstes Argument erwartet, helfen anonyme Funktionen, benannte Funktionen oder Tidyverse-Alternativen.\nBeim Debugging baut ihr die Kette schrittweise auf und prüft nach jedem Schritt das Zwischenergebnis.\n\nIhr kennt jetzt das wichtigste Werkzeug, um Analyseschritte aneinanderzureihen. Bevor ihr damit aber gleich Spalten auswählt und Zeilen filtert, solltet ihr euren Datensatz erst einmal kennenlernen. Genau darum geht es im nächsten Kapitel (siehe Kapitel 7).",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pipe-Operator</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/exploring-data.html",
    "href": "03-data-transformation/exploring-data.html",
    "title": "7  Daten kennenlernen",
    "section": "",
    "text": "7.1 Dimensionen und Spalten\nIhr habt gelernt, wie ihr Daten aus verschiedenen Quellen laden könnt, und ihr kennt die Pipe als Werkzeug, um Schritte sauber aneinanderzureihen. Dieses Kapitel widmet sich dem nächsten logischen Schritt: Euren Datensatz kennenzulernen, bevor ihr ihn verändert. Wir befassen uns damit, wie ihr die Größe des Datensatzes bestimmt, Spalten und Datentypen überblickt, fehlende Werte aufspürt und erste statistische Kennzahlen ermittelt.\nDieser explorative Schritt ist enorm wichtig für den weiteren Verlauf eurer Arbeit, wird aber oft aus Ungeduld übersprungen. Wer sich die Zeit nimmt, seine Daten initial gründlich zu prüfen, versteht nicht nur die inhaltlichen Zusammenhänge besser, sondern erkennt auch Probleme wie verschmutzte Daten frühzeitig. Das spart später viel Zeit, weil ihr genau wisst, wo ihr ansetzen müsst, statt euch mitten in der Analyse über unerwartete Fehler zu wundern.\nDie erste Frage bei einem neuen Datensatz ist: Wie groß ist er? Mit nrow() und ncol() bekommt ihr die Anzahl der Zeilen und Spalten:\nnrow(tweets)\n\n[1] 58421\nncol(tweets)\n\n[1] 22\nUnser Tweets-Datensatz hat also 58.421 Zeilen und 22 Spalten. Jede Zeile steht für einen Tweet, jede Spalte für eine Eigenschaft dieses Tweets.\nWelche Spalten gibt es überhaupt? Mit names() bekommt ihr die Spaltennamen als Vektor:\nnames(tweets)\n\n [1] \"id\"                      \"screen_name\"            \n [3] \"text\"                    \"retweet_count\"          \n [5] \"favorite_count\"          \"is_quote_status\"        \n [7] \"is_retweet\"              \"retweeted_status_id\"    \n [9] \"retweeted_user\"          \"lang\"                   \n[11] \"hashtags\"                \"urls\"                   \n[13] \"user_mentions\"           \"photos\"                 \n[15] \"source\"                  \"insert_timestamp\"       \n[17] \"created_at\"              \"quote_count\"            \n[19] \"reply_count\"             \"in_reply_to_screen_name\"\n[21] \"in_reply_to_status_id\"   \"quoted_status_id\"\nDas ist nützlich, wenn ihr schnell nachschauen wollt, wie eine Spalte genau heißt. Denn Tippfehler in Spaltennamen führen sofort zu Fehlermeldungen.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Daten kennenlernen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/exploring-data.html#sec-exploring-data-first-rows",
    "href": "03-data-transformation/exploring-data.html#sec-exploring-data-first-rows",
    "title": "7  Daten kennenlernen",
    "section": "\n7.2 Erste Zeilen anschauen",
    "text": "7.2 Erste Zeilen anschauen\nEin Blick auf die ersten Zeilen gibt euch ein Gefühl dafür, wie die Daten aussehen. Dafür gibt es head():\n\ntweets |&gt;\n  head(5)\n\n# A tibble: 5 × 22\n  id              screen_name text  retweet_count favorite_count is_quote_status\n  &lt;chr&gt;           &lt;chr&gt;       &lt;chr&gt;         &lt;dbl&gt;          &lt;dbl&gt; &lt;lgl&gt;          \n1 16422519457326… cem_oezdem… \"RT …            23              0 FALSE          \n2 16424168190037… W_Schmidt_  \"RT …         10659              0 FALSE          \n3 16420826297962… lisapaus    \"@Ha…             1              3 FALSE          \n4 16420901117005… lisapaus    \"@an…             1             11 FALSE          \n5 16425327413662… Wissing     \"\\U0…             6             25 FALSE          \n# ℹ 16 more variables: is_retweet &lt;lgl&gt;, retweeted_status_id &lt;chr&gt;,\n#   retweeted_user &lt;chr&gt;, lang &lt;chr&gt;, hashtags &lt;list&gt;, urls &lt;list&gt;,\n#   user_mentions &lt;list&gt;, photos &lt;list&gt;, source &lt;chr&gt;, insert_timestamp &lt;chr&gt;,\n#   created_at &lt;dttm&gt;, quote_count &lt;dbl&gt;, reply_count &lt;dbl&gt;,\n#   in_reply_to_screen_name &lt;chr&gt;, in_reply_to_status_id &lt;chr&gt;,\n#   quoted_status_id &lt;chr&gt;\n\n\nUnd wenn ihr lieber die letzten Zeilen sehen wollt, nutzt ihr tail():\n\ntweets |&gt;\n  tail(5)\n\n# A tibble: 5 × 22\n  id              screen_name text  retweet_count favorite_count is_quote_status\n  &lt;chr&gt;           &lt;chr&gt;       &lt;chr&gt;         &lt;dbl&gt;          &lt;dbl&gt; &lt;lgl&gt;          \n1 15326104607968… lisapaus    RT @…            30              0 FALSE          \n2 15323909393014… cem_oezdem… RT @…             6              0 FALSE          \n3 15402350357097… SteffiLemke RT @…            63              0 FALSE          \n4 15449926952901… cem_oezdem… RT @…            54              0 FALSE          \n5 15449677044775… lisapaus    RT @…           138              0 FALSE          \n# ℹ 16 more variables: is_retweet &lt;lgl&gt;, retweeted_status_id &lt;chr&gt;,\n#   retweeted_user &lt;chr&gt;, lang &lt;chr&gt;, hashtags &lt;list&gt;, urls &lt;list&gt;,\n#   user_mentions &lt;list&gt;, photos &lt;list&gt;, source &lt;chr&gt;, insert_timestamp &lt;chr&gt;,\n#   created_at &lt;dttm&gt;, quote_count &lt;dbl&gt;, reply_count &lt;dbl&gt;,\n#   in_reply_to_screen_name &lt;chr&gt;, in_reply_to_status_id &lt;chr&gt;,\n#   quoted_status_id &lt;chr&gt;\n\n\nIn der Praxis reichen oft die ersten fünf bis zehn Zeilen, um zu erkennen, ob die Daten plausibel aussehen. Sind die Spalten richtig benannt? Stehen dort Werte, die Sinn ergeben? Sehen Zahlen wie Zahlen aus und Texte wie Texte?",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Daten kennenlernen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/exploring-data.html#sec-exploring-data-glimpse",
    "href": "03-data-transformation/exploring-data.html#sec-exploring-data-glimpse",
    "title": "7  Daten kennenlernen",
    "section": "\n7.3 Struktur mit glimpse()\n",
    "text": "7.3 Struktur mit glimpse()\n\nglimpse() aus dplyr ist eine der nützlichsten Funktionen, um sich schnell einen Überblick zu verschaffen. Sie zeigt euch für jede Spalte den Namen, den Datentyp und die ersten Werte:\n\ntweets |&gt;\n  glimpse()\n\nRows: 58,421\nColumns: 22\n$ id                      &lt;chr&gt; \"1642251945732653057\", \"1642416819003707397\", …\n$ screen_name             &lt;chr&gt; \"cem_oezdemir\", \"W_Schmidt_\", \"lisapaus\", \"lis…\n$ text                    &lt;chr&gt; \"RT @BriHasselmann: Endlich! Wir sind drangebl…\n$ retweet_count           &lt;dbl&gt; 23, 10659, 1, 1, 6, 9, 15, 56, 29, 1, 1, 1, 10…\n$ favorite_count          &lt;dbl&gt; 0, 0, 3, 11, 25, 93, 154, 448, 0, 1, 2, 2, 58,…\n$ is_quote_status         &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n$ is_retweet              &lt;lgl&gt; TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE,…\n$ retweeted_status_id     &lt;chr&gt; \"1642158717113081856\", \"1641976869460275201\", …\n$ retweeted_user          &lt;chr&gt; \"BriHasselmann\", \"aakashg0\", NA, NA, NA, NA, N…\n$ lang                    &lt;chr&gt; \"de\", \"en\", \"de\", \"de\", \"qme\", \"de\", \"de\", \"de…\n$ hashtags                &lt;list&gt; &lt;\"Tierhaltungskennzeichnung\", \"Wettbewerb\"&gt;, …\n$ urls                    &lt;list&gt; [&lt;data.frame[0 x 0]&gt;], [&lt;data.frame[0 x 0]&gt;],…\n$ user_mentions           &lt;list&gt; \"BriHasselmann\", \"aakashg0\", &lt;\"HassoSuliak\", …\n$ photos                  &lt;list&gt; [&lt;data.frame[0 x 0]&gt;], [&lt;data.frame[0 x 0]&gt;],…\n$ source                  &lt;chr&gt; \"&lt;a href=\\\"http://twitter.com/download/iphone\\…\n$ insert_timestamp        &lt;chr&gt; \"2023-04-02 03:00:04.749 UTC\", \"2023-04-02 07:…\n$ created_at              &lt;dttm&gt; 2023-04-01 19:45:50, 2023-04-02 06:40:58, 202…\n$ quote_count             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reply_count             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ in_reply_to_screen_name &lt;chr&gt; NA, NA, \"HassoSuliak\", \"andiewoerle\", \"Wissing…\n$ in_reply_to_status_id   &lt;chr&gt; NA, NA, \"1642059841169502210\", \"16420886499603…\n$ quoted_status_id        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, \"16424095440462397…\n\n\nWarum ist glimpse() so praktisch? Weil ihr auf einen Blick seht, ob die Datentypen stimmen. Wenn eine Spalte, die Zahlen enthalten sollte, als chr (Text) angezeigt wird, wisst ihr sofort, dass etwas beim Laden schiefgegangen ist. Und wenn eine Datumsspalte als dttm erscheint, könnt ihr sicher sein, dass R sie als Zeitstempel erkannt hat.\nIm Tweets-Datensatz seht ihr zum Beispiel:\n\n\nscreen_name und text sind Text (chr)\n\nretweet_count und favorite_count sind ganze Zahlen (int)\n\ncreated_at ist ein Zeitstempel (dttm)\n\nis_retweet ist ein logischer Wert (lgl), also TRUE oder FALSE\n\n\nDiese Information braucht ihr immer wieder, wenn ihr später mit mutate() oder filter() arbeitet. Deshalb schaut euch glimpse() am besten direkt nach dem Laden eurer Daten an.\n\n\n\n\n\n\nTippglimpse() vs. str()\n\n\n\nDie Base-R-Funktion str() liefert ähnliche Informationen wie glimpse(), aber in einem weniger lesbaren Format. Im Tidyverse ist glimpse() die bevorzugte Wahl.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Daten kennenlernen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/exploring-data.html#sec-exploring-data-summary",
    "href": "03-data-transformation/exploring-data.html#sec-exploring-data-summary",
    "title": "7  Daten kennenlernen",
    "section": "\n7.4 Statistische Übersicht mit summary()\n",
    "text": "7.4 Statistische Übersicht mit summary()\n\nWährend glimpse() euch die Struktur zeigt, liefert summary() statistische Kennzahlen. Für numerische Spalten bekommt ihr Minimum, Maximum, Mittelwert, Median und Quartile. Für Text- und Faktorspalten bekommt ihr die Häufigkeiten der häufigsten Werte.\n\ntweets |&gt;\n  select(retweet_count, favorite_count, is_retweet) |&gt;\n  summary()\n\n retweet_count      favorite_count     is_retweet     \n Min.   :     0.0   Min.   :     0.0   Mode :logical  \n 1st Qu.:     2.0   1st Qu.:     0.0   FALSE:35757    \n Median :     9.0   Median :     3.0   TRUE :22664    \n Mean   :   139.7   Mean   :   374.4                  \n 3rd Qu.:    35.0   3rd Qu.:    84.0                  \n Max.   :434571.0   Max.   :105493.0                  \n\n\nWas sagt euch diese Ausgabe? Schaut euch den Mittelwert und den Median an. Wenn die beiden weit auseinanderliegen, deutet das auf eine schiefe Verteilung hin. Bei retweet_count ist das typisch: Die meisten Tweets haben wenige Retweets, aber ein paar wenige haben sehr viele. Der Mittelwert wird von diesen Ausreißern nach oben gezogen, der Median bleibt davon unbeeindruckt.\nAuch das Maximum ist aufschlussreich. Wenn dort ein unplausibel hoher Wert steht, habt ihr vielleicht einen Datenfehler entdeckt.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Daten kennenlernen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/exploring-data.html#sec-exploring-data-missing",
    "href": "03-data-transformation/exploring-data.html#sec-exploring-data-missing",
    "title": "7  Daten kennenlernen",
    "section": "\n7.5 Fehlende Werte erkennen",
    "text": "7.5 Fehlende Werte erkennen\nFehlende Werte sind in echten Datensätzen völlig normal. Nicht jeder Tweet ist eine Antwort auf einen anderen, also ist in_reply_to_screen_name oft leer. Aber ihr solltet wissen, wie viele fehlende Werte es gibt und wo sie auftreten, bevor ihr mit der Analyse beginnt.\nMit is.na() und sum() könnt ihr die fehlenden Werte pro Spalte zählen:\n\ntweets |&gt;\n  summarise(\n    na_reply_to = sum(is.na(in_reply_to_screen_name)),\n    na_quoted = sum(is.na(quoted_status_id)),\n    na_retweets = sum(is.na(retweet_count))\n  )\n\n# A tibble: 1 × 3\n  na_reply_to na_quoted na_retweets\n        &lt;int&gt;     &lt;int&gt;       &lt;int&gt;\n1       44922     49507           0\n\n\nDas funktioniert, ist aber mühsam, wenn ihr viele Spalten prüfen wollt. Eleganter geht es mit across(), das ihr später noch im Detail kennenlernt (siehe Kapitel 9.9). Hier ein Vorgeschmack:\n\ntweets |&gt;\n  summarise(across(everything(), \\(x) sum(is.na(x)))) |&gt;\n  glimpse()\n\nRows: 1\nColumns: 22\n$ id                      &lt;int&gt; 0\n$ screen_name             &lt;int&gt; 0\n$ text                    &lt;int&gt; 0\n$ retweet_count           &lt;int&gt; 0\n$ favorite_count          &lt;int&gt; 0\n$ is_quote_status         &lt;int&gt; 0\n$ is_retweet              &lt;int&gt; 0\n$ retweeted_status_id     &lt;int&gt; 35757\n$ retweeted_user          &lt;int&gt; 35757\n$ lang                    &lt;int&gt; 0\n$ hashtags                &lt;int&gt; 0\n$ urls                    &lt;int&gt; 0\n$ user_mentions           &lt;int&gt; 0\n$ photos                  &lt;int&gt; 0\n$ source                  &lt;int&gt; 0\n$ insert_timestamp        &lt;int&gt; 0\n$ created_at              &lt;int&gt; 0\n$ quote_count             &lt;int&gt; 0\n$ reply_count             &lt;int&gt; 0\n$ in_reply_to_screen_name &lt;int&gt; 44922\n$ in_reply_to_status_id   &lt;int&gt; 45073\n$ quoted_status_id        &lt;int&gt; 49507\n\n\nSo seht ihr auf einen Blick, welche Spalten fehlende Werte haben und wie viele. Spalten mit null fehlenden Werten sind unkritisch. Bei Spalten mit vielen NA-Werten müsst ihr euch überlegen, wie ihr damit umgehen wollt: ignorieren, ersetzen oder die betroffenen Zeilen ausschließen.\n\n\n\n\n\n\nTippFehlende Werte sind Information\n\n\n\nEin NA bedeutet nicht, dass etwas kaputt ist. Es bedeutet, dass die Information nicht vorhanden ist. Ein Tweet ohne in_reply_to_screen_name ist kein Fehler, sondern einfach kein Reply. Behandelt fehlende Werte also nicht reflexartig als Problem, sondern fragt euch immer, warum sie fehlen.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Daten kennenlernen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/exploring-data.html#sec-exploring-data-count",
    "href": "03-data-transformation/exploring-data.html#sec-exploring-data-count",
    "title": "7  Daten kennenlernen",
    "section": "\n7.6 Häufigkeiten mit count()\n",
    "text": "7.6 Häufigkeiten mit count()\n\nBei kategorialen Variablen, also Spalten mit einer begrenzten Anzahl möglicher Werte, wollt ihr wissen, wie die Werte verteilt sind. Welche Accounts twittern am meisten? In welcher Sprache wird getwittert? Wie viele Tweets sind Retweets?\nDafür ist count() aus dplyr das perfekte Werkzeug:\n\ntweets |&gt;\n  count(is_retweet)\n\n# A tibble: 2 × 2\n  is_retweet     n\n  &lt;lgl&gt;      &lt;int&gt;\n1 FALSE      35757\n2 TRUE       22664\n\n\nUngefähr die Hälfte der Tweets sind Retweets. Das ist eine wichtige Information, denn bei vielen Analysen wollt ihr Retweets ausschließen, um nur Original-Inhalte zu betrachten.\nWelche Sprachen kommen vor?\n\ntweets |&gt;\n  count(lang, sort = TRUE) |&gt;\n  head(10)\n\n# A tibble: 10 × 2\n   lang      n\n   &lt;chr&gt; &lt;int&gt;\n 1 de    53574\n 2 en     2824\n 3 und    1165\n 4 tr      167\n 5 in       99\n 6 fr       81\n 7 es       76\n 8 nl       60\n 9 pl       60\n10 pt       44\n\n\nUnd welche Accounts sind am aktivsten?\n\ntweets |&gt;\n  count(screen_name, sort = TRUE) |&gt;\n  head(10)\n\n# A tibble: 10 × 2\n   screen_name         n\n   &lt;chr&gt;           &lt;int&gt;\n 1 c_lindner        5172\n 2 MarcoBuschmann   5171\n 3 cem_oezdemir     4704\n 4 lisapaus         4260\n 5 Karl_Lauterbach  4139\n 6 W_Schmidt_       3936\n 7 SvenjaSchulze68  3856\n 8 starkwatzinger   3848\n 9 hubertus_heil    3751\n10 SteffiLemke      3581\n\n\nMit sort = TRUE sortiert count() direkt absteigend nach Häufigkeit. Das spart euch ein zusätzliches arrange().\nIhr könnt auch nach mehreren Variablen gleichzeitig zählen. Zum Beispiel: Wie verteilen sich Original-Tweets und Retweets auf die Accounts?\n\ntweets |&gt;\n  count(screen_name, is_retweet, sort = TRUE) |&gt;\n  head(10)\n\n# A tibble: 10 × 3\n   screen_name     is_retweet     n\n   &lt;chr&gt;           &lt;lgl&gt;      &lt;int&gt;\n 1 MarcoBuschmann  FALSE       4436\n 2 Karl_Lauterbach FALSE       4018\n 3 starkwatzinger  FALSE       2942\n 4 c_lindner       FALSE       2931\n 5 cem_oezdemir    TRUE        2828\n 6 Wissing         FALSE       2447\n 7 hubertus_heil   TRUE        2390\n 8 c_lindner       TRUE        2241\n 9 lisapaus        TRUE        2162\n10 klara_geywitz   FALSE       2118\n\n\ncount() wird euch im ganzen Buch immer wieder begegnen, weil es die schnellste Art ist, sich einen Überblick über kategoriale Variablen zu verschaffen. Mehr zu count() und verwandten Funktionen erfahrt ihr im Kapitel über summarise() (siehe Kapitel 12).",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Daten kennenlernen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/exploring-data.html#sec-exploring-data-skimr",
    "href": "03-data-transformation/exploring-data.html#sec-exploring-data-skimr",
    "title": "7  Daten kennenlernen",
    "section": "\n7.7 Kompakte Übersicht mit skimr\n",
    "text": "7.7 Kompakte Übersicht mit skimr\n\nWenn ihr alles auf einmal sehen wollt, ohne einzelne Funktionen nacheinander aufzurufen, ist das Paket skimr eine ausgezeichnete Wahl. Die Funktion skim() liefert eine umfassende Übersicht, die nach Datentypen gruppiert ist:\n\nlibrary(skimr)\n\ntweets |&gt;\n  select(screen_name, text, retweet_count, favorite_count, is_retweet, created_at) |&gt;\n  skim()\n\n\nData summary\n\n\nName\nselect(…)\n\n\nNumber of rows\n58421\n\n\nNumber of columns\n6\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nlogical\n1\n\n\nnumeric\n2\n\n\nPOSIXct\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\nscreen_name\n0\n1\n7\n15\n0\n17\n0\n\n\ntext\n0\n1\n2\n612\n0\n57844\n0\n\n\n\nVariable type: logical\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\n\n\nis_retweet\n0\n1\n0.39\nFAL: 35757, TRU: 22664\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\nretweet_count\n0\n1\n139.66\n3087.42\n0\n2\n9\n35\n434571\n▇▁▁▁▁\n\n\nfavorite_count\n0\n1\n374.35\n1698.97\n0\n0\n3\n84\n105493\n▇▁▁▁▁\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\ncreated_at\n0\n1\n2012-06-27 17:02:20\n2023-04-04 09:37:10\n2021-05-20 06:58:42\n56972\n\n\n\n\nskim() zeigt euch für jede Spalte unterschiedliche Kennzahlen, je nach Datentyp:\n\nFür numerische Spalten: Mittelwert, Standardabweichung, Quartile und ein kleines Histogramm\nFür Text-Spalten: Anzahl fehlender Werte, kürzeste und längste Zeichenkette, Anzahl eindeutiger Werte\nFür logische Spalten: Anzahl TRUE und FALSE\n\nFür Datum/Zeit-Spalten: Frühestes und spätestes Datum\n\nDas kleine Histogramm in der Spalte hist ist besonders praktisch: Es zeigt euch auf einen Blick, ob die Verteilung symmetrisch, schief oder gleichmäßig ist, ganz ohne einen Plot erstellen zu müssen.\n\n\n\n\n\n\nTippskimr vs. summary()\n\n\n\nsummary() liefert die klassischen R-Kennzahlen und funktioniert ohne zusätzliches Paket. skim() bietet mehr Informationen, eine klarere Struktur und die kleinen Histogramme. Für eine schnelle Prüfung reicht summary(), für eine gründliche Erstuntersuchung ist skim() die bessere Wahl.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Daten kennenlernen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/exploring-data.html#sec-exploring-data-checklist",
    "href": "03-data-transformation/exploring-data.html#sec-exploring-data-checklist",
    "title": "7  Daten kennenlernen",
    "section": "\n7.8 Eine Checkliste für neue Datensätze",
    "text": "7.8 Eine Checkliste für neue Datensätze\nWenn ihr einen neuen Datensatz bekommt, könnt ihr euch an dieser Reihenfolge orientieren:\n\n\nDimensionen prüfen: nrow() und ncol() – wie groß ist der Datensatz?\n\nStruktur ansehen: glimpse() – welche Spalten gibt es, welche Datentypen liegen vor?\n\nErste Zeilen inspizieren: head() – sehen die Werte plausibel aus?\n\nFehlende Werte zählen: summarise(across(everything(), \\(x) sum(is.na(x)))) – wo fehlen Daten?\n\nKategorien erkunden: count() – wie sind kategoriale Variablen verteilt?\n\nStatistische Kennzahlen: summary() oder skim() – wie verteilen sich numerische Werte?\n\nDiese Reihenfolge hilft euch, systematisch vorzugehen, statt planlos in den Daten herumzustochern. In den folgenden Kapiteln werden wir den Tweets-Datensatz Stück für Stück auseinandernehmen. Dafür braucht ihr die Werkzeuge, die jetzt kommen: Spalten auswählen mit select() (siehe Kapitel 8), Variablen verändern mit mutate() (siehe Kapitel 9) und Zeilen filtern mit filter() (siehe Kapitel 11).\nJetzt, da ihr den Datensatz kennt und wisst, was euch erwartet, können wir mit der eigentlichen Arbeit beginnen. Im nächsten Kapitel lernt ihr, wie ihr mit select() gezielt die Spalten auswählt, die ihr für eine bestimmte Frage braucht.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Daten kennenlernen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/select.html",
    "href": "03-data-transformation/select.html",
    "title": "8  Variablen auswählen",
    "section": "",
    "text": "8.1 Das Grundprinzip\nNachdem ihr im vorherigen Kapitel einen ersten Überblick über euren Datensatz gewonnen habt, geht es nun an das gezielte Aufräumen. In diesem Kapitel lernt ihr die Funktion select() aus dem dplyr-Paket kennen. Wir zeigen euch, wie ihr bestimmte Spalten auswählt, überflüssige Spalten entfernt, die Reihenfolge der Variablen verändert und Spalten bei der Auswahl direkt umbenennt.\nDas gezielte Auswählen von Variablen ist ein zentraler Bestandteil der Datenvorbereitung, da reale Datensätze oft hunderte von Spalten enthalten, von denen für eine spezifische Analyse nur eine Handvoll relevant ist. Durch das Reduzieren des Datensatzes auf das Wesentliche behaltet ihr den Überblick, vermeidet Ablenkungen und macht eure Analysen deutlich strukturierter. Ihr könnt euch das wie das Packen eines Rucksacks vorstellen: Ihr nehmt nur das mit, was ihr für die nächste Etappe braucht, der Rest bleibt zu Hause.\nWir nutzen in diesem Kapitel wieder den Tweets Datensatz. Wenn ihr euch erst einmal orientieren wollt, schaut euch kurz die Spalten an:\nIn diesem Kapitel klären wir drei Dinge:\nselect() nimmt einen Tibble und gibt einen Tibble zurück. Nur die Spalten ändern sich.\nDie einfachste Form ist die Auswahl einzelner Spalten:\nMehrere Spalten schreibt ihr einfach hintereinander:\nEin praktischer Nebeneffekt ist die Reihenfolge. select() ordnet die Spalten genau so an, wie ihr sie angebt. Das ist hilfreich, wenn ihr euch eine Ausgabe gezielt lesbar machen wollt:\nAbbildung: Eine Skizze, die einen Datensatz als Tabelle zeigt. Ein Marker hebt vier Spalten hervor, die in eine kleinere Tabelle übernommen werden. Ein Pfeil zeigt, dass select() die Spalten auswählt und dabei die Reihenfolge neu anordnet.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Variablen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/select.html#sec-select-grundprinzip",
    "href": "03-data-transformation/select.html#sec-select-grundprinzip",
    "title": "8  Variablen auswählen",
    "section": "",
    "text": "tweets |&gt;\n  select(screen_name)\n\n# A tibble: 58,421 × 1\n   screen_name \n   &lt;chr&gt;       \n 1 cem_oezdemir\n 2 W_Schmidt_  \n 3 lisapaus    \n 4 lisapaus    \n 5 Wissing     \n 6 Wissing     \n 7 Wissing     \n 8 c_lindner   \n 9 lisapaus    \n10 lisapaus    \n# ℹ 58,411 more rows\n\n\n\n\n\n\ntweets |&gt;\n  select(screen_name, retweet_count, favorite_count)\n\n# A tibble: 58,421 × 3\n   screen_name  retweet_count favorite_count\n   &lt;chr&gt;                &lt;dbl&gt;          &lt;dbl&gt;\n 1 cem_oezdemir            23              0\n 2 W_Schmidt_           10659              0\n 3 lisapaus                 1              3\n 4 lisapaus                 1             11\n 5 Wissing                  6             25\n 6 Wissing                  9             93\n 7 Wissing                 15            154\n 8 c_lindner               56            448\n 9 lisapaus                29              0\n10 lisapaus                 1              1\n# ℹ 58,411 more rows\n\n\n\n\n\n\ntweets |&gt;\n  select(retweet_count, favorite_count, screen_name, text) |&gt;\n  head(3)\n\n# A tibble: 3 × 4\n  retweet_count favorite_count screen_name  text                                \n          &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;                               \n1            23              0 cem_oezdemir RT @BriHasselmann: Endlich! Wir sin…\n2         10659              0 W_Schmidt_   RT @aakashg0: Twitter revealed its …\n3             1              3 lisapaus     @HassoSuliak @Storch_i @tagesschau …",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Variablen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/select.html#sec-select-entfernen",
    "href": "03-data-transformation/select.html#sec-select-entfernen",
    "title": "8  Variablen auswählen",
    "section": "\n8.2 Spalten entfernen",
    "text": "8.2 Spalten entfernen\nManchmal ist es einfacher zu sagen, was weg soll. In select() könnt ihr Spalten mit einem Minus entfernen.\n\n\ntweets |&gt;\n  select(-text) |&gt;\n  head(3)\n\n# A tibble: 3 × 21\n  id         screen_name retweet_count favorite_count is_quote_status is_retweet\n  &lt;chr&gt;      &lt;chr&gt;               &lt;dbl&gt;          &lt;dbl&gt; &lt;lgl&gt;           &lt;lgl&gt;     \n1 164225194… cem_oezdem…            23              0 FALSE           TRUE      \n2 164241681… W_Schmidt_          10659              0 FALSE           TRUE      \n3 164208262… lisapaus                1              3 FALSE           FALSE     \n# ℹ 15 more variables: retweeted_status_id &lt;chr&gt;, retweeted_user &lt;chr&gt;,\n#   lang &lt;chr&gt;, hashtags &lt;list&gt;, urls &lt;list&gt;, user_mentions &lt;list&gt;,\n#   photos &lt;list&gt;, source &lt;chr&gt;, insert_timestamp &lt;chr&gt;, created_at &lt;dttm&gt;,\n#   quote_count &lt;dbl&gt;, reply_count &lt;dbl&gt;, in_reply_to_screen_name &lt;chr&gt;,\n#   in_reply_to_status_id &lt;chr&gt;, quoted_status_id &lt;chr&gt;\n\n\n\nDas funktioniert auch mit mehreren Spalten:\n\n\ntweets |&gt;\n  select(-text, -is_retweet) |&gt;\n  head(3)\n\n# A tibble: 3 × 20\n  id                  screen_name  retweet_count favorite_count is_quote_status\n  &lt;chr&gt;               &lt;chr&gt;                &lt;dbl&gt;          &lt;dbl&gt; &lt;lgl&gt;          \n1 1642251945732653057 cem_oezdemir            23              0 FALSE          \n2 1642416819003707397 W_Schmidt_           10659              0 FALSE          \n3 1642082629796216834 lisapaus                 1              3 FALSE          \n# ℹ 15 more variables: retweeted_status_id &lt;chr&gt;, retweeted_user &lt;chr&gt;,\n#   lang &lt;chr&gt;, hashtags &lt;list&gt;, urls &lt;list&gt;, user_mentions &lt;list&gt;,\n#   photos &lt;list&gt;, source &lt;chr&gt;, insert_timestamp &lt;chr&gt;, created_at &lt;dttm&gt;,\n#   quote_count &lt;dbl&gt;, reply_count &lt;dbl&gt;, in_reply_to_screen_name &lt;chr&gt;,\n#   in_reply_to_status_id &lt;chr&gt;, quoted_status_id &lt;chr&gt;\n\n\n\nWenn ihr euch die Spaltennamen anschauen wollt, hilft names():\n\n\nnames(tweets)\n\n [1] \"id\"                      \"screen_name\"            \n [3] \"text\"                    \"retweet_count\"          \n [5] \"favorite_count\"          \"is_quote_status\"        \n [7] \"is_retweet\"              \"retweeted_status_id\"    \n [9] \"retweeted_user\"          \"lang\"                   \n[11] \"hashtags\"                \"urls\"                   \n[13] \"user_mentions\"           \"photos\"                 \n[15] \"source\"                  \"insert_timestamp\"       \n[17] \"created_at\"              \"quote_count\"            \n[19] \"reply_count\"             \"in_reply_to_screen_name\"\n[21] \"in_reply_to_status_id\"   \"quoted_status_id\"       \n\n\n\n\n\n\n\n\n\nTippWenn select() meckert\n\n\n\nWenn ihr euch bei einem Spaltennamen vertippt, bekommt ihr eine Fehlermeldung. Das ist gut, denn es verhindert stillschweigende Fehler. Schaut dann als Erstes in names(tweets), ob der Name genau so geschrieben ist.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Variablen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/select.html#sec-select-umbenennen",
    "href": "03-data-transformation/select.html#sec-select-umbenennen",
    "title": "8  Variablen auswählen",
    "section": "\n8.3 Umbenennen",
    "text": "8.3 Umbenennen\nIhr könnt Spalten in select() auch direkt umbenennen. Das Muster ist:\nneuer_name = alter_name\n\n\ntweets |&gt;\n  select(\n    user = screen_name,\n    likes = favorite_count,\n    retweets = retweet_count,\n    text\n  ) |&gt;\n  head(3)\n\n# A tibble: 3 × 4\n  user         likes retweets text                                              \n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;                                             \n1 cem_oezdemir     0       23 RT @BriHasselmann: Endlich! Wir sind drangebliebe…\n2 W_Schmidt_       0    10659 RT @aakashg0: Twitter revealed its algorithm to t…\n3 lisapaus         3        1 @HassoSuliak @Storch_i @tagesschau Die EU Richtli…\n\n\n\nDas ist praktisch, wenn ihr ohnehin gerade eine Auswahl baut. Wenn ihr dagegen nur umbenennen wollt, ohne die Spaltenauswahl zu ändern, ist rename() die bessere Wahl:\n\ntweets |&gt;\n  rename(user = screen_name, likes = favorite_count) |&gt;\n  head(3)\n\n# A tibble: 3 × 22\n  id                  user  text  retweet_count likes is_quote_status is_retweet\n  &lt;chr&gt;               &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;           &lt;lgl&gt;     \n1 1642251945732653057 cem_… RT @…            23     0 FALSE           TRUE      \n2 1642416819003707397 W_Sc… RT @…         10659     0 FALSE           TRUE      \n3 1642082629796216834 lisa… @Has…             1     3 FALSE           FALSE     \n# ℹ 15 more variables: retweeted_status_id &lt;chr&gt;, retweeted_user &lt;chr&gt;,\n#   lang &lt;chr&gt;, hashtags &lt;list&gt;, urls &lt;list&gt;, user_mentions &lt;list&gt;,\n#   photos &lt;list&gt;, source &lt;chr&gt;, insert_timestamp &lt;chr&gt;, created_at &lt;dttm&gt;,\n#   quote_count &lt;dbl&gt;, reply_count &lt;dbl&gt;, in_reply_to_screen_name &lt;chr&gt;,\n#   in_reply_to_status_id &lt;chr&gt;, quoted_status_id &lt;chr&gt;\n\n\nMit rename() bleiben alle Spalten erhalten, nur die genannten bekommen einen neuen Namen.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Variablen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/select.html#sec-select-muster",
    "href": "03-data-transformation/select.html#sec-select-muster",
    "title": "8  Variablen auswählen",
    "section": "\n8.4 Spaltenmuster",
    "text": "8.4 Spaltenmuster\nIn echten Projekten ändern sich Datensätze. Es kommen Spalten dazu, Namen ändern sich leicht, oder ihr bekommt eine zweite Version einer Datei. Dann ist es hilfreich, nicht alles hart auszuschreiben, sondern über Muster auszuwählen.\n\nstarts_with(), ends_with(), contains()\n\nDiese drei Helfer sind schnell verstanden:\n\n\nstarts_with(\"...\"): Name beginnt mit diesem Text\n\nends_with(\"...\"): Name endet mit diesem Text\n\ncontains(\"...\"): Name enthält diesen Text\n\nDamit das reproduzierbar ist, schauen wir uns die Idee kurz an einem Mini Datensatz an:\n\n\nmini &lt;- tibble(\n  user_name = c(\"a\", \"b\"),\n  user_id = c(1, 2),\n  tweet_text = c(\"hi\", \"bye\"),\n  tweet_id = c(10, 20)\n)\n\nmini |&gt;\n  select(starts_with(\"user\"))\n\n# A tibble: 2 × 2\n  user_name user_id\n  &lt;chr&gt;       &lt;dbl&gt;\n1 a               1\n2 b               2\n\n\n\nUnd genauso funktionieren die Helfer auch in größeren Datensätzen. Wenn eure Spalten sinnvolle Präfixe oder Suffixe haben, spart ihr euch viel Tipparbeit.\n\nmatches() für reguläre Ausdrücke\nmatches() ist die fortgeschrittene Variante, wenn ihr ein Muster sehr genau beschreiben wollt. Dahinter stecken reguläre Ausdrücke.\n\n\nmini |&gt;\n  select(matches(\"_(id|text)$\"))\n\n# A tibble: 2 × 3\n  user_id tweet_text tweet_id\n    &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;\n1       1 hi               10\n2       2 bye              20\n\n\n\nWenn euch reguläre Ausdrücke neu sind, merkt euch erst einmal diese Idee: Ihr könnt damit sehr präzise sagen, wie Spaltennamen aussehen sollen.\n\neverything() und last_col()\n\nManchmal wollt ihr nur einzelne Spalten an eine bestimmte Stelle schieben. Dafür könnt ihr everything() nutzen, das für alle übrigen Spalten steht.\n\n\ntweets |&gt;\n  select(screen_name, everything()) |&gt;\n  head(3)\n\n# A tibble: 3 × 22\n  screen_name  id             text  retweet_count favorite_count is_quote_status\n  &lt;chr&gt;        &lt;chr&gt;          &lt;chr&gt;         &lt;dbl&gt;          &lt;dbl&gt; &lt;lgl&gt;          \n1 cem_oezdemir 1642251945732… RT @…            23              0 FALSE          \n2 W_Schmidt_   1642416819003… RT @…         10659              0 FALSE          \n3 lisapaus     1642082629796… @Has…             1              3 FALSE          \n# ℹ 16 more variables: is_retweet &lt;lgl&gt;, retweeted_status_id &lt;chr&gt;,\n#   retweeted_user &lt;chr&gt;, lang &lt;chr&gt;, hashtags &lt;list&gt;, urls &lt;list&gt;,\n#   user_mentions &lt;list&gt;, photos &lt;list&gt;, source &lt;chr&gt;, insert_timestamp &lt;chr&gt;,\n#   created_at &lt;dttm&gt;, quote_count &lt;dbl&gt;, reply_count &lt;dbl&gt;,\n#   in_reply_to_screen_name &lt;chr&gt;, in_reply_to_status_id &lt;chr&gt;,\n#   quoted_status_id &lt;chr&gt;\n\n\n\nlast_col() ist ähnlich praktisch, wenn ihr Bereiche über das Ende eines Datensatzes ausdrücken wollt. Das ist vor allem bei vielen Spalten hilfreich.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Variablen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/select.html#sec-select-bereiche",
    "href": "03-data-transformation/select.html#sec-select-bereiche",
    "title": "8  Variablen auswählen",
    "section": "\n8.5 Bereiche",
    "text": "8.5 Bereiche\nIhr könnt Spalten auch als Bereich auswählen, zum Beispiel a:c. Das funktioniert allerdings nur, wenn die Spalten im Datensatz in dieser Reihenfolge vorkommen.\nDamit ihr den Mechanismus sicher seht, nutzen wir wieder einen kleinen Datensatz:\n\n\ntoy &lt;- tibble(a = 1, b = 2, c = 3, d = 4)\n\ntoy |&gt;\n  select(b:d)\n\n# A tibble: 1 × 3\n      b     c     d\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     2     3     4\n\n\n\nIn euren eigenen Daten ist : vor allem dann praktisch, wenn Spaltenblöcke zusammenhängen, zum Beispiel Messwerte von m1 bis m20.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Variablen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/select.html#sec-select-dynamisch",
    "href": "03-data-transformation/select.html#sec-select-dynamisch",
    "title": "8  Variablen auswählen",
    "section": "\n8.6 Dynamische Auswahl",
    "text": "8.6 Dynamische Auswahl\nOft habt ihr eine Liste von Spaltennamen, die ihr auswählen wollt. Vielleicht kommt sie aus einem Skript, aus einer Konfiguration oder ihr baut sie dynamisch zusammen.\nWenn ihr einfach einen Vektor in select() schreibt, funktioniert das nicht so, wie ihr es vermutlich erwartet. Stattdessen nutzt ihr all_of() oder any_of():\n\n\nall_of(cols): alle Spalten müssen existieren, sonst gibt es einen Fehler\n\nany_of(cols): nimmt, was existiert, und ignoriert den Rest\n\n\n\ncols &lt;- c(\"screen_name\", \"retweet_count\", \"does_not_exist\")\n\n# all_of() ist strikt und hilft, Fehler früh zu finden.\n# Dieser Aufruf wirft hier absichtlich einen Fehler, weil eine Spalte nicht existiert.\ntweets |&gt;\n  select(all_of(cols))\n\nError in `select()`:\nℹ In argument: `all_of(cols)`.\nCaused by error in `all_of()` at rlang/R/eval-tidy.R:121:3:\n! Can't subset elements that don't exist.\n✖ Element `does_not_exist` doesn't exist.\n\n\n\ncols &lt;- c(\"screen_name\", \"retweet_count\", \"does_not_exist\")\n\n# any_of() ist tolerant, wenn sich Spalten je nach Version unterscheiden\ntweets |&gt;\n  select(any_of(cols)) |&gt;\n  head(3)\n\n# A tibble: 3 × 2\n  screen_name  retweet_count\n  &lt;chr&gt;                &lt;dbl&gt;\n1 cem_oezdemir            23\n2 W_Schmidt_           10659\n3 lisapaus                 1\n\n\n\nall_of() ist oft die bessere Wahl, wenn ihr euch auf eine feste Struktur verlasst. any_of() ist hilfreich, wenn ihr bewusst mit mehreren Datensatz Varianten arbeiten wollt.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Variablen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/select.html#sec-select-datentyp",
    "href": "03-data-transformation/select.html#sec-select-datentyp",
    "title": "8  Variablen auswählen",
    "section": "\n8.7 Auswahl nach Datentyp",
    "text": "8.7 Auswahl nach Datentyp\nManchmal wollt ihr nicht nach Namen auswählen, sondern nach Eigenschaften. Zum Beispiel alle numerischen Spalten, weil ihr sie gleich zusammenfassen oder visualisieren wollt.\nDas geht mit where():\n\n\ntweets |&gt;\n  select(where(is.numeric)) |&gt;\n  glimpse()\n\nRows: 58,421\nColumns: 4\n$ retweet_count  &lt;dbl&gt; 23, 10659, 1, 1, 6, 9, 15, 56, 29, 1, 1, 1, 10, 13, 26,…\n$ favorite_count &lt;dbl&gt; 0, 0, 3, 11, 25, 93, 154, 448, 0, 1, 2, 2, 58, 103, 266…\n$ quote_count    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reply_count    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\nIhr könnt where() auch kombinieren, zum Beispiel alle Zeichen Spalten, aber ohne den Text:\n\n\ntweets |&gt;\n  select(where(is.character), -text) |&gt;\n  head(3)\n\n# A tibble: 3 × 10\n  id                 screen_name retweeted_status_id retweeted_user lang  source\n  &lt;chr&gt;              &lt;chr&gt;       &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt; &lt;chr&gt; \n1 16422519457326530… cem_oezdem… 1642158717113081856 BriHasselmann  de    \"&lt;a h…\n2 16424168190037073… W_Schmidt_  1641976869460275201 aakashg0       en    \"&lt;a h…\n3 16420826297962168… lisapaus    &lt;NA&gt;                &lt;NA&gt;           de    \"&lt;a h…\n# ℹ 4 more variables: insert_timestamp &lt;chr&gt;, in_reply_to_screen_name &lt;chr&gt;,\n#   in_reply_to_status_id &lt;chr&gt;, quoted_status_id &lt;chr&gt;\n\n\n\nAbbildung: Zwei Filterkarten. Karte eins heißt “Namensmuster” und zeigt starts_with(), contains(), matches(). Karte zwei heißt “Eigenschaften” und zeigt where(is.numeric). Beide führen in denselben Ausgang “select()”. Der Fokus ist, dass es zwei Denkweisen gibt.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Variablen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/select.html#sec-select-weitere",
    "href": "03-data-transformation/select.html#sec-select-weitere",
    "title": "8  Variablen auswählen",
    "section": "\n8.8 Weitere Werkzeuge",
    "text": "8.8 Weitere Werkzeuge\n\nnum_range() für durchnummerierte Spalten\nWenn Spalten durchnummeriert sind, hilft num_range(). Das ist typisch bei Messreihen oder Umfrageitems wie q1, q2, q3.\n\n\nsurvey_like &lt;- tibble(q1 = 1, q2 = 2, q3 = 3, meta = \"x\")\n\nsurvey_like |&gt;\n  select(num_range(\"q\", 1:3))\n\n# A tibble: 1 × 3\n     q1    q2    q3\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     2     3\n\n\n\nOptionales Entfernen mit -any_of()\n\nManchmal wollt ihr Spalten entfernen, die vielleicht gar nicht in jeder Version eures Datensatzes existieren. Dann ist -any_of() praktisch:\n\n\ntweets |&gt;\n  select(-any_of(c(\"text\", \"does_not_exist\"))) |&gt;\n  head(3)\n\n# A tibble: 3 × 21\n  id         screen_name retweet_count favorite_count is_quote_status is_retweet\n  &lt;chr&gt;      &lt;chr&gt;               &lt;dbl&gt;          &lt;dbl&gt; &lt;lgl&gt;           &lt;lgl&gt;     \n1 164225194… cem_oezdem…            23              0 FALSE           TRUE      \n2 164241681… W_Schmidt_          10659              0 FALSE           TRUE      \n3 164208262… lisapaus                1              3 FALSE           FALSE     \n# ℹ 15 more variables: retweeted_status_id &lt;chr&gt;, retweeted_user &lt;chr&gt;,\n#   lang &lt;chr&gt;, hashtags &lt;list&gt;, urls &lt;list&gt;, user_mentions &lt;list&gt;,\n#   photos &lt;list&gt;, source &lt;chr&gt;, insert_timestamp &lt;chr&gt;, created_at &lt;dttm&gt;,\n#   quote_count &lt;dbl&gt;, reply_count &lt;dbl&gt;, in_reply_to_screen_name &lt;chr&gt;,\n#   in_reply_to_status_id &lt;chr&gt;, quoted_status_id &lt;chr&gt;\n\n\n\nGruppierte Daten: Gruppierungsvariablen bleiben erhalten\nEin Detail, das euch später viel Zeit sparen kann: Wenn ein Tibble gruppiert ist, behält select() die Gruppierungsvariablen auch dann, wenn ihr sie nicht explizit auswählt.\n\n\ntweets |&gt;\n  group_by(screen_name) |&gt;\n  select(retweet_count) |&gt;\n  head(3)\n\n# A tibble: 3 × 2\n# Groups:   screen_name [3]\n  screen_name  retweet_count\n  &lt;chr&gt;                &lt;dbl&gt;\n1 cem_oezdemir            23\n2 W_Schmidt_           10659\n3 lisapaus                 1",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Variablen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/select.html#sec-select-relocate",
    "href": "03-data-transformation/select.html#sec-select-relocate",
    "title": "8  Variablen auswählen",
    "section": "\n8.9 Spalten umordnen mit relocate()\n",
    "text": "8.9 Spalten umordnen mit relocate()\n\nManchmal wollt ihr Spalten nicht auswählen oder entfernen, sondern nur an eine andere Stelle schieben. Dafür gibt es relocate(). Es verschiebt Spalten, ohne die übrigen zu verändern:\n\ntweets |&gt;\n  relocate(text, .before = screen_name) |&gt;\n  head(3)\n\n# A tibble: 3 × 22\n  id              text  screen_name retweet_count favorite_count is_quote_status\n  &lt;chr&gt;           &lt;chr&gt; &lt;chr&gt;               &lt;dbl&gt;          &lt;dbl&gt; &lt;lgl&gt;          \n1 16422519457326… RT @… cem_oezdem…            23              0 FALSE          \n2 16424168190037… RT @… W_Schmidt_          10659              0 FALSE          \n3 16420826297962… @Has… lisapaus                1              3 FALSE          \n# ℹ 16 more variables: is_retweet &lt;lgl&gt;, retweeted_status_id &lt;chr&gt;,\n#   retweeted_user &lt;chr&gt;, lang &lt;chr&gt;, hashtags &lt;list&gt;, urls &lt;list&gt;,\n#   user_mentions &lt;list&gt;, photos &lt;list&gt;, source &lt;chr&gt;, insert_timestamp &lt;chr&gt;,\n#   created_at &lt;dttm&gt;, quote_count &lt;dbl&gt;, reply_count &lt;dbl&gt;,\n#   in_reply_to_screen_name &lt;chr&gt;, in_reply_to_status_id &lt;chr&gt;,\n#   quoted_status_id &lt;chr&gt;\n\n\nMit .before und .after legt ihr fest, wohin die Spalte wandert. Wenn ihr mehrere Spalten auf einmal verschieben wollt, funktionieren auch die bekannten Helfer wie starts_with() oder where():\n\ntweets |&gt;\n  relocate(where(is.numeric), .after = last_col()) |&gt;\n  head(3)\n\n# A tibble: 3 × 22\n  id            screen_name text  is_quote_status is_retweet retweeted_status_id\n  &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt; &lt;lgl&gt;           &lt;lgl&gt;      &lt;chr&gt;              \n1 164225194573… cem_oezdem… RT @… FALSE           TRUE       1642158717113081856\n2 164241681900… W_Schmidt_  RT @… FALSE           TRUE       1641976869460275201\n3 164208262979… lisapaus    @Has… FALSE           FALSE      &lt;NA&gt;               \n# ℹ 16 more variables: retweeted_user &lt;chr&gt;, lang &lt;chr&gt;, hashtags &lt;list&gt;,\n#   urls &lt;list&gt;, user_mentions &lt;list&gt;, photos &lt;list&gt;, source &lt;chr&gt;,\n#   insert_timestamp &lt;chr&gt;, created_at &lt;dttm&gt;, in_reply_to_screen_name &lt;chr&gt;,\n#   in_reply_to_status_id &lt;chr&gt;, quoted_status_id &lt;chr&gt;, retweet_count &lt;dbl&gt;,\n#   favorite_count &lt;dbl&gt;, quote_count &lt;dbl&gt;, reply_count &lt;dbl&gt;\n\n\nrelocate() ist eine gute Alternative zu dem Trick mit select(spalte, everything()), weil die Absicht klarer ist.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Variablen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/select.html#sec-select-pipe",
    "href": "03-data-transformation/select.html#sec-select-pipe",
    "title": "8  Variablen auswählen",
    "section": "\n8.10 Einsatz in Pipe-Ketten",
    "text": "8.10 Einsatz in Pipe-Ketten\nIn der explorativen Analyse nutzt ihr select() selten allein. Meist ist es ein Schritt in einer Pipe-Kette, um die Sicht auf den Datensatz zu fokussieren.\nHier ist ein typisches Muster: erst auswählen, dann kurz prüfen.\n\n\ntweets |&gt;\n  select(screen_name, retweet_count, favorite_count) |&gt;\n  glimpse()\n\nRows: 58,421\nColumns: 3\n$ screen_name    &lt;chr&gt; \"cem_oezdemir\", \"W_Schmidt_\", \"lisapaus\", \"lisapaus\", \"…\n$ retweet_count  &lt;dbl&gt; 23, 10659, 1, 1, 6, 9, 15, 56, 29, 1, 1, 1, 10, 13, 26,…\n$ favorite_count &lt;dbl&gt; 0, 0, 3, 11, 25, 93, 154, 448, 0, 1, 2, 2, 58, 103, 266…\n\n\n\nWenn ihr danach weiterarbeitet, habt ihr weniger Ballast in eurem Kopf und in euren Ausgaben.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Variablen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/select.html#sec-select-zusammenfassung",
    "href": "03-data-transformation/select.html#sec-select-zusammenfassung",
    "title": "8  Variablen auswählen",
    "section": "\n8.11 Kurz zusammengefasst",
    "text": "8.11 Kurz zusammengefasst\n\n\n\nselect() wählt Spalten aus, ordnet sie um und kann sie auch umbenennen.\nMit -spalte entfernt ihr Spalten, statt sie aufzuzählen.\nMit Helfern wie starts_with() oder matches() bleibt eure Auswahl flexibel.\nMit all_of() und any_of() wählt ihr Spalten über Vektoren aus, strikt oder tolerant.\nMit where() wählt ihr Spalten nach Datentyp aus, zum Beispiel alle numerischen Spalten.\n\n\nIhr wisst jetzt, wie ihr euren Datensatz auf die relevanten Spalten zuschneidet. Im nächsten Kapitel lernt ihr, wie ihr bestehende Spalten mit mutate() verändern könnt, zum Beispiel um Datentypen zu korrigieren oder Texte zu normalisieren (siehe Kapitel 9).",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Variablen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/mutate-modify.html",
    "href": "03-data-transformation/mutate-modify.html",
    "title": "9  Variablen verändern",
    "section": "",
    "text": "9.1 Variablen umbenennen\nNachdem ihr gelernt habt, wie ihr Datensätze auf die relevanten Spalten reduziert, widmen wir uns nun der Qualität dieser Spalten. In diesem Kapitel geht es darum, wie ihr bestehende Variablen mit der Funktion mutate() aus dem dplyr-Paket gezielt verändern könnt. Wir zeigen euch, wie ihr Datentypen korrigiert, Text vereinheitlicht und fehlende oder fehlerhafte Werte ersetzt.\nBevor ihr mit euren Daten rechnen, filtern oder visualisieren könnt, müsst ihr sie oft erst in Form bringen, denn die Realität liefert selten perfekte Daten. Spalten haben den falschen Datentyp, Texte sind uneinheitlich geschrieben oder es fehlen Werte. Wer lernt, diese Unsauberkeiten effizient zu beheben, schafft die notwendige Grundlage für alle verlässlichen Analysen und Modelle, die auf diesen Daten aufbauen.\nDie folgende Tabelle zeigt die Funktionen, die wir in diesem Abschnitt kennenlernen.\nBeginnen wir mit der rudimentärsten Form der Anpassung: Dem Umbenennen von Spalten.\nDas Umbenennen von Spalten ist streng genommen keine mutate()-Aufgabe, aber es gehört zum Vorbereiten eines Datensatzes dazu. Wie ihr im Kapitel zu select() gesehen habt (siehe Kapitel 8.3), gibt es dafür die Funktion rename():\ntweets |&gt;\n  rename(user = screen_name, likes = favorite_count) |&gt;\n  head(3)\n\n# A tibble: 3 × 22\n  id                  user  text  retweet_count likes is_quote_status is_retweet\n  &lt;chr&gt;               &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;           &lt;lgl&gt;     \n1 1642251945732653057 cem_… RT @…            23     0 FALSE           TRUE      \n2 1642416819003707397 W_Sc… RT @…         10659     0 FALSE           TRUE      \n3 1642082629796216834 lisa… @Has…             1     3 FALSE           FALSE     \n# ℹ 15 more variables: retweeted_status_id &lt;chr&gt;, retweeted_user &lt;chr&gt;,\n#   lang &lt;chr&gt;, hashtags &lt;list&gt;, urls &lt;list&gt;, user_mentions &lt;list&gt;,\n#   photos &lt;list&gt;, source &lt;chr&gt;, insert_timestamp &lt;chr&gt;, created_at &lt;dttm&gt;,\n#   quote_count &lt;dbl&gt;, reply_count &lt;dbl&gt;, in_reply_to_screen_name &lt;chr&gt;,\n#   in_reply_to_status_id &lt;chr&gt;, quoted_status_id &lt;chr&gt;\nDas Muster ist immer neuer_name = alter_name. Alle übrigen Spalten bleiben unverändert.\nWenn ihr viele Spalten auf einmal umbenennen wollt, gibt es auch rename_with(). Damit könnt ihr eine Funktion auf alle (oder ausgewählte) Spaltennamen anwenden. Zum Beispiel alles in Großbuchstaben:\norders |&gt;\n  rename_with(toupper) |&gt;\n  head(3)\n\n# A tibble: 3 × 68\n      ORDER_ID NAME  ORDER_NUMBER APP_ID CREATED_AT          UPDATED_AT         \n         &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;             \n1      1.13e12 B1014         1014 580111 2019-05-24 12:59:16 2019-06-19 13:23:26\n2      1.13e12 B1015         1015 580111 2019-05-24 13:09:08 2019-06-21 14:40:07\n3      1.13e12 B1016         1016 580111 2019-05-24 13:22:41 2019-06-21 12:35:23\n# ℹ 62 more variables: TEST &lt;lgl&gt;, CURRENT_SUBTOTAL_PRICE &lt;dbl&gt;,\n#   CURRENT_TOTAL_PRICE &lt;dbl&gt;, CURRENT_TOTAL_DISCOUNTS &lt;dbl&gt;,\n#   CURRENT_TOTAL_DUTIES_SET &lt;dbl&gt;, TOTAL_DISCOUNTS &lt;dbl&gt;,\n#   TOTAL_LINE_ITEMS_PRICE &lt;dbl&gt;, TOTAL_OUTSTANDING &lt;dbl&gt;, TOTAL_PRICE &lt;dbl&gt;,\n#   TOTAL_TAX &lt;dbl&gt;, TOTAL_TIP_RECEIVED &lt;dbl&gt;, TAXES_INCLUDED &lt;lgl&gt;,\n#   DISCOUNT_CODES &lt;chr&gt;, FINANCIAL_STATUS &lt;chr&gt;, FULFILLMENT_STATUS &lt;chr&gt;,\n#   SOURCE_NAME &lt;chr&gt;, LANDING_SITE &lt;chr&gt;, LANDING_SITE_REF &lt;chr&gt;, …\nOder nur ausgewählte Spalten:\ntweets |&gt;\n  rename_with(toupper, starts_with(\"retweet\")) |&gt;\n  names()\n\n [1] \"id\"                      \"screen_name\"            \n [3] \"text\"                    \"RETWEET_COUNT\"          \n [5] \"favorite_count\"          \"is_quote_status\"        \n [7] \"is_retweet\"              \"RETWEETED_STATUS_ID\"    \n [9] \"RETWEETED_USER\"          \"lang\"                   \n[11] \"hashtags\"                \"urls\"                   \n[13] \"user_mentions\"           \"photos\"                 \n[15] \"source\"                  \"insert_timestamp\"       \n[17] \"created_at\"              \"quote_count\"            \n[19] \"reply_count\"             \"in_reply_to_screen_name\"\n[21] \"in_reply_to_status_id\"   \"quoted_status_id\"\nIn der Praxis begegnen euch oft Datensätze mit Spaltennamen wie Total Price, Order.ID oder CUSTOMER_NAME. Leerzeichen, Punkte, Großbuchstaben und gemischte Konventionen machen das Arbeiten unnötig umständlich. Das Paket janitor bietet dafür clean_names(), das alle Spaltennamen auf einmal in ein einheitliches Format bringt:\nlibrary(janitor)\n\nmessy_columns &lt;- tibble(\n  `Order ID` = 1:3,\n  `Total.Price` = c(9.99, 19.50, 4.99),\n  `CUSTOMER name` = c(\"Anna\", \"Ben\", \"Cleo\")\n)\n\nmessy_columns |&gt;\n  clean_names()\n\n# A tibble: 3 × 3\n  order_id total_price customer_name\n     &lt;int&gt;       &lt;dbl&gt; &lt;chr&gt;        \n1        1        9.99 Anna         \n2        2       19.5  Ben          \n3        3        4.99 Cleo\nclean_names() wandelt alles in snake_case um: Kleinbuchstaben, Unterstriche statt Leerzeichen und Punkte, keine Sonderzeichen. Das ist besonders praktisch, wenn ihr Daten aus Excel oder externen Quellen ladet, bei denen die Spaltennamen nicht für R optimiert sind.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Variablen verändern</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/mutate-modify.html#sec-mutate-modify-umbenennen",
    "href": "03-data-transformation/mutate-modify.html#sec-mutate-modify-umbenennen",
    "title": "9  Variablen verändern",
    "section": "",
    "text": "TippNamenskonventionen\n\n\n\nEs gibt verschiedene Konventionen, um mehrteilige Namen zu schreiben:\n\n\nKonvention\nBeispiel\nTypisch für\n\n\n\nsnake_case\ntotal_price\nR, Python\n\n\ncamelCase\ntotalPrice\nJavaScript, Java\n\n\nPascalCase\nTotalPrice\nC#, Klassennamen\n\n\nkebab-case\ntotal-price\nURLs, CSS\n\n\ndot.case\ntotal.price\nÄlterer R-Code\n\n\n\nIn R und im Tidyverse ist snake_case der Standard. clean_names() sorgt dafür, dass eure Spaltennamen automatisch diesem Standard folgen.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Variablen verändern</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/mutate-modify.html#sec-mutate-modify-datentypen",
    "href": "03-data-transformation/mutate-modify.html#sec-mutate-modify-datentypen",
    "title": "9  Variablen verändern",
    "section": "\n9.2 Datentypen umwandeln",
    "text": "9.2 Datentypen umwandeln\nWarum ändert man überhaupt den Datentyp einer Spalte? Weil R je nach Typ unterschiedliche Dinge damit machen kann. Eine Zahl, die als Text gespeichert ist, lässt sich nicht addieren. Ein Datum, das als Zeichenkette vorliegt, kann nicht nach Monaten gruppiert werden. Deshalb ist das Umwandeln von Datentypen einer der häufigsten Schritte bei der Datenvorbereitung.\nText in Zahlen\nManchmal kommen Zahlenwerte als Text in euren Datensatz, zum Beispiel weil sie aus einer CSV-Datei falsch geladen wurden. Mit as.double() oder as.integer() wandelt ihr sie um:\n\ndata_with_text_numbers &lt;- tibble(\n  product = c(\"Laptop\", \"Mouse\", \"Keyboard\"),\n  price = c(\"999.99\", \"29.50\", \"79.00\")\n)\n\ndata_with_text_numbers |&gt;\n  mutate(price = as.double(price))\n\n# A tibble: 3 × 2\n  product   price\n  &lt;chr&gt;     &lt;dbl&gt;\n1 Laptop   1000. \n2 Mouse      29.5\n3 Keyboard   79  \n\n\nWenn die Umwandlung fehlschlägt, weil der Text keine gültige Zahl enthält, erzeugt R ein NA und gibt eine Warnung aus. Das ist ein nützliches Signal, dass etwas mit den Daten nicht stimmt.\nZahlen in Text\nDer umgekehrte Weg funktioniert mit as.character(). Das braucht ihr seltener, aber manchmal wollt ihr eine ID-Spalte, die zufällig nur aus Ziffern besteht, explizit als Text behandeln:\n\ntweets |&gt;\n  mutate(id = as.character(id)) |&gt;\n  select(id) |&gt;\n  head(3)\n\n# A tibble: 3 × 1\n  id                 \n  &lt;chr&gt;              \n1 1642251945732653057\n2 1642416819003707397\n3 1642082629796216834\n\n\nWerte in Faktoren\nFaktoren sind Rs Art, kategoriale Daten darzustellen, also Spalten mit einer begrenzten Anzahl möglicher Werte. Wenn ihr im Kapitel zur Datenrepräsentation aufgepasst habt, erinnert ihr euch: Faktoren haben ein festes Set von Levels, und die Reihenfolge dieser Levels kann bei Auswertungen und Visualisierungen eine Rolle spielen.\nMit as.factor() wandelt ihr eine Spalte einfach um:\n\ntweets |&gt;\n  mutate(lang = as.factor(lang)) |&gt;\n  select(lang) |&gt;\n  glimpse()\n\nRows: 58,421\nColumns: 1\n$ lang &lt;fct&gt; de, en, de, de, qme, de, de, de, de, de, qme, de, de, de, de, de,…\n\n\nAber warum ist die Reihenfolge der Levels so wichtig? Schauen wir uns das an einem Beispiel an. Stellt euch vor, ihr habt Umfragedaten mit einer Zufriedenheitsskala:\n\nsurvey &lt;- tibble(\n  satisfaction = c(\n    \"very satisfied\", \"satisfied\", \"neutral\", \"dissatisfied\",\n    \"satisfied\", \"very satisfied\", \"neutral\", \"satisfied\",\n    \"dissatisfied\", \"very dissatisfied\", \"satisfied\", \"neutral\"\n  )\n)\n\nWenn ihr diese Daten ohne Faktor in einem Balkendiagramm darstellt, sortiert R die Kategorien alphabetisch. Das Ergebnis ist inhaltlich unsinnig:\n\nlibrary(ggplot2)\n\nggplot(survey, aes(x = satisfaction)) +\n  geom_bar() +\n  labs(x = \"Zufriedenheit\", y = \"Anzahl\")\n\n\n\n\n\n\nAbbildung 9.1: Ohne Faktor sortiert R die Kategorien alphabetisch.\n\n\n\n\n“dissatisfied” steht vor “neutral”, “very dissatisfied” steht irgendwo am Ende. Die Reihenfolge hat keinen inhaltlichen Sinn. Jetzt wandeln wir die Spalte in einen geordneten Faktor um:\n\nsurvey &lt;- survey |&gt;\n  mutate(\n    satisfaction = factor(\n      satisfaction,\n      levels = c(\n        \"very dissatisfied\", \"dissatisfied\", \"neutral\", \n        \"satisfied\", \"very satisfied\"\n      )\n    )\n  )\n\nUnd erstellen das gleiche Diagramm noch einmal:\n\nggplot(survey, aes(x = satisfaction)) +\n  geom_bar() +\n  labs(x = \"Zufriedenheit\", y = \"Anzahl\")\n\n\n\n\n\n\nAbbildung 9.2: Mit einem geordneten Faktor erscheinen die Kategorien in der richtigen Reihenfolge.\n\n\n\n\nJetzt stimmt die Reihenfolge: von “very dissatisfied” bis “very satisfied”, genau wie auf einer Likert-Skala. Das ist der Grund, warum Faktoren bei ordinalen Variablen so wichtig sind. Ohne sie verliert ihr die inhaltliche Ordnung.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Variablen verändern</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/mutate-modify.html#sec-mutate-modify-umkodieren",
    "href": "03-data-transformation/mutate-modify.html#sec-mutate-modify-umkodieren",
    "title": "9  Variablen verändern",
    "section": "\n9.3 Werte umkodieren",
    "text": "9.3 Werte umkodieren\nHäufig müsst ihr die Werte einer Spalte in andere Werte übersetzen. Vielleicht liegen Kategorien als kryptische Codes vor, oder ihr wollt Wertebereiche zu Gruppen zusammenfassen. Dafür gibt es in R mehrere Werkzeuge.\nEinfache Bedingung mit if_else()\n\nWenn es nur zwei Möglichkeiten gibt, reicht if_else():\n\ntweets |&gt;\n  mutate(is_retweet = if_else(is_retweet, \"Retweet\", \"Original\")) |&gt;\n  select(screen_name, is_retweet, text) |&gt;\n  head(5)\n\n# A tibble: 5 × 3\n  screen_name  is_retweet text                                                  \n  &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;                                                 \n1 cem_oezdemir Retweet    \"RT @BriHasselmann: Endlich! Wir sind drangeblieben. …\n2 W_Schmidt_   Retweet    \"RT @aakashg0: Twitter revealed its algorithm to the …\n3 lisapaus     Original   \"@HassoSuliak @Storch_i @tagesschau Die EU Richtlinie…\n4 lisapaus     Original   \"@andiewoerle @svenlehmann Nein, sie werden nicht ver…\n5 Wissing      Original   \"\\U0001f449 https://t.co/NTFHy7j9AT\"                  \n\n\nif_else() prüft eine Bedingung und gibt je nach Ergebnis den einen oder den anderen Wert zurück. Hier haben wir die logische Spalte is_retweet (mit den Werten TRUE und FALSE) in lesbare Textlabels umgewandelt. Achtet darauf, dass beide Werte denselben Datentyp haben müssen.\nMehrere Bedingungen mit case_when()\n\nWenn ihr mehr als zwei Fälle unterscheiden müsst, ist case_when() die richtige Wahl. Es funktioniert wie eine Reihe von “wenn … dann”-Regeln, die der Reihe nach geprüft werden:\n\ntweets |&gt;\n  mutate(\n    source = case_when(\n      str_detect(source, \"iPhone\")  ~ \"Mobile (iOS)\",\n      str_detect(source, \"Android\") ~ \"Mobile (Android)\",\n      str_detect(source, \"Web\")     ~ \"Web\",\n      .default = \"Other\"\n    )\n  ) |&gt;\n  select(screen_name, source) |&gt;\n  head(10)\n\n# A tibble: 10 × 2\n   screen_name  source      \n   &lt;chr&gt;        &lt;chr&gt;       \n 1 cem_oezdemir Mobile (iOS)\n 2 W_Schmidt_   Mobile (iOS)\n 3 lisapaus     Mobile (iOS)\n 4 lisapaus     Mobile (iOS)\n 5 Wissing      Mobile (iOS)\n 6 Wissing      Mobile (iOS)\n 7 Wissing      Mobile (iOS)\n 8 c_lindner    Web         \n 9 lisapaus     Mobile (iOS)\n10 lisapaus     Mobile (iOS)\n\n\nDie Reihenfolge ist wichtig: Die erste Bedingung, die zutrifft, gewinnt. .default fängt alles auf, was keine der Bedingungen erfüllt. Ohne .default werden nicht abgedeckte Fälle zu NA.\n\n\n\n\n\n\nTippReihenfolge bei case_when()\n\n\n\nPrüft die speziellsten Bedingungen zuerst. Wenn ihr retweet_count &gt;= 10 vor retweet_count &gt;= 1000 schreibt, werden alle Tweets mit mehr als 10 Retweets sofort als “medium” eingestuft, und die Bedingung für “viral” wird nie erreicht.\n\n\nWerte direkt ersetzen mit case_match()\n\nWenn ihr einzelne Werte direkt in andere übersetzen wollt, ist case_match() besonders übersichtlich. Stellt es euch wie eine Übersetzungstabelle vor:\n\ntweets |&gt;\n  mutate(\n    lang = case_match(\n      lang,\n      \"de\" ~ \"German\",\n      \"en\" ~ \"English\",\n      \"fr\" ~ \"French\",\n      .default = \"Other\"\n    )\n  ) |&gt;\n  select(screen_name, lang) |&gt;\n  head(5)\n\n# A tibble: 5 × 2\n  screen_name  lang   \n  &lt;chr&gt;        &lt;chr&gt;  \n1 cem_oezdemir German \n2 W_Schmidt_   English\n3 lisapaus     German \n4 lisapaus     German \n5 Wissing      Other  \n\n\nDer Unterschied zu case_when() ist, dass case_match() direkt Werte vergleicht statt Bedingungen zu prüfen. Das macht den Code kürzer und lesbarer, wenn es um einfache Zuordnungen geht.\nAbbildung: Eine zweispaltige Tabelle mit dem Titel “case_match()”. Links steht “Originalwert” mit den Einträgen “de”, “en”, “fr”, “sonstige”. Rechts steht “Neuer Wert” mit den Einträgen “German”, “English”, “French”, “Other”. Pfeile verbinden jeweils linke und rechte Seite. Unter der Tabelle steht ein kurzer R-Code-Schnipsel, der das Muster zeigt.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Variablen verändern</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/mutate-modify.html#sec-mutate-modify-einheiten",
    "href": "03-data-transformation/mutate-modify.html#sec-mutate-modify-einheiten",
    "title": "9  Variablen verändern",
    "section": "\n9.4 Einheiten umrechnen",
    "text": "9.4 Einheiten umrechnen\nManchmal liegen eure Daten in der falschen Einheit vor. Vielleicht sind Preise in Cent statt in Euro, Gewichte in Pfund statt in Kilogramm oder Temperaturen in Fahrenheit statt in Celsius. Solche Umrechnungen sind einfache arithmetische Operationen in mutate():\n\nweather_data &lt;- tibble(\n  city = c(\"Berlin\", \"Munich\", \"Hamburg\"),\n  temp_fahrenheit = c(68, 72, 59)\n)\n\nweather_data |&gt;\n  mutate(temp_fahrenheit = (temp_fahrenheit - 32) * 5 / 9)\n\n# A tibble: 3 × 2\n  city    temp_fahrenheit\n  &lt;chr&gt;             &lt;dbl&gt;\n1 Berlin             20  \n2 Munich             22.2\n3 Hamburg            15  \n\n\nBeachtet, dass wir die Spalte hier überschreiben. Der Name temp_fahrenheit passt nach der Umrechnung natürlich nicht mehr. In der Praxis würdet ihr die Spalte gleichzeitig umbenennen oder eine neue Spalte anlegen. Hier überschreiben wir sie der Einfachheit halber.\nDas Gleiche funktioniert für Preise:\n\norders |&gt;\n  mutate(total_price = total_price / 100) |&gt;\n  select(order_id, total_price) |&gt;\n  head(5)\n\n# A tibble: 5 × 2\n       order_id total_price\n          &lt;dbl&gt;       &lt;dbl&gt;\n1 1130007101519       0.947\n2 1130014965839       0.322\n3 1130026958927       0.302\n4 1130030563407       0.322\n5 1130038853711       0.302",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Variablen verändern</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/mutate-modify.html#sec-mutate-modify-korrigieren",
    "href": "03-data-transformation/mutate-modify.html#sec-mutate-modify-korrigieren",
    "title": "9  Variablen verändern",
    "section": "\n9.5 Werte korrigieren",
    "text": "9.5 Werte korrigieren\nIn echten Datensätzen finden sich immer wieder Tippfehler, uneinheitliche Schreibweisen oder andere kleine Fehler. Stellt euch vor, ihr habt eine Spalte mit Städtenamen, in der “Osnabrück” manchmal als “Osnabrueck” oder “osnabrück” geschrieben wurde. Solche Inkonsistenzen müsst ihr bereinigen, bevor ihr die Daten gruppieren oder filtern könnt.\nEinzelne Werte ersetzen\nFür gezielte Korrekturen eignet sich case_match(), das ihr schon kennt:\n\ncity_data &lt;- tibble(\n  city = c(\"Berlin\", \"Muenchen\", \"berlin\", \"München\", \"Berln\")\n)\n\ncity_data |&gt;\n  mutate(\n    city = case_match(\n      city,\n      \"Muenchen\" ~ \"München\",\n      \"berlin\" ~ \"Berlin\",\n      \"Berln\" ~ \"Berlin\",\n      .default = city\n    )\n  )\n\n# A tibble: 5 × 1\n  city   \n  &lt;chr&gt;  \n1 Berlin \n2 München\n3 Berlin \n4 München\n5 Berlin \n\n\nBeachtet das .default = city: Alle Werte, die nicht explizit genannt sind, bleiben unverändert.\nMuster ersetzen mit str_replace()\n\nWenn das Problem systematischer ist, hilft str_replace() aus dem Paket stringr. Damit ersetzt ihr Teilstrings, die einem Muster entsprechen:\n\nurl_data &lt;- tibble(\n  url = c(\"http://example.com\", \"http://test.org\", \"https://secure.net\")\n)\n\nurl_data |&gt;\n  mutate(url = str_replace(url, \"^http://\", \"https://\"))\n\n# A tibble: 3 × 1\n  url                \n  &lt;chr&gt;              \n1 https://example.com\n2 https://test.org   \n3 https://secure.net \n\n\nstr_replace() ersetzt nur das erste Vorkommen. Wenn ihr alle Vorkommen ersetzen wollt, nutzt str_replace_all().",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Variablen verändern</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/mutate-modify.html#sec-mutate-modify-na",
    "href": "03-data-transformation/mutate-modify.html#sec-mutate-modify-na",
    "title": "9  Variablen verändern",
    "section": "\n9.6 Fehlende Werte ersetzen",
    "text": "9.6 Fehlende Werte ersetzen\nFehlende Werte (NA) sind in der Datenanalyse unvermeidlich. Manchmal stören sie aber bei Berechnungen oder Visualisierungen. Dann wollt ihr sie durch einen Ersatzwert ersetzen.\nreplace_na()\nDie direkteste Methode ist replace_na() aus dem Paket tidyr:\n\ntweets |&gt;\n  mutate(in_reply_to_screen_name = replace_na(in_reply_to_screen_name, \"unknown\")) |&gt;\n  select(screen_name, in_reply_to_screen_name) |&gt;\n  head(5)\n\n# A tibble: 5 × 2\n  screen_name  in_reply_to_screen_name\n  &lt;chr&gt;        &lt;chr&gt;                  \n1 cem_oezdemir unknown                \n2 W_Schmidt_   unknown                \n3 lisapaus     HassoSuliak            \n4 lisapaus     andiewoerle            \n5 Wissing      Wissing                \n\n\n\ncoalesce() für Ersatzwerte aus mehreren Spalten\nManchmal wollt ihr einen fehlenden Wert durch den Wert einer anderen Spalte ersetzen. Dafür gibt es coalesce(). Es nimmt den ersten nicht-fehlenden Wert aus einer Reihe von Spalten:\n\ndata_with_gaps &lt;- tibble(\n  primary_email = c(\"anna@example.com\", NA, \"cleo@example.com\"),\n  backup_email = c(\"anna2@example.com\", \"ben@example.com\", NA)\n)\n\ndata_with_gaps |&gt;\n  mutate(email = coalesce(primary_email, backup_email))\n\n# A tibble: 3 × 3\n  primary_email    backup_email      email           \n  &lt;chr&gt;            &lt;chr&gt;             &lt;chr&gt;           \n1 anna@example.com anna2@example.com anna@example.com\n2 &lt;NA&gt;             ben@example.com   ben@example.com \n3 cleo@example.com &lt;NA&gt;              cleo@example.com\n\n\ncoalesce() prüft von links nach rechts und nimmt den ersten Wert, der nicht NA ist. Das ist besonders nützlich, wenn ihr mehrere Quellen für denselben Wert habt.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Variablen verändern</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/mutate-modify.html#sec-mutate-modify-text",
    "href": "03-data-transformation/mutate-modify.html#sec-mutate-modify-text",
    "title": "9  Variablen verändern",
    "section": "\n9.7 Text normalisieren",
    "text": "9.7 Text normalisieren\nTextdaten sind oft uneinheitlich: Groß- und Kleinschreibung variiert, es gibt überflüssige Leerzeichen oder unerwünschte Sonderzeichen. Bevor ihr Texte analysieren könnt, müsst ihr sie normalisieren. Dafür bietet das Paket stringr eine Reihe von Funktionen.\nGroß- und Kleinschreibung\nMit str_to_lower() wandelt ihr alles in Kleinbuchstaben um. Das ist besonders wichtig, wenn ihr später nach Wörtern suchen oder Texte gruppieren wollt:\n\ntweets |&gt;\n  mutate(text = str_to_lower(text)) |&gt;\n  select(text) |&gt;\n  head(3)\n\n# A tibble: 3 × 1\n  text                                                                          \n  &lt;chr&gt;                                                                         \n1 rt @brihasselmann: endlich! wir sind drangeblieben. die #tierhaltungskennzeic…\n2 rt @aakashg0: twitter revealed its algorithm to the world. but what does it m…\n3 @hassosuliak @storch_i @tagesschau die eu richtlinie ist bereits umgesetzt. u…\n\n\nDaneben gibt es str_to_upper() für Großbuchstaben und str_to_title() für die Großschreibung am Wortanfang.\nLeerzeichen bereinigen\nstr_trim() entfernt Leerzeichen am Anfang und Ende eines Texts. str_squish() geht einen Schritt weiter und fasst auch mehrere Leerzeichen innerhalb eines Texts zu einem einzigen zusammen:\n\nmessy_data &lt;- tibble(\n  name = c(\"  Anna  \", \"Ben\", \"  Cleo   Doe  \")\n)\n\nmessy_data |&gt;\n  mutate(name = str_squish(name))\n\n# A tibble: 3 × 1\n  name    \n  &lt;chr&gt;   \n1 Anna    \n2 Ben     \n3 Cleo Doe\n\n\nSonderzeichen entfernen\nWenn ihr Texte für eine Analyse vorbereiten wollt, kann es sinnvoll sein, Satzzeichen oder andere Sonderzeichen zu entfernen. Dafür nutzt ihr str_remove_all():\n\ntweets |&gt;\n  mutate(text = str_remove_all(text, \"[[:punct:]]\")) |&gt;\n  select(text) |&gt;\n  head(3)\n\n# A tibble: 3 × 1\n  text                                                                          \n  &lt;chr&gt;                                                                         \n1 RT BriHasselmann Endlich Wir sind drangeblieben Die Tierhaltungskennzeichnung…\n2 RT aakashg0 Twitter revealed its algorithm to the world But what does it mean…\n3 HassoSuliak Storchi tagesschau Die EU Richtlinie ist bereits umgesetzt Und es…\n\n\nDas Muster [[:punct:]] steht für alle gängigen Satzzeichen. Wenn ihr nur bestimmte Zeichen entfernen wollt, gebt sie direkt an, zum Beispiel str_remove_all(text, \"#\") für Hashtag-Symbole.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Variablen verändern</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/mutate-modify.html#sec-mutate-modify-runden",
    "href": "03-data-transformation/mutate-modify.html#sec-mutate-modify-runden",
    "title": "9  Variablen verändern",
    "section": "\n9.8 Zahlen runden",
    "text": "9.8 Zahlen runden\nBeim Arbeiten mit Dezimalzahlen wollt ihr die Werte manchmal runden, sei es für eine übersichtlichere Ausgabe oder weil Nachkommastellen in eurem Kontext keine Rolle spielen.\n\norders |&gt;\n  mutate(total_price = round(total_price, 2)) |&gt;\n  select(order_id, total_price) |&gt;\n  head(5)\n\n# A tibble: 5 × 2\n       order_id total_price\n          &lt;dbl&gt;       &lt;dbl&gt;\n1 1130007101519        94.7\n2 1130014965839        32.2\n3 1130026958927        30.2\n4 1130030563407        32.2\n5 1130038853711        30.2\n\n\nNeben round() gibt es floor() (abrunden auf die nächste ganze Zahl) und ceiling() (aufrunden). Diese Funktionen sind nützlich, wenn ihr zum Beispiel Altersangaben aus Geburtsdaten berechnet und immer auf ganze Jahre abrunden wollt.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Variablen verändern</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/mutate-modify.html#sec-mutate-modify-across",
    "href": "03-data-transformation/mutate-modify.html#sec-mutate-modify-across",
    "title": "9  Variablen verändern",
    "section": "\n9.9 Mehrere Variablen ändern",
    "text": "9.9 Mehrere Variablen ändern\nBisher haben wir immer eine Spalte nach der anderen verändert. Was aber, wenn ihr dieselbe Transformation auf mehrere Spalten gleichzeitig anwenden wollt? Dafür gibt es across().\n\ntweets |&gt;\n  mutate(across(c(retweet_count, favorite_count), as.double)) |&gt;\n  select(retweet_count, favorite_count) |&gt;\n  glimpse()\n\nRows: 58,421\nColumns: 2\n$ retweet_count  &lt;dbl&gt; 23, 10659, 1, 1, 6, 9, 15, 56, 29, 1, 1, 1, 10, 13, 26,…\n$ favorite_count &lt;dbl&gt; 0, 0, 3, 11, 25, 93, 154, 448, 0, 1, 2, 2, 58, 103, 266…\n\n\nacross() nimmt zwei Argumente: die Spaltenauswahl und die Funktion, die auf jede Spalte angewendet werden soll. Für die Spaltenauswahl könnt ihr die gleichen Helfer nutzen, die ihr von select() kennt:\n\ntweets |&gt;\n  mutate(across(where(is.character), str_to_lower)) |&gt;\n  select(where(is.character)) |&gt;\n  head(3)\n\n# A tibble: 3 × 11\n  id           screen_name text  retweeted_status_id retweeted_user lang  source\n  &lt;chr&gt;        &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt; &lt;chr&gt; \n1 16422519457… cem_oezdem… rt @… 1642158717113081856 brihasselmann  de    \"&lt;a h…\n2 16424168190… w_schmidt_  rt @… 1641976869460275201 aakashg0       en    \"&lt;a h…\n3 16420826297… lisapaus    @has… &lt;NA&gt;                &lt;NA&gt;           de    \"&lt;a h…\n# ℹ 4 more variables: insert_timestamp &lt;chr&gt;, in_reply_to_screen_name &lt;chr&gt;,\n#   in_reply_to_status_id &lt;chr&gt;, quoted_status_id &lt;chr&gt;\n\n\nHier haben wir alle Text-Spalten auf einmal in Kleinbuchstaben umgewandelt. Ohne across() müsstet ihr für jede Spalte eine eigene Zeile schreiben.\n\n\n\n\n\n\nTippacross() mit eigenen Funktionen\n\n\n\nWenn eure Transformation komplexer ist, könnt ihr auch eine anonyme Funktion übergeben: across(where(is.numeric), \\(x) round(x, 2)) rundet alle numerischen Spalten auf zwei Nachkommastellen.\n\n\nAbbildung: Ein Datensatz als Tabelle mit fünf Spalten. Drei davon sind farblich hervorgehoben (zum Beispiel alle numerischen). Darunter steht der Code mutate(across(where(is.numeric), round)). Ein Pfeil zeigt von den hervorgehobenen Spalten auf die gleiche Tabelle, in der die Werte dieser drei Spalten gerundet sind. Der Fokus liegt darauf, dass across() die gleiche Funktion auf mehrere Spalten anwendet.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Variablen verändern</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/mutate-modify.html#sec-mutate-modify-zusammenfassung",
    "href": "03-data-transformation/mutate-modify.html#sec-mutate-modify-zusammenfassung",
    "title": "9  Variablen verändern",
    "section": "\n9.10 Kurz zusammengefasst",
    "text": "9.10 Kurz zusammengefasst\n\nMit rename() und rename_with() benennt ihr Spalten um.\n\nmutate() verändert bestehende Spalten, indem ihr den gleichen Spaltennamen links und rechts verwendet.\nDatentypen wandelt ihr mit as.double(), as.character(), as.factor() und verwandten Funktionen um.\nWerte kodiert ihr mit if_else(), case_when() und case_match() um.\nFehlende Werte ersetzt ihr mit replace_na() oder coalesce().\nText normalisiert ihr mit str_to_lower(), str_trim(), str_squish() und str_remove_all().\nMit across() wendet ihr dieselbe Transformation auf mehrere Spalten gleichzeitig an.\n\nJetzt wisst ihr, wie ihr bestehende Spalten in Form bringt. Im nächsten Kapitel geht es darum, aus vorhandenen Daten neue Variablen zu berechnen (siehe Kapitel 10).",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Variablen verändern</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/mutate-add.html",
    "href": "03-data-transformation/mutate-add.html",
    "title": "10  Variablen erstellen",
    "section": "",
    "text": "10.1 Neue Variablen berechnen\nIm vorherigen Kapitel habt ihr gelernt, wie ihr bestehende Variablen verändert und repariert. Jetzt gehen wir den nächsten logischen Schritt: Neue Variablen anlegen. In diesem Kapitel lernt ihr, wie ihr mit mutate() aus zwei oder mehr Spalten eine völlig neue berechnet, Kategorien aus numerischen Werten ableitet und laufende Summen oder Ränge aufbaut. Der Unterschied zum vorherigen Kapitel ist konzeptionell einfach: Wenn ihr bei mutate() links vom Gleichheitszeichen einen Namen verwendet, der im Datensatz noch nicht existiert, wird die Spalte neu angehängt.\nIn vielen quantitativen Projekten enthalten die rohen Daten nicht direkt die Kennzahlen, die ihr für eure Forschungsfrage benötigt. Ihr müsst sie erst berechnen – seien es Altersgruppen aus Geburtsjahren, prozentuale Anteile aus absoluten Zahlen oder textuelle Zusammenfassungen aus Einzelstrings. Die Fähigkeit, gezielt neue Metriken zu synthetisieren, erweitert eure Analysemöglichkeiten enorm und macht eure Visualisierungen später deutlich aussagekräftiger.\nDie einfachste Form: Ihr rechnet mit bestehenden Spalten und gebt dem Ergebnis einen neuen Namen.\ntweets |&gt;\n  mutate(total_engagement = retweet_count + favorite_count) |&gt;\n  select(screen_name, retweet_count, favorite_count, total_engagement) |&gt;\n  head(5)\n\n# A tibble: 5 × 4\n  screen_name  retweet_count favorite_count total_engagement\n  &lt;chr&gt;                &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1 cem_oezdemir            23              0               23\n2 W_Schmidt_           10659              0            10659\n3 lisapaus                 1              3                4\n4 lisapaus                 1             11               12\n5 Wissing                  6             25               31\nHier entsteht die neue Spalte total_engagement als Summe von Retweets und Likes. Die bestehenden Spalten bleiben vollständig erhalten.\nIhr könnt in einem einzigen mutate()-Aufruf auch mehrere neue Variablen gleichzeitig anlegen. Dabei könnt ihr sogar auf Variablen zugreifen, die ihr gerade erst erstellt habt:\ntweets |&gt;\n  mutate(\n    total_engagement = retweet_count + favorite_count,\n    engagement_ratio = retweet_count / total_engagement\n  ) |&gt;\n  select(screen_name, total_engagement, engagement_ratio) |&gt;\n  head(5)\n\n# A tibble: 5 × 3\n  screen_name  total_engagement engagement_ratio\n  &lt;chr&gt;                   &lt;dbl&gt;            &lt;dbl&gt;\n1 cem_oezdemir               23           1     \n2 W_Schmidt_              10659           1     \n3 lisapaus                    4           0.25  \n4 lisapaus                   12           0.0833\n5 Wissing                    31           0.194\nengagement_ratio greift auf total_engagement zu, obwohl diese Spalte erst in der Zeile darüber definiert wurde. Das funktioniert, weil mutate() die neuen Variablen von oben nach unten abarbeitet.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Variablen erstellen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/mutate-add.html#sec-mutate-add-berechnen",
    "href": "03-data-transformation/mutate-add.html#sec-mutate-add-berechnen",
    "title": "10  Variablen erstellen",
    "section": "",
    "text": "TippDivision durch Null\n\n\n\nWenn total_engagement den Wert 0 hat, liefert die Division Inf (unendlich). In der Praxis wollt ihr solche Fälle abfangen, zum Beispiel mit if_else(total_engagement == 0, 0, retweet_count / total_engagement).",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Variablen erstellen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/mutate-add.html#sec-mutate-add-text",
    "href": "03-data-transformation/mutate-add.html#sec-mutate-add-text",
    "title": "10  Variablen erstellen",
    "section": "\n10.2 Textuelle Variablen",
    "text": "10.2 Textuelle Variablen\nNeben arithmetischen Berechnungen könnt ihr auch neue Textspalten zusammensetzen. Die Funktion str_c() aus stringr fügt mehrere Werte zu einem einzigen String zusammen:\n\ntweets |&gt;\n  mutate(label = str_c(screen_name, \": \", text)) |&gt;\n  select(label) |&gt;\n  head(3)\n\n# A tibble: 3 × 1\n  label                                                                         \n  &lt;chr&gt;                                                                         \n1 cem_oezdemir: RT @BriHasselmann: Endlich! Wir sind drangeblieben. Die #Tierha…\n2 W_Schmidt_: RT @aakashg0: Twitter revealed its algorithm to the world. But wh…\n3 lisapaus: @HassoSuliak @Storch_i @tagesschau Die EU Richtlinie ist bereits um…\n\n\nEin häufiger Anwendungsfall ist das Erstellen lesbarer Labels für Diagramme oder Berichte. Wenn ihr Werte mit einem Trennzeichen zusammenfügen wollt, nutzt den Parameter sep:\n\ntweets |&gt;\n  mutate(\n    info = str_c(screen_name, retweet_count, sep = \" | \")\n  ) |&gt;\n  select(info) |&gt;\n  head(3)\n\n# A tibble: 3 × 1\n  info              \n  &lt;chr&gt;             \n1 cem_oezdemir | 23 \n2 W_Schmidt_ | 10659\n3 lisapaus | 1",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Variablen erstellen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/mutate-add.html#sec-mutate-add-bedingt",
    "href": "03-data-transformation/mutate-add.html#sec-mutate-add-bedingt",
    "title": "10  Variablen erstellen",
    "section": "\n10.3 Bedingte Variablen",
    "text": "10.3 Bedingte Variablen\nOft hängt der Wert einer neuen Spalte von einer Bedingung ab. Das kennt ihr bereits aus dem vorherigen Kapitel. Hier erstellen wir aber eine neue Variable, statt eine bestehende zu verändern.\nZwei Fälle mit if_else()\n\n\ntweets |&gt;\n  mutate(is_popular = if_else(retweet_count &gt;= 100, \"popular\", \"normal\")) |&gt;\n  select(screen_name, retweet_count, is_popular) |&gt;\n  head(5)\n\n# A tibble: 5 × 3\n  screen_name  retweet_count is_popular\n  &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;     \n1 cem_oezdemir            23 normal    \n2 W_Schmidt_           10659 popular   \n3 lisapaus                 1 normal    \n4 lisapaus                 1 normal    \n5 Wissing                  6 normal    \n\n\nMehrere Fälle mit case_when()\n\n\ntweets |&gt;\n  mutate(\n    engagement_level = case_when(\n      retweet_count &gt;= 1000 ~ \"viral\",\n      retweet_count &gt;= 100  ~ \"high\",\n      retweet_count &gt;= 10   ~ \"medium\",\n      .default = \"low\"\n    )\n  ) |&gt;\n  select(screen_name, retweet_count, engagement_level) |&gt;\n  head(10)\n\n# A tibble: 10 × 3\n   screen_name  retweet_count engagement_level\n   &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;           \n 1 cem_oezdemir            23 medium          \n 2 W_Schmidt_           10659 viral           \n 3 lisapaus                 1 low             \n 4 lisapaus                 1 low             \n 5 Wissing                  6 low             \n 6 Wissing                  9 low             \n 7 Wissing                 15 medium          \n 8 c_lindner               56 medium          \n 9 lisapaus                29 medium          \n10 lisapaus                 1 low             \n\n\nDie Reihenfolge der Bedingungen ist entscheidend: Die erste zutreffende Bedingung gewinnt. Wenn ihr die speziellsten Fälle nicht zuerst nennt, werden sie von allgemeineren Bedingungen überschattet.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Variablen erstellen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/mutate-add.html#sec-mutate-add-fenster",
    "href": "03-data-transformation/mutate-add.html#sec-mutate-add-fenster",
    "title": "10  Variablen erstellen",
    "section": "\n10.4 Fensterfunktionen",
    "text": "10.4 Fensterfunktionen\nFensterfunktionen sind Funktionen, die für jede Zeile einen Wert berechnen, aber dabei die umliegenden Zeilen berücksichtigen. Im Gegensatz zu Aggregatfunktionen wie sum() oder mean(), die einen Datensatz auf einen einzigen Wert reduzieren, geben Fensterfunktionen für jede Zeile einen eigenen Wert zurück. Der Datensatz behält also seine Länge.\nVorherige und nächste Werte mit lag() und lead()\n\nMit lag() greift ihr auf den Wert der vorherigen Zeile zu, mit lead() auf den der nächsten. Das ist besonders nützlich für Zeitreihendaten, wenn ihr Veränderungen zwischen aufeinanderfolgenden Einträgen berechnen wollt.\n\norders |&gt;\n  arrange(created_at) |&gt;\n  mutate(\n    previous_price = lag(total_price),\n    price_change = total_price - lag(total_price)\n  ) |&gt;\n  select(order_id, created_at, total_price, previous_price, price_change) |&gt;\n  head(5)\n\n# A tibble: 5 × 5\n       order_id created_at          total_price previous_price price_change\n          &lt;dbl&gt; &lt;dttm&gt;                    &lt;dbl&gt;          &lt;dbl&gt;        &lt;dbl&gt;\n1 1130007101519 2019-05-24 12:59:16        94.7           NA           NA  \n2 1130014965839 2019-05-24 13:09:08        32.2           94.7        -62.4\n3 1130026958927 2019-05-24 13:22:41        30.2           32.2         -2  \n4 1130030563407 2019-05-24 13:27:43        32.2           30.2          2  \n5 1130038853711 2019-05-24 13:36:46        30.2           32.2         -2  \n\n\nBeachtet, dass die erste Zeile für lag() immer NA liefert, weil es keinen Vorgänger gibt. Genauso liefert lead() für die letzte Zeile NA.\n\n\n\n\n\n\nTippSortierung ist entscheidend\n\n\n\nlag() und lead() arbeiten auf der aktuellen Zeilenreihenfolge. Wenn eure Daten nicht sortiert sind, liefern sie unsinnige Ergebnisse. Sortiert deshalb vorher mit arrange().\n\n\nLaufende Summen und Durchschnitte\nLaufende (kumulative) Berechnungen bauen Schritt für Schritt auf: Jede Zeile enthält die Summe, den Mittelwert oder das Maximum aller bisherigen Werte.\n\norders |&gt;\n  arrange(created_at) |&gt;\n  mutate(\n    cumulative_revenue = cumsum(total_price),\n    running_avg_price = cummean(total_price)\n  ) |&gt;\n  select(order_id, total_price, cumulative_revenue, running_avg_price) |&gt;\n  head(10)\n\n# A tibble: 10 × 4\n        order_id total_price cumulative_revenue running_avg_price\n           &lt;dbl&gt;       &lt;dbl&gt;              &lt;dbl&gt;             &lt;dbl&gt;\n 1 1130007101519        94.7               94.7              94.7\n 2 1130014965839        32.2              127.               63.4\n 3 1130026958927        30.2              157.               52.4\n 4 1130030563407        32.2              189.               47.3\n 5 1130038853711        30.2              220.               43.9\n 6 1130045964367        30.2              250.               41.6\n 7 1130050519119        30.2              280.               40.0\n 8 1130060283983        32.2              312.               39.0\n 9 1130102194255        96.7              409.               45.4\n10 1130106880079        32.2              441.               44.1\n\n\nDie wichtigsten kumulativen Funktionen:\n\n\nFunktion\nBeschreibung\n\n\n\ncumsum()\nLaufende Summe\n\n\ncummean()\nLaufender Durchschnitt\n\n\ncummax()\nLaufendes Maximum\n\n\ncummin()\nLaufendes Minimum\n\n\nRangfolgen\nWenn ihr Zeilen nach einem Wert ranken wollt, gibt es mehrere Funktionen. Der Unterschied liegt im Umgang mit Gleichständen:\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  mutate(rank = min_rank(desc(retweet_count))) |&gt;\n  select(screen_name, retweet_count, rank) |&gt;\n  arrange(rank) |&gt;\n  head(10)\n\n# A tibble: 10 × 3\n   screen_name     retweet_count  rank\n   &lt;chr&gt;                   &lt;dbl&gt; &lt;int&gt;\n 1 Bundeskanzler           12652     1\n 2 Bundeskanzler            8032     2\n 3 ABaerbockArchiv          7152     3\n 4 ABaerbock                5407     4\n 5 Karl_Lauterbach          5363     5\n 6 Karl_Lauterbach          5121     6\n 7 Karl_Lauterbach          4636     7\n 8 Karl_Lauterbach          4574     8\n 9 Karl_Lauterbach          4102     9\n10 ABaerbock                3987    10\n\n\nmin_rank() vergibt bei Gleichstand denselben Rang und lässt danach Plätze aus (wie bei einem Sportwettbewerb: Platz 1, 1, 3). dense_rank() lässt dagegen keine Plätze aus (Platz 1, 1, 2). row_number() vergibt jeden Rang nur einmal, die Reihenfolge bei Gleichstand ist aber willkürlich.\n\nexample &lt;- tibble(score = c(100, 90, 90, 80))\n\nexample |&gt;\n  mutate(\n    min_rank = min_rank(desc(score)),\n    dense_rank = dense_rank(desc(score)),\n    row_number = row_number(desc(score))\n  )\n\n# A tibble: 4 × 4\n  score min_rank dense_rank row_number\n  &lt;dbl&gt;    &lt;int&gt;      &lt;int&gt;      &lt;int&gt;\n1   100        1          1          1\n2    90        2          2          2\n3    90        2          2          3\n4    80        4          3          4\n\n\nAbbildung: Drei Spalten nebeneinander mit denselben vier Werten (100, 90, 90, 80). In der ersten Spalte steht die Rangfolge mit min_rank (1, 2, 2, 4). In der zweiten Spalte steht dense_rank (1, 2, 2, 3). In der dritten Spalte steht row_number (1, 2, 3, 4). Die Gleichstände bei 90 sind farblich hervorgehoben, um den Unterschied im Umgang mit Gleichständen zu zeigen.\nZeilennummern\nManchmal braucht ihr einfach eine fortlaufende Nummer für jede Zeile. Dafür gibt es row_number() ohne Argument:\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  arrange(desc(retweet_count)) |&gt;\n  mutate(position = row_number()) |&gt;\n  select(position, screen_name, retweet_count) |&gt;\n  head(5)\n\n# A tibble: 5 × 3\n  position screen_name     retweet_count\n     &lt;int&gt; &lt;chr&gt;                   &lt;dbl&gt;\n1        1 Bundeskanzler           12652\n2        2 Bundeskanzler            8032\n3        3 ABaerbockArchiv          7152\n4        4 ABaerbock                5407\n5        5 Karl_Lauterbach          5363",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Variablen erstellen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/mutate-add.html#sec-mutate-add-grouped",
    "href": "03-data-transformation/mutate-add.html#sec-mutate-add-grouped",
    "title": "10  Variablen erstellen",
    "section": "\n10.5 Gruppiertes Mutieren",
    "text": "10.5 Gruppiertes Mutieren\nHier wird es besonders spannend: Wenn ihr mutate() auf einen gruppierten Datensatz anwendet, werden die Berechnungen innerhalb jeder Gruppe durchgeführt. Das öffnet die Tür für Fragen wie “Wie verhält sich dieser Wert im Vergleich zu seiner Gruppe?”\n\n\nIn Kombination mit Gruppierung erzeugt mutate Berechnungen auf Gruppenebene, behält aber weiterhin jede Zeile.\n\nAnteile innerhalb von Gruppen\nStellt euch vor, ihr wollt wissen, wie viel Prozent der Gesamtinteraktion jeder Tweet innerhalb seines Accounts ausmacht:\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  group_by(screen_name) |&gt;\n  mutate(\n    account_total = sum(retweet_count),\n    share = retweet_count / account_total\n  ) |&gt;\n  select(screen_name, retweet_count, account_total, share) |&gt;\n  head(10)\n\n# A tibble: 10 × 4\n# Groups:   screen_name [4]\n   screen_name retweet_count account_total     share\n   &lt;chr&gt;               &lt;dbl&gt;         &lt;dbl&gt;     &lt;dbl&gt;\n 1 lisapaus                1         11658 0.0000858\n 2 lisapaus                1         11658 0.0000858\n 3 Wissing                 6         30608 0.000196 \n 4 Wissing                 9         30608 0.000294 \n 5 Wissing                15         30608 0.000490 \n 6 c_lindner              56        114113 0.000491 \n 7 lisapaus                1         11658 0.0000858\n 8 lisapaus                1         11658 0.0000858\n 9 lisapaus                1         11658 0.0000858\n10 NancyFaeser            10         52212 0.000192 \n\n\nOhne group_by() würde sum(retweet_count) die Summe über den gesamten Datensatz berechnen. Mit group_by() berechnet R die Summe separat für jeden Account. Die Spalte account_total hat also für alle Tweets desselben Accounts denselben Wert.\nAbbildung: Ein Datensatz als Tabelle mit drei Gruppen (farblich markiert, jeweils 3 Zeilen). Links: eine Spalte “value” mit Einzelwerten. Rechts: eine neue Spalte “group_sum” mit der Gruppensumme, die für alle Zeilen einer Gruppe identisch ist. Ein Pfeil zeigt, dass group_by() |&gt; mutate(group_sum = sum(value)) die Summe pro Gruppe berechnet und in jede Zeile schreibt, statt den Datensatz zu komprimieren.\nRang innerhalb von Gruppen\nAuch Rangfolgen funktionieren gruppiert:\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  group_by(screen_name) |&gt;\n  mutate(rank_within_account = min_rank(desc(retweet_count))) |&gt;\n  filter(rank_within_account == 1) |&gt;\n  select(screen_name, retweet_count, rank_within_account)\n\n# A tibble: 17 × 3\n# Groups:   screen_name [17]\n   screen_name     retweet_count rank_within_account\n   &lt;chr&gt;                   &lt;dbl&gt;               &lt;int&gt;\n 1 Wissing                   428                   1\n 2 ABaerbock                5407                   1\n 3 cem_oezdemir             2886                   1\n 4 ABaerbockArchiv          7152                   1\n 5 OlafScholz               2520                   1\n 6 Bundeskanzler           12652                   1\n 7 lisapaus                  676                   1\n 8 W_Schmidt_                401                   1\n 9 Karl_Lauterbach          5363                   1\n10 c_lindner                 833                   1\n11 SteffiLemke               839                   1\n12 starkwatzinger            662                   1\n13 NancyFaeser              3889                   1\n14 hubertus_heil             966                   1\n15 MarcoBuschmann           1066                   1\n16 SvenjaSchulze68           409                   1\n17 klara_geywitz             188                   1\n\n\nHier bekommt jeder Tweet einen Rang innerhalb seines Accounts. Das Filtern auf Rang 1 ergibt den meistretweeteten Tweet pro Account.\nLaufende Berechnungen pro Gruppe\nKumulative Funktionen in gruppierten Daten starten für jede Gruppe neu von Null:\n\norders |&gt;\n  arrange(created_at) |&gt;\n  group_by(financial_status) |&gt;\n  mutate(\n    cumulative_revenue = cumsum(total_price),\n    order_number_in_group = row_number()\n  ) |&gt;\n  select(financial_status, total_price, cumulative_revenue, order_number_in_group) |&gt;\n  head(10)\n\n# A tibble: 10 × 4\n# Groups:   financial_status [1]\n   financial_status total_price cumulative_revenue order_number_in_group\n   &lt;chr&gt;                  &lt;dbl&gt;              &lt;dbl&gt;                 &lt;int&gt;\n 1 paid                    94.7               94.7                     1\n 2 paid                    32.2              127.                      2\n 3 paid                    30.2              157.                      3\n 4 paid                    32.2              189.                      4\n 5 paid                    30.2              220.                      5\n 6 paid                    30.2              250.                      6\n 7 paid                    30.2              280.                      7\n 8 paid                    32.2              312.                      8\n 9 paid                    96.7              409.                      9\n10 paid                    32.2              441.                     10\n\n\n\n\n\n\n\n\nTippGruppierung entfernen\n\n\n\nVergesst nicht, die Gruppierung nach dem Mutieren mit ungroup() wieder aufzuheben, wenn ihr danach mit dem gesamten Datensatz weiterarbeiten wollt. Sonst wirken sich spätere Operationen weiterhin nur innerhalb der Gruppen aus.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Variablen erstellen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/mutate-add.html#sec-mutate-add-optionen",
    "href": "03-data-transformation/mutate-add.html#sec-mutate-add-optionen",
    "title": "10  Variablen erstellen",
    "section": "\n10.6 Optionen für mutate()\n",
    "text": "10.6 Optionen für mutate()\n\nStandardmäßig fügt mutate() neue Spalten ganz rechts an und behält alle bestehenden Spalten. Über drei Parameter könnt ihr dieses Verhalten anpassen: .before, .after und .keep.\nPosition neuer Spalten mit .before und .after\n\nWenn ihr die neue Spalte an einer bestimmten Stelle im Datensatz haben wollt, statt ganz am Ende, nutzt .before oder .after:\n\ntweets |&gt;\n  mutate(\n    total_engagement = retweet_count + favorite_count,\n    .after = screen_name\n  ) |&gt;\n  select(screen_name, total_engagement, retweet_count, favorite_count) |&gt;\n  head(3)\n\n# A tibble: 3 × 4\n  screen_name  total_engagement retweet_count favorite_count\n  &lt;chr&gt;                   &lt;dbl&gt;         &lt;dbl&gt;          &lt;dbl&gt;\n1 cem_oezdemir               23            23              0\n2 W_Schmidt_              10659         10659              0\n3 lisapaus                    4             1              3\n\n\nMit .before = retweet_count würde die neue Spalte direkt vor retweet_count erscheinen. Das ist praktisch, wenn ihr euren Datensatz übersichtlich halten wollt, ohne danach extra relocate() aufrufen zu müssen.\nSpalten behalten oder verwerfen mit .keep\n\nDer Parameter .keep steuert, welche der bestehenden Spalten im Ergebnis erhalten bleiben. Es gibt vier Optionen:\n\n\n\n\n\n\n.keep\nVerhalten\n\n\n\n\"all\"\nAlle Spalten behalten (Standard)\n\n\n\"used\"\nNur die Spalten behalten, die in der Berechnung verwendet wurden\n\n\n\"unused\"\nNur die Spalten behalten, die nicht in der Berechnung verwendet wurden\n\n\n\"none\"\nKeine bestehenden Spalten behalten, nur die neuen\n\n\n\nSchauen wir uns die Unterschiede an. Mit \"used\" behaltet ihr nur die Spalten, aus denen die neue Variable berechnet wurde:\n\ntweets |&gt;\n  mutate(\n    total_engagement = retweet_count + favorite_count,\n    .keep = \"used\"\n  ) |&gt;\n  head(3)\n\n# A tibble: 3 × 3\n  retweet_count favorite_count total_engagement\n          &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1            23              0               23\n2         10659              0            10659\n3             1              3                4\n\n\nDas Ergebnis enthält retweet_count, favorite_count und total_engagement, aber keine der anderen Spalten. Das ist nützlich, wenn ihr schnell prüfen wollt, ob eure Berechnung stimmt.\nMit \"none\" behaltet ihr ausschließlich die neuen Variablen:\n\ntweets |&gt;\n  mutate(\n    user = screen_name,\n    total_engagement = retweet_count + favorite_count,\n    .keep = \"none\"\n  ) |&gt;\n  head(3)\n\n# A tibble: 3 × 2\n  user         total_engagement\n  &lt;chr&gt;                   &lt;dbl&gt;\n1 cem_oezdemir               23\n2 W_Schmidt_              10659\n3 lisapaus                    4\n\n\n\ntransmute() als Alternative\nmutate(..., .keep = \"none\") macht genau das Gleiche wie transmute(). Die Funktion transmute() existierte bereits, bevor .keep eingeführt wurde, und ist eine kürzere Schreibweise:\n\ntweets |&gt;\n  transmute(\n    user = screen_name,\n    total_engagement = retweet_count + favorite_count,\n    engagement_ratio = retweet_count / total_engagement\n  ) |&gt;\n  head(5)\n\n# A tibble: 5 × 3\n  user         total_engagement engagement_ratio\n  &lt;chr&gt;                   &lt;dbl&gt;            &lt;dbl&gt;\n1 cem_oezdemir               23           1     \n2 W_Schmidt_              10659           1     \n3 lisapaus                    4           0.25  \n4 lisapaus                   12           0.0833\n5 Wissing                    31           0.194 \n\n\nWelchen Weg ihr wählt, ist Geschmackssache. transmute() ist etwas kürzer, mutate(..., .keep = \"none\") macht die Absicht über den Parameter expliziter.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Variablen erstellen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/mutate-add.html#sec-mutate-add-zusammenfassung",
    "href": "03-data-transformation/mutate-add.html#sec-mutate-add-zusammenfassung",
    "title": "10  Variablen erstellen",
    "section": "\n10.7 Kurz zusammengefasst",
    "text": "10.7 Kurz zusammengefasst\n\nMit mutate() erstellt ihr neue Variablen, indem ihr links vom = einen neuen Namen vergebt.\nIhr könnt arithmetisch rechnen, Texte zusammensetzen und bedingte Werte mit if_else() oder case_when() erzeugen.\nFensterfunktionen wie lag(), lead(), cumsum() und min_rank() berechnen Werte im Kontext umliegender Zeilen.\nMit group_by() |&gt; mutate() laufen Berechnungen innerhalb von Gruppen, ohne den Datensatz zu komprimieren.\nMit .before und .after steuert ihr die Position neuer Spalten.\nMit .keep bestimmt ihr, welche bestehenden Spalten erhalten bleiben (\"all\", \"used\", \"unused\", \"none\").\n\ntransmute() ist eine Kurzform für mutate(..., .keep = \"none\").\n\nMit select() und mutate() könnt ihr Spalten auswählen, verändern und neue berechnen. Im nächsten Kapitel dreht sich alles um die Frage, welche Zeilen für eure Analyse relevant sind (siehe Kapitel 11).",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Variablen erstellen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/filter.html",
    "href": "03-data-transformation/filter.html",
    "title": "11  Beobachtungen auswählen",
    "section": "",
    "text": "11.1 Das Grundprinzip\nIhr habt jetzt gelernt, wie ihr mit select() den Blick auf die richtigen Spalten richtet und mit mutate() neue Variablen anlegt. In diesem Kapitel widmen wir uns dem Gegenstück zur Spaltenauswahl: Der Auswahl der relevanten Zeilen. Wir zeigen euch, wie ihr mit der Funktion filter() aus dplyr gezielt Beobachtungen behaltet, die bestimmte logische Bedingungen erfüllen, und wie ihr leere oder doppelte Zeilen entfernt.\nDas Filtern von Daten ist einer der wichtigsten Schritte in jeder explorativen Analyse. Reale Datensätze sind fast immer größer und unschärfer als das, was ihr für eine spezifische Forschungsfrage untersuchen möchtet. Erst indem ihr Gruppen isoliert, Ausreißer entfernt oder den Fokus auf einen konkreten Zeitraum beschränkt, könnt ihr präzise Aussagen treffen und den Rausch aus euren Daten entfernen.\nDie folgende Tabelle zeigt die Funktionen, die wir in diesem Abschnitt kennenlernen.\nBevor wir anfangen zu filtern, werfen wir einen kurzen Blick auf unseren Datensatz, damit wir wissen, wonach wir suchen können.\nWenn ihr euch erst einmal orientieren wollt, schaut euch kurz die Struktur des Datensatzes an:\nfilter() bekommt einen Tibble, prüft pro Zeile eine oder mehrere Bedingungen und gibt nur die Zeilen zurück, die passen.\nDie einfachste Variante ist eine einzelne Bedingung. Zum Beispiel: Zeigt nur Tweets, die keine Retweets sind.\nHier passiert gleich viel auf einmal:\nAbbildung: Ein Datensatz als Tabelle mit acht Zeilen. Ein Filtersymbol steht links, daneben die Bedingung !is_retweet. Vier Zeilen sind durchgestrichen oder ausgegraut (die Retweets), die übrigen vier bleiben übrig. Rechts sieht man die kleinere Ergebnistabelle mit nur den vier verbliebenen Zeilen.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Beobachtungen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/filter.html#sec-filter-grundprinzip",
    "href": "03-data-transformation/filter.html#sec-filter-grundprinzip",
    "title": "11  Beobachtungen auswählen",
    "section": "",
    "text": "Die filter-Funktion reduziert die Beobachtungen in einem Tibble.\n\n\n\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  select(screen_name, retweet_count, favorite_count, text) |&gt;\n  head(5)\n\n# A tibble: 5 × 4\n  screen_name retweet_count favorite_count text                                 \n  &lt;chr&gt;               &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;                                \n1 lisapaus                1              3 \"@HassoSuliak @Storch_i @tagesschau …\n2 lisapaus                1             11 \"@andiewoerle @svenlehmann Nein, sie…\n3 Wissing                 6             25 \"\\U0001f449 https://t.co/NTFHy7j9AT\" \n4 Wissing                 9             93 \"Wir folgen Stimmen aus der Wissensc…\n5 Wissing                15            154 \"Weshalb wir politische Verantwortun…\n\n\n\n\n\n\nfilter(!is_retweet) wählt Zeilen aus, bei denen is_retweet nicht TRUE ist.\n\nselect(...) reduziert die Spalten auf das Wesentliche, das kennt ihr schon.\n\nhead(5) zeigt euch eine kleine Vorschau, damit ihr schnell prüfen könnt, ob der Filter macht, was ihr erwartet.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Beobachtungen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/filter.html#sec-filter-vergleich",
    "href": "03-data-transformation/filter.html#sec-filter-vergleich",
    "title": "11  Beobachtungen auswählen",
    "section": "\n11.2 Vergleichsoperatoren",
    "text": "11.2 Vergleichsoperatoren\nDie meisten Filterbedingungen beruhen auf Vergleichen:\n\n\nOperator\nBedeutung\n\n\n\n==\ngleich\n\n\n!=\nungleich\n\n\n&lt;\nkleiner als\n\n\n&lt;=\nkleiner oder gleich\n\n\n&gt;\ngrößer als\n\n\n&gt;=\ngrößer oder gleich\n\n\n\nZum Beispiel: Zeigt nur Tweets mit mindestens 1.000 Retweets.\n\n\ntweets |&gt;\n  filter(retweet_count &gt;= 1000) |&gt;\n  select(screen_name, retweet_count, text) |&gt;\n  arrange(desc(retweet_count)) |&gt;\n  head(5)\n\n# A tibble: 5 × 3\n  screen_name     retweet_count text                                            \n  &lt;chr&gt;                   &lt;dbl&gt; &lt;chr&gt;                                           \n1 cem_oezdemir           434571 RT @Schwarzenegger: I love the Russian people. …\n2 klara_geywitz          276452 RT @Twitter: Twitter is built by immigrants of …\n3 SteffiLemke            271059 RT @KamalaHarris: While I may be the first woma…\n4 ABaerbockArchiv        188454 RT @verygooster: every woman in this pic tho ht…\n5 W_Schmidt_             169437 RT @MarcusRashford: https://t.co/bs9lksGM4q     \n\n\n\nWenn ihr bei einer Bedingung unsicher seid, lohnt sich ein kurzer Check. Zählt einmal, wie viele Zeilen überhaupt übrig bleiben:\n\n\ntweets |&gt;\n  filter(retweet_count &gt;= 1000) |&gt;\n  nrow()\n\n[1] 866\n\n\n\n\n\n\n\n\n\nTipp== ist nicht =\n\n\n\nEin häufiger Anfängerfehler: = ist eine Zuweisung, == ist ein Vergleich. Wenn ihr filter(retweet_count = 1000) schreibt, bekommt ihr eine Fehlermeldung. Ihr braucht filter(retweet_count == 1000).",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Beobachtungen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/filter.html#sec-filter-kombinieren",
    "href": "03-data-transformation/filter.html#sec-filter-kombinieren",
    "title": "11  Beobachtungen auswählen",
    "section": "\n11.3 Bedingungen kombinieren",
    "text": "11.3 Bedingungen kombinieren\nIn der Praxis filtert ihr fast immer mit mehr als einer Bedingung. Manchmal müssen alle Kriterien erfüllt sein, manchmal reicht eines.\nUND\nWenn ihr mehrere Bedingungen durch Kommas trennt, bedeutet das: Alle Bedingungen müssen wahr sein. Das entspricht einem logischen UND.\n\n\ntweets |&gt;\n  filter(!is_retweet, retweet_count &gt;= 500) |&gt;\n  select(screen_name, retweet_count, text) |&gt;\n  head(5)\n\n# A tibble: 5 × 3\n  screen_name retweet_count text                                                \n  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;                                               \n1 ABaerbock            1585 \"Bewohner*innen von Kiew in Todesangst im Morgenver…\n2 ABaerbock             807 \"Die Knüppel und das Tränengas sind kein Ausdruck v…\n3 ABaerbock            3375 \"Kaum zu ertragen, was an der #SharifUniversity in …\n4 ABaerbock            1035 \"Schwer zu ertragen auch, dass unsere außenpolitisc…\n5 ABaerbock             562 \"Als Russland vor 8 Monaten die #Ukraine überfiel, …\n\n\n\nIhr könnt das auch explizit mit & schreiben. Inhaltlich ist es gleich, aber manchmal ist die &-Schreibweise besser, wenn ihr Klammern setzen wollt:\n\n\ntweets |&gt;\n  filter(!is_retweet & retweet_count &gt;= 500) |&gt;\n  select(screen_name, retweet_count, text) |&gt;\n  head(5)\n\n# A tibble: 5 × 3\n  screen_name retweet_count text                                                \n  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;                                               \n1 ABaerbock            1585 \"Bewohner*innen von Kiew in Todesangst im Morgenver…\n2 ABaerbock             807 \"Die Knüppel und das Tränengas sind kein Ausdruck v…\n3 ABaerbock            3375 \"Kaum zu ertragen, was an der #SharifUniversity in …\n4 ABaerbock            1035 \"Schwer zu ertragen auch, dass unsere außenpolitisc…\n5 ABaerbock             562 \"Als Russland vor 8 Monaten die #Ukraine überfiel, …\n\n\n\nODER\nMit | verknüpft ihr Bedingungen als logisches ODER. Dann reicht es, wenn mindestens eine Bedingung zutrifft.\n\n\ntweets |&gt;\n  filter(retweet_count &gt;= 2000 | favorite_count &gt;= 5000) |&gt;\n  select(screen_name, retweet_count, favorite_count, text) |&gt;\n  head(5)\n\n# A tibble: 5 × 4\n  screen_name retweet_count favorite_count text                                 \n  &lt;chr&gt;               &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;                                \n1 W_Schmidt_          10659              0 \"RT @aakashg0: Twitter revealed its …\n2 lisapaus             2970              0 \"RT @NatalieAmiri: Oh wow Berlin. He…\n3 ABaerbock            1585          13304 \"Bewohner*innen von Kiew in Todesang…\n4 ABaerbock             807           6767 \"Die Knüppel und das Tränengas sind …\n5 ABaerbock            3375          15379 \"Kaum zu ertragen, was an der #Shari…\n\n\n\nKlammern setzen\nWenn ihr UND und ODER kombiniert, sind Klammern entscheidend. Ohne Klammern kann es passieren, dass ihr einen ganz anderen Filter baut, als ihr im Kopf habt.\n\n\ntweets |&gt;\n  filter(!is_retweet & (retweet_count &gt;= 2000 | favorite_count &gt;= 5000)) |&gt;\n  select(screen_name, retweet_count, favorite_count, text) |&gt;\n  head(5)\n\n# A tibble: 5 × 4\n  screen_name retweet_count favorite_count text                                 \n  &lt;chr&gt;               &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;                                \n1 ABaerbock            1585          13304 \"Bewohner*innen von Kiew in Todesang…\n2 ABaerbock             807           6767 \"Die Knüppel und das Tränengas sind …\n3 ABaerbock            3375          15379 \"Kaum zu ertragen, was an der #Shari…\n4 ABaerbock            1035           7550 \"Schwer zu ertragen auch, dass unser…\n5 ABaerbock             562           5639 \"Als Russland vor 8 Monaten die #Ukr…\n\n\n\nOhne die Klammern um die ODER-Bedingung würde !is_retweet nur mit retweet_count &gt;= 2000 verknüpft, und favorite_count &gt;= 5000 würde unabhängig davon gelten. Das Ergebnis wäre ein komplett anderer Datensatz.\nAbbildung: Zwei Venn-Diagramme nebeneinander. Links: Zwei Kreise “Retweets &gt;= 2000” und “Likes &gt;= 5000”, die sich überlappen, innerhalb eines Rahmens “keine Retweets”. Die Schnittmenge des Rahmens mit der Vereinigung der Kreise ist hervorgehoben. Rechts: Dieselben Kreise, aber der Rahmen “keine Retweets” umschließt nur den linken Kreis. Die hervorgehobene Fläche ist deutlich größer. Unter dem linken Diagramm steht die Formel mit Klammern, unter dem rechten die Formel ohne Klammern.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Beobachtungen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/filter.html#sec-filter-bereiche",
    "href": "03-data-transformation/filter.html#sec-filter-bereiche",
    "title": "11  Beobachtungen auswählen",
    "section": "\n11.4 Bereiche und Wertelisten",
    "text": "11.4 Bereiche und Wertelisten\nbetween()\nWenn ihr Werte in einem Bereich behalten wollt, ist between() oft lesbarer als zwei Vergleiche:\n\n\ntweets |&gt;\n  filter(between(retweet_count, 100, 500)) |&gt;\n  select(screen_name, retweet_count, text) |&gt;\n  head(5)\n\n# A tibble: 5 × 3\n  screen_name   retweet_count text                                              \n  &lt;chr&gt;                 &lt;dbl&gt; &lt;chr&gt;                                             \n1 ABaerbock               176 \"Journalismus ist kein Verbrechen. Russland muss …\n2 Bundeskanzler           169 \"Moldau ist Teil der europäischen Familie und EU-…\n3 Bundeskanzler           100 \"\\U0001f1f7\\U0001f1f4und \\U0001f1e9\\U0001f1easind…\n4 lisapaus                168 \"RT @BriHasselmann: Wir dürfen uns nicht damit ab…\n5 Wissing                 113 \"RT @bmdv: Das #Deutschlandticket kommt! Es ist d…\n\n\n\nDas ist gleichbedeutend mit retweet_count &gt;= 100 & retweet_count &lt;= 500, nur kürzer.\n%in%\nWenn ihr mehrere konkrete Werte zulassen wollt, ist %in% euer Werkzeug. Stellt es euch wie eine Gästeliste vor:\n\n\nusers &lt;- c(\"cem_oezdemir\", \"Karl_Lauterbach\")\n\ntweets |&gt;\n  filter(screen_name %in% users) |&gt;\n  select(screen_name, retweet_count, text) |&gt;\n  head(5)\n\n# A tibble: 5 × 3\n  screen_name  retweet_count text                                               \n  &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;                                              \n1 cem_oezdemir            23 RT @BriHasselmann: Endlich! Wir sind drangeblieben…\n2 cem_oezdemir            13 In dieser Woche jähren sich die Morde des #NSU an …\n3 cem_oezdemir             7 RT @DLAMarbach: Fr., 21.4., 17 Uhr: Benefizveranst…\n4 cem_oezdemir             1 @cziedler @StZ_NEWS @StN_News Alles Gute &amp; Dan…\n5 cem_oezdemir             2 @NewsWatchHH Was schee isch, braucht mr ned lang b…\n\n\n\nWenn ihr nicht sicher seid, ob die Schreibweise der Namen exakt passt, prüft die häufigsten Werte vorher:\n\n\ntweets |&gt;\n  count(screen_name, sort = TRUE) |&gt;\n  head(10)\n\n# A tibble: 10 × 2\n   screen_name         n\n   &lt;chr&gt;           &lt;int&gt;\n 1 c_lindner        5172\n 2 MarcoBuschmann   5171\n 3 cem_oezdemir     4704\n 4 lisapaus         4260\n 5 Karl_Lauterbach  4139\n 6 W_Schmidt_       3936\n 7 SvenjaSchulze68  3856\n 8 starkwatzinger   3848\n 9 hubertus_heil    3751\n10 SteffiLemke      3581\n\n\n\nNegation mit !\n\nManchmal wollt ihr das Gegenteil: alle Zeilen, die nicht in einer Liste stehen. Dafür setzt ihr ein ! vor die Bedingung:\n\ntweets |&gt;\n  filter(!screen_name %in% users) |&gt;\n  select(screen_name, retweet_count) |&gt;\n  head(5)\n\n# A tibble: 5 × 2\n  screen_name retweet_count\n  &lt;chr&gt;               &lt;dbl&gt;\n1 W_Schmidt_          10659\n2 lisapaus                1\n3 lisapaus                1\n4 Wissing                 6\n5 Wissing                 9\n\n\nDas funktioniert genauso mit str_detect() (dazu gleich mehr) und anderen logischen Ausdrücken.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Beobachtungen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/filter.html#sec-filter-text",
    "href": "03-data-transformation/filter.html#sec-filter-text",
    "title": "11  Beobachtungen auswählen",
    "section": "\n11.5 Textfilter",
    "text": "11.5 Textfilter\nBeim Filtern von Text nutzt ihr Funktionen aus stringr. Der Klassiker ist str_detect(), das prüft, ob ein Text ein bestimmtes Muster enthält.\n\n\ntweets |&gt;\n  filter(str_detect(text, \"klima\")) |&gt;\n  select(screen_name, retweet_count, text) |&gt;\n  head(5)\n\n# A tibble: 5 × 3\n  screen_name retweet_count text                                                \n  &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;                                               \n1 Wissing                17 RT @fdpbt: Technologieoffen und klimaneutral: Auch …\n2 lisapaus               22 RT @gruenelvnds: Du hast es in der Hand: Wähle eine…\n3 ABaerbock              24 Deshalb steigen wir aus der Kohle aus. Und deshalb …\n4 c_lindner              79 Bei unseren europäischen Partnern treffe ich vielfa…\n5 c_lindner              35 So hätten wir 5 sichere, klimafreundliche Kraftwerk…\n\n\n\nGroß- und Kleinschreibung ignorieren\nstr_detect() unterscheidet standardmäßig zwischen Groß- und Kleinschreibung. Wenn ihr beides finden wollt, nutzt regex() mit ignore_case = TRUE:\n\n\ntweets |&gt;\n  filter(str_detect(text, regex(\"klima\", ignore_case = TRUE))) |&gt;\n  select(screen_name, retweet_count, text) |&gt;\n  head(5)\n\n# A tibble: 5 × 3\n  screen_name   retweet_count text                                              \n  &lt;chr&gt;                 &lt;dbl&gt; &lt;chr&gt;                                             \n1 Wissing                   9 \"Wir folgen Stimmen aus der Wissenschaft und führ…\n2 Wissing                  15 \"Weshalb wir politische Verantwortung nicht in Se…\n3 klara_geywitz             2 \"RT @BMWSB_Bund: Für den Schutz unseres Klimas un…\n4 Wissing                  16 \"Die Aktionen von @AufstandLastGen sind massive Ü…\n5 Wissing                   3 \"RT @bmdv: Klimaneutral durch #Wasserstoff – bald…\n\n\n\nTextmuster ausschließen\nUm Zeilen auszuschließen, die ein Muster enthalten, negiert ihr str_detect():\n\ntweets |&gt;\n  filter(!str_detect(text, regex(\"klima\", ignore_case = TRUE))) |&gt;\n  nrow()\n\n[1] 55383\n\n\nText am Anfang oder Ende\nWenn euch interessiert, ob ein Text mit einem bestimmten Muster beginnt oder endet, gibt es str_starts() und str_ends():\n\ntweets |&gt;\n  filter(str_starts(text, \"RT\")) |&gt;\n  select(screen_name, text) |&gt;\n  head(3)\n\n# A tibble: 3 × 2\n  screen_name  text                                                             \n  &lt;chr&gt;        &lt;chr&gt;                                                            \n1 cem_oezdemir RT @BriHasselmann: Endlich! Wir sind drangeblieben. Die #Tierhal…\n2 W_Schmidt_   RT @aakashg0: Twitter revealed its algorithm to the world. But w…\n3 lisapaus     RT @JSchmitzLeipzig: Die gesellschaftlichen Folgekosten von Kind…",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Beobachtungen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/filter.html#sec-filter-na",
    "href": "03-data-transformation/filter.html#sec-filter-na",
    "title": "11  Beobachtungen auswählen",
    "section": "\n11.6 Fehlende Werte",
    "text": "11.6 Fehlende Werte\nEin häufiger Stolperstein: NA ist weder wahr noch falsch. Es bedeutet, dass der Wert fehlt. In filter() werden Zeilen mit NA in der Bedingung automatisch entfernt, weil die Bedingung nicht eindeutig wahr ist.\nWenn euch fehlende Werte wichtig sind, müsst ihr das explizit ausdrücken. Mit is.na() findet ihr Zeilen, in denen ein Wert fehlt:\n\n\ntweets |&gt;\n  filter(is.na(in_reply_to_screen_name)) |&gt;\n  select(screen_name, in_reply_to_screen_name, text) |&gt;\n  head(5)\n\n# A tibble: 5 × 3\n  screen_name  in_reply_to_screen_name text                                     \n  &lt;chr&gt;        &lt;chr&gt;                   &lt;chr&gt;                                    \n1 cem_oezdemir &lt;NA&gt;                    \"RT @BriHasselmann: Endlich! Wir sind dr…\n2 W_Schmidt_   &lt;NA&gt;                    \"RT @aakashg0: Twitter revealed its algo…\n3 Wissing      &lt;NA&gt;                    \"Wir folgen Stimmen aus der Wissenschaft…\n4 Wissing      &lt;NA&gt;                    \"Weshalb wir politische Verantwortung ni…\n5 c_lindner    &lt;NA&gt;                    \"2024 werden wir voraussichtlich erstmal…\n\n\n\nUnd das Gegenstück: Behaltet nur Zeilen, in denen der Wert vorhanden ist.\n\n\ntweets |&gt;\n  filter(!is.na(in_reply_to_screen_name)) |&gt;\n  select(screen_name, in_reply_to_screen_name, text) |&gt;\n  head(5)\n\n# A tibble: 5 × 3\n  screen_name in_reply_to_screen_name text                                      \n  &lt;chr&gt;       &lt;chr&gt;                   &lt;chr&gt;                                     \n1 lisapaus    HassoSuliak             \"@HassoSuliak @Storch_i @tagesschau Die E…\n2 lisapaus    andiewoerle             \"@andiewoerle @svenlehmann Nein, sie werd…\n3 Wissing     Wissing                 \"\\U0001f449 https://t.co/NTFHy7j9AT\"      \n4 lisapaus    SBachTax                \"@SBachTax @W_SK @APeichl Na ja. Wir rede…\n5 lisapaus    DavidMorawe             \"@DavidMorawe @SBachTax @W_SK https://t.c…\n\n\n\n\n\n\n\n\n\nTippLeere Strings sind nicht NA\n\n\n\nEin fehlender Wert ist NA. Ein leerer Text wie \"\" ist dagegen ein vorhandener Wert, der nur leer ist. Wenn ihr beides ausschließen wollt, kombiniert ihr Bedingungen: filter(!is.na(text), text != \"\").",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Beobachtungen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/filter.html#sec-filter-mehrere",
    "href": "03-data-transformation/filter.html#sec-filter-mehrere",
    "title": "11  Beobachtungen auswählen",
    "section": "\n11.7 Mehrere Spalten filtern",
    "text": "11.7 Mehrere Spalten filtern\nManchmal wollt ihr eine Bedingung nicht nur für eine Spalte prüfen, sondern für mehrere gleichzeitig. Dafür gibt es if_any() und if_all().\nif_any()\nBehaltet Zeilen, wenn die Bedingung für mindestens eine der Spalten wahr ist:\n\n\ntweets |&gt;\n  filter(if_any(c(retweet_count, favorite_count), \\(x) x &gt;= 2000)) |&gt;\n  select(screen_name, retweet_count, favorite_count, text) |&gt;\n  head(5)\n\n# A tibble: 5 × 4\n  screen_name retweet_count favorite_count text                                 \n  &lt;chr&gt;               &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;                                \n1 W_Schmidt_          10659              0 \"RT @aakashg0: Twitter revealed its …\n2 lisapaus             2970              0 \"RT @NatalieAmiri: Oh wow Berlin. He…\n3 ABaerbock             438           3289 \"Russia’s strategy of violent land-g…\n4 ABaerbock            1585          13304 \"Bewohner*innen von Kiew in Todesang…\n5 ABaerbock             807           6767 \"Die Knüppel und das Tränengas sind …\n\n\n\nif_all()\nBehaltet Zeilen, wenn die Bedingung für alle Spalten wahr ist:\n\n\ntweets |&gt;\n  filter(if_all(c(retweet_count, favorite_count), \\(x) x &gt;= 2000)) |&gt;\n  select(screen_name, retweet_count, favorite_count, text) |&gt;\n  head(5)\n\n# A tibble: 5 × 4\n  screen_name     retweet_count favorite_count text                             \n  &lt;chr&gt;                   &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;                            \n1 ABaerbock                3375          15379 Kaum zu ertragen, was an der #Sh…\n2 ABaerbock                3987           7274 Die Menschenverachtung des irani…\n3 NancyFaeser              2180          29726 #OneLove https://t.co/L5itnDJcsI \n4 ABaerbock                5407          11736 #MohammadMehdiKarami &amp; #Moha…\n5 ABaerbockArchiv          3860          49703 Ich freue mich, dass Robert Habe…",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Beobachtungen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/filter.html#sec-filter-slice",
    "href": "03-data-transformation/filter.html#sec-filter-slice",
    "title": "11  Beobachtungen auswählen",
    "section": "\n11.8 Zeilen gezielt auswählen mit slice()\n",
    "text": "11.8 Zeilen gezielt auswählen mit slice()\n\nfilter() wählt Zeilen nach einer Bedingung aus. Manchmal wollt ihr aber einfach bestimmte Zeilen nach Position oder Rang. Dafür gibt es die slice()-Familie.\n\nslice_head() und slice_tail()\n\nDie einfachste Variante: Die ersten oder letzten n Zeilen:\n\ntweets |&gt;\n  slice_head(n = 3)\n\n# A tibble: 3 × 22\n  id              screen_name text  retweet_count favorite_count is_quote_status\n  &lt;chr&gt;           &lt;chr&gt;       &lt;chr&gt;         &lt;dbl&gt;          &lt;dbl&gt; &lt;lgl&gt;          \n1 16422519457326… cem_oezdem… RT @…            23              0 FALSE          \n2 16424168190037… W_Schmidt_  RT @…         10659              0 FALSE          \n3 16420826297962… lisapaus    @Has…             1              3 FALSE          \n# ℹ 16 more variables: is_retweet &lt;lgl&gt;, retweeted_status_id &lt;chr&gt;,\n#   retweeted_user &lt;chr&gt;, lang &lt;chr&gt;, hashtags &lt;list&gt;, urls &lt;list&gt;,\n#   user_mentions &lt;list&gt;, photos &lt;list&gt;, source &lt;chr&gt;, insert_timestamp &lt;chr&gt;,\n#   created_at &lt;dttm&gt;, quote_count &lt;dbl&gt;, reply_count &lt;dbl&gt;,\n#   in_reply_to_screen_name &lt;chr&gt;, in_reply_to_status_id &lt;chr&gt;,\n#   quoted_status_id &lt;chr&gt;\n\n\n\nslice_max() und slice_min()\n\nWenn ihr die Zeilen mit den höchsten oder niedrigsten Werten einer Spalte wollt, ist slice_max() eine kompakte Alternative zu arrange() und head():\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  slice_max(retweet_count, n = 5) |&gt;\n  select(screen_name, retweet_count, text)\n\n# A tibble: 5 × 3\n  screen_name     retweet_count text                                            \n  &lt;chr&gt;                   &lt;dbl&gt; &lt;chr&gt;                                           \n1 Bundeskanzler           12652 Der russische Überfall markiert eine Zeitenwend…\n2 Bundeskanzler            8032 The Russian invasion marks a turning point. It …\n3 ABaerbockArchiv          7152 Klimakrise ist jetzt. Hören wir auf, nur zu red…\n4 ABaerbock                5407 #MohammadMehdiKarami &amp; #MohammadHosseini - …\n5 Karl_Lauterbach          5363 Ich möchte mich bei allen bedanken, die mich al…\n\n\nDas Gleiche funktioniert mit slice_min() für die kleinsten Werte.\nslice_sample()\nFür eine zufällige Stichprobe nutzt ihr slice_sample():\n\ntweets |&gt;\n  slice_sample(n = 5) |&gt;\n  select(screen_name, retweet_count, text)\n\n# A tibble: 5 × 3\n  screen_name     retweet_count text                                            \n  &lt;chr&gt;                   &lt;dbl&gt; &lt;chr&gt;                                           \n1 SteffiLemke                 4 \"Die AfD-Fraktion vertritt im Bundestag immer o…\n2 lisapaus                    0 \"Die Alternative dazu, die #Kindergrundsicherun…\n3 c_lindner                   4 \"RT @fdpbt: Jetzt debattiert der #Bundestag übe…\n4 Karl_Lauterbach           220 \"Sehr wichtige Studie zur Wirkung des BionTech …\n5 Karl_Lauterbach            53 \"Deutschland hat bisher überzeugend gespielt un…\n\n\nDas ist nützlich, wenn ihr euch schnell einen Eindruck von eurem Datensatz verschaffen wollt, ohne immer nur die ersten Zeilen zu sehen.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Beobachtungen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/filter.html#sec-filter-distinct",
    "href": "03-data-transformation/filter.html#sec-filter-distinct",
    "title": "11  Beobachtungen auswählen",
    "section": "\n11.9 Doppelte Zeilen entfernen mit distinct()\n",
    "text": "11.9 Doppelte Zeilen entfernen mit distinct()\n\nWenn euer Datensatz doppelte Zeilen enthält und ihr nur die eindeutigen behalten wollt, nutzt distinct():\n\ntweets |&gt;\n  distinct(screen_name) |&gt;\n  head(10)\n\n# A tibble: 10 × 1\n   screen_name  \n   &lt;chr&gt;        \n 1 cem_oezdemir \n 2 W_Schmidt_   \n 3 lisapaus     \n 4 Wissing      \n 5 c_lindner    \n 6 NancyFaeser  \n 7 klara_geywitz\n 8 ABaerbock    \n 9 Bundeskanzler\n10 OlafScholz   \n\n\nOhne Argumente entfernt distinct() vollständig identische Zeilen. Mit Spaltennamen behält es nur die erste Zeile pro einzigartige Kombination und entfernt die übrigen Spalten. Wenn ihr alle Spalten behalten wollt, nutzt .keep_all = TRUE:\n\ntweets |&gt;\n  distinct(screen_name, .keep_all = TRUE) |&gt;\n  select(screen_name, text) |&gt;\n  head(5)\n\n# A tibble: 5 × 2\n  screen_name  text                                                             \n  &lt;chr&gt;        &lt;chr&gt;                                                            \n1 cem_oezdemir \"RT @BriHasselmann: Endlich! Wir sind drangeblieben. Die #Tierha…\n2 W_Schmidt_   \"RT @aakashg0: Twitter revealed its algorithm to the world. But …\n3 lisapaus     \"@HassoSuliak @Storch_i @tagesschau Die EU Richtlinie ist bereit…\n4 Wissing      \"\\U0001f449 https://t.co/NTFHy7j9AT\"                             \n5 c_lindner    \"2024 werden wir voraussichtlich erstmals über 1 Billion Euro ei…",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Beobachtungen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/filter.html#sec-filter-grouped",
    "href": "03-data-transformation/filter.html#sec-filter-grouped",
    "title": "11  Beobachtungen auswählen",
    "section": "\n11.10 Gruppierte Daten",
    "text": "11.10 Gruppierte Daten\nWenn ihr mit group_by() arbeitet, ändert sich die Bedeutung mancher Ausdrücke. filter() bleibt genauso nützlich, aber ihr könnt zusätzlich gruppenbezogene Informationen verwenden.\nGruppen nach Größe filtern\nEin typischer Fall ist: Behaltet nur Accounts, die oft im Datensatz vorkommen.\n\n\ntweets |&gt;\n  group_by(screen_name) |&gt;\n  filter(n() &gt;= 50) |&gt;\n  ungroup() |&gt;\n  select(screen_name, retweet_count, text) |&gt;\n  head(5)\n\n# A tibble: 5 × 3\n  screen_name  retweet_count text                                               \n  &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;                                              \n1 cem_oezdemir            23 \"RT @BriHasselmann: Endlich! Wir sind drangebliebe…\n2 W_Schmidt_           10659 \"RT @aakashg0: Twitter revealed its algorithm to t…\n3 lisapaus                 1 \"@HassoSuliak @Storch_i @tagesschau Die EU Richtli…\n4 lisapaus                 1 \"@andiewoerle @svenlehmann Nein, sie werden nicht …\n5 Wissing                  6 \"\\U0001f449 https://t.co/NTFHy7j9AT\"               \n\n\n\nn() zählt hier die Zeilen pro Gruppe. Ohne group_by() würde n() die Gesamtzahl aller Zeilen zählen, nicht die Anzahl pro Account.\nInnerhalb einer Gruppe filtern\nIhr könnt auch innerhalb jeder Gruppe den stärksten Tweet behalten:\n\n\ntweets |&gt;\n  group_by(screen_name) |&gt;\n  filter(retweet_count == max(retweet_count, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  select(screen_name, retweet_count, text) |&gt;\n  arrange(desc(retweet_count)) |&gt;\n  head(10)\n\n# A tibble: 10 × 3\n   screen_name     retweet_count text                                           \n   &lt;chr&gt;                   &lt;dbl&gt; &lt;chr&gt;                                          \n 1 cem_oezdemir           434571 RT @Schwarzenegger: I love the Russian people.…\n 2 klara_geywitz          276452 RT @Twitter: Twitter is built by immigrants of…\n 3 SteffiLemke            271059 RT @KamalaHarris: While I may be the first wom…\n 4 ABaerbockArchiv        188454 RT @verygooster: every woman in this pic tho h…\n 5 W_Schmidt_             169437 RT @MarcusRashford: https://t.co/bs9lksGM4q    \n 6 hubertus_heil          149011 RT @BarackObama: I’m proud to endorse my frien…\n 7 OlafScholz             116422 RT @BarackObama: There are few issues more imp…\n 8 c_lindner               35685 RT @JoeBiden: We have one shot. One opportunit…\n 9 NancyFaeser             14694 RT @Podolski10: Amazing win !! Rio we are comi…\n10 lisapaus                12895 RT @rezomusik: Hier ist Teil 2. Dieses Video l…\n\n\n\nWenn mehrere Tweets denselben Maximalwert haben, bekommt ihr mehrere Zeilen pro Gruppe. Wenn ihr genau eine Zeile pro Gruppe wollt, nutzt slice_max() mit gruppierten Daten:\n\ntweets |&gt;\n  group_by(screen_name) |&gt;\n  slice_max(retweet_count, n = 1) |&gt;\n  ungroup() |&gt;\n  select(screen_name, retweet_count, text) |&gt;\n  arrange(desc(retweet_count)) |&gt;\n  head(10)\n\n# A tibble: 10 × 3\n   screen_name     retweet_count text                                           \n   &lt;chr&gt;                   &lt;dbl&gt; &lt;chr&gt;                                          \n 1 cem_oezdemir           434571 RT @Schwarzenegger: I love the Russian people.…\n 2 klara_geywitz          276452 RT @Twitter: Twitter is built by immigrants of…\n 3 SteffiLemke            271059 RT @KamalaHarris: While I may be the first wom…\n 4 ABaerbockArchiv        188454 RT @verygooster: every woman in this pic tho h…\n 5 W_Schmidt_             169437 RT @MarcusRashford: https://t.co/bs9lksGM4q    \n 6 hubertus_heil          149011 RT @BarackObama: I’m proud to endorse my frien…\n 7 OlafScholz             116422 RT @BarackObama: There are few issues more imp…\n 8 c_lindner               35685 RT @JoeBiden: We have one shot. One opportunit…\n 9 NancyFaeser             14694 RT @Podolski10: Amazing win !! Rio we are comi…\n10 lisapaus                12895 RT @rezomusik: Hier ist Teil 2. Dieses Video l…",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Beobachtungen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/filter.html#sec-filter-probleme",
    "href": "03-data-transformation/filter.html#sec-filter-probleme",
    "title": "11  Beobachtungen auswählen",
    "section": "\n11.11 Typische Probleme",
    "text": "11.11 Typische Probleme\nErgebnis ist leer\nWenn ihr nach einem Filter plötzlich null Zeilen habt, stimmt oft eine Annahme nicht. Dann helfen zwei schnelle Checks:\n\n\ntweets |&gt;\n  summarise(\n    min_retweets = min(retweet_count, na.rm = TRUE),\n    max_retweets = max(retweet_count, na.rm = TRUE),\n    min_likes = min(favorite_count, na.rm = TRUE),\n    max_likes = max(favorite_count, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 4\n  min_retweets max_retweets min_likes max_likes\n         &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1            0       434571         0    105493\n\n\n\nDamit seht ihr den tatsächlichen Wertebereich. Vielleicht habt ihr einen Schwellenwert gewählt, den kein einziger Tweet erreicht.\nUnd wenn ihr bei Kategorien unsicher seid:\n\n\ntweets |&gt;\n  count(is_retweet)\n\n# A tibble: 2 × 2\n  is_retweet     n\n  &lt;lgl&gt;      &lt;int&gt;\n1 FALSE      35757\n2 TRUE       22664\n\n\n\nZu viele Zeilen\nWenn ein Filter immer noch zu viele Zeilen zurückgibt, ist das kein Fehler. Es bedeutet nur, dass eure Bedingung noch zu grob ist. Dann baut ihr Schritt für Schritt weitere Kriterien ein und prüft zwischendurch mit nrow():\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  nrow()\n\n[1] 35757\n\ntweets |&gt;\n  filter(!is_retweet, retweet_count &gt;= 100) |&gt;\n  nrow()\n\n[1] 4562\n\ntweets |&gt;\n  filter(!is_retweet, retweet_count &gt;= 100, str_detect(text, regex(\"klima\", ignore_case = TRUE))) |&gt;\n  nrow()\n\n[1] 251\n\n\nSo seht ihr genau, wie jede zusätzliche Bedingung den Datensatz weiter einschränkt.\nUnerwartete NA-Verluste\nWenn euer Datensatz nach dem Filtern plötzlich weniger Zeilen hat als erwartet, kann es sein, dass NA-Werte stillschweigend entfernt wurden. Prüft vorher, wie viele NA-Werte in der gefilterten Spalte stecken:\n\ntweets |&gt;\n  summarise(\n    na_count = sum(is.na(in_reply_to_screen_name)),\n    total = n()\n  )\n\n# A tibble: 1 × 2\n  na_count total\n     &lt;int&gt; &lt;int&gt;\n1    44922 58421\n\n\nAutomatisches Logging mit tidylog\n\nWenn ihr eine längere Pipe mit mehreren Filterschritten baut, kann es mühsam sein, nach jedem Schritt manuell nrow() einzufügen. Hier hilft das Paket tidylog: Es gibt euch nach jedem dplyr-Befehl automatisch eine Rückmeldung, wie viele Zeilen betroffen waren.\n\nlibrary(tidylog)\n\nNachdem ihr es aktiviert habt, loggt es fleißig mit:\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  filter(retweet_count &gt;= 100) |&gt;\n  select(screen_name, retweet_count, text) |&gt;\n  head(5)\n\nfilter: removed 22,664 rows (39%), 35,757 rows remaining\nfilter: removed 31,195 rows (87%), 4,562 rows remaining\nselect: dropped 19 variables (id, favorite_count, is_quote_status, is_retweet, retweeted_status_id, …)\n\n\n# A tibble: 5 × 3\n  screen_name   retweet_count text                                              \n  &lt;chr&gt;                 &lt;dbl&gt; &lt;chr&gt;                                             \n1 ABaerbock               176 \"Journalismus ist kein Verbrechen. Russland muss …\n2 Bundeskanzler           169 \"Moldau ist Teil der europäischen Familie und EU-…\n3 Bundeskanzler           100 \"\\U0001f1f7\\U0001f1f4und \\U0001f1e9\\U0001f1easind…\n4 ABaerbock               438 \"Russia’s strategy of violent land-grabs and nucl…\n5 ABaerbock              1585 \"Bewohner*innen von Kiew in Todesangst im Morgenv…\n\n\nIn der Konsole seht ihr jetzt nach jedem Schritt eine Zeile wie filter: removed 42,000 rows (65%), 23,000 rows remaining. So erkennt ihr sofort, wenn ein Filter unerwartet viele oder wenige Zeilen entfernt.\n\n\n\n\n\n\nTipptidylog deaktivieren\n\n\n\ntidylog überschreibt die dplyr-Funktionen mit eigenen Versionen, die zusätzliche Ausgaben erzeugen. Wenn die Meldungen stören, entfernt das Paket wieder mit detach(\"package:tidylog\", unload = TRUE) oder startet eine neue R-Sitzung.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Beobachtungen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/filter.html#sec-filter-zusammenfassung",
    "href": "03-data-transformation/filter.html#sec-filter-zusammenfassung",
    "title": "11  Beobachtungen auswählen",
    "section": "\n11.12 Kurz zusammengefasst",
    "text": "11.12 Kurz zusammengefasst\n\n\n\nfilter() wählt Zeilen aus, die eine Bedingung erfüllen.\nMehrere Bedingungen mit Kommas bedeuten UND, mit | bedeutet ODER. Klammern bei Mischungen sind wichtig.\nMit between() und %in% drückt ihr Bereiche und Wertelisten gut lesbar aus.\nFür Textsuche nutzt ihr str_detect(), für fehlende Werte is.na().\nMit if_any() und if_all() filtert ihr über mehrere Spalten gleichzeitig.\nDie slice()-Familie wählt Zeilen nach Position oder Rang statt nach Bedingung.\n\ndistinct() entfernt doppelte Zeilen.\nMit group_by() könnt ihr in Gruppen filtern, zum Beispiel mit n() oder max().\n\n\nIhr könnt jetzt Spalten auswählen, verändern, neue berechnen und Zeilen filtern. Im nächsten Kapitel lernt ihr, wie ihr aus vielen Zeilen kompakte Zusammenfassungen erstellt (siehe Kapitel 12).",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Beobachtungen auswählen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/summarize.html",
    "href": "03-data-transformation/summarize.html",
    "title": "12  Beobachtungen zusammenfassen",
    "section": "",
    "text": "12.1 Das Grundprinzip\nBisher habt ihr gelernt, in welcher Form man Spalten und Zeilen bearbeitet, ohne jedoch die grundsätzliche Struktur des Datensatzes massiv zu verändern. In diesem Kapitel geht es nun um das Verdichten von Daten. Mit der Funktion summarise() aus dem dplyr-Paket könnt ihr aus hunderten Einzelwerten eine Handvoll aussagekräftiger Kennzahlen berechnen, wie Mittelwerte, Summen oder Anzahlen. Meistens geschieht dies nicht für den gesamten Datensatz, sondern für definierte Untergruppen, wofür wir die Funktion group_by() nutzen.\nDas Aggregieren von Daten ist ein Schlüsselelement der deskriptiven Statistik und Berichtserstellung. Selten interessiert sich jemand für jede einzelne Transaktion in einem Datensatz. Die wahren Erkenntnisse – und auch die Grundlage für aussagekräftige Visualisierungen – liegen stattdessen in den zusammengefassten Kennzahlen: Welches Produkt hat den höchsten Durchschnittsumsatz? Wie viele Nutzer waren pro Wochentag aktiv? summarise() liefert euch genau diese aggregierten Werte prägnant und effizient.\nDie folgende Tabelle zeigt die Funktionen, die wir in diesem Abschnitt kennenlernen.\nSehen wir uns zunächst an, wie wir den kompletten Datensatz auf eine einzige Zeile zusammenfassen können.\nsummarise() nimmt einen Tibble und gibt einen neuen Tibble mit einer einzigen Zeile zurück. In dieser Zeile stehen die Ergebnisse eurer Zusammenfassungsfunktionen.\ntweets |&gt;\n  summarise(\n    total_tweets = n(),\n    avg_retweets = mean(retweet_count, na.rm = TRUE),\n    max_likes = max(favorite_count, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 3\n  total_tweets avg_retweets max_likes\n         &lt;int&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n1        58421         140.    105493\nDrei Dinge fallen auf:\nAbbildung: Links ein großer Datensatz als Tabelle mit vielen Zeilen und Spalten. In der Mitte ein Trichtersymbol mit der Beschriftung summarise(). Rechts ein kleiner Tibble mit einer einzigen Zeile und drei Spalten (total_tweets, avg_retweets, max_likes). Der Fokus liegt darauf, dass viele Zeilen zu einer einzigen Zeile komprimiert werden.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Beobachtungen zusammenfassen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/summarize.html#sec-summarize-grundprinzip",
    "href": "03-data-transformation/summarize.html#sec-summarize-grundprinzip",
    "title": "12  Beobachtungen zusammenfassen",
    "section": "",
    "text": "n() zählt die Zeilen. Es braucht kein Argument.\n\nmean() und max() berechnen den Durchschnitt und das Maximum. Das Argument na.rm = TRUE sorgt dafür, dass fehlende Werte ignoriert werden.\nDas Ergebnis ist ein Tibble mit einer Zeile und drei Spalten. Der ursprüngliche Datensatz mit seinen vielen Spalten und Zeilen ist verschwunden.\n\n\nHäufige Zusammenfassungsfunktionen\nHier sind die Funktionen, die ihr am häufigsten in summarise() verwenden werdet:\n\n\nFunktion\nBeschreibung\n\n\n\nn()\nAnzahl der Zeilen\n\n\nsum()\nSumme\n\n\nmean()\nArithmetisches Mittel\n\n\nmedian()\nMedian\n\n\n\nmin() / max()\n\nMinimum / Maximum\n\n\nsd()\nStandardabweichung\n\n\n\nfirst() / last()\n\nErster / letzter Wert\n\n\nn_distinct()\nAnzahl eindeutiger Werte\n\n\n\nDie meisten dieser Funktionen brauchen na.rm = TRUE, wenn eure Daten fehlende Werte enthalten. Ohne dieses Argument gibt R bei einem einzigen NA als Ergebnis NA zurück.\n\n\n\n\n\n\nTippna.rm nicht vergessen\n\n\n\nWenn mean(), sum() oder eine andere Aggregatfunktion plötzlich NA zurückgibt, obwohl ihr echte Daten habt, liegt es fast immer an fehlenden Werten. Fügt na.rm = TRUE hinzu, und das Problem ist gelöst.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Beobachtungen zusammenfassen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/summarize.html#sec-summarize-vs-mutate",
    "href": "03-data-transformation/summarize.html#sec-summarize-vs-mutate",
    "title": "12  Beobachtungen zusammenfassen",
    "section": "\n12.2 summarise() und mutate() im Vergleich",
    "text": "12.2 summarise() und mutate() im Vergleich\nWas ist eigentlich der Unterschied zwischen summarise() und mutate()? Beide können mit Aggregatfunktionen wie mean() arbeiten, aber sie tun etwas grundlegend Verschiedenes:\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  mutate(avg_retweets = mean(retweet_count, na.rm = TRUE)) |&gt;\n  select(screen_name, retweet_count, avg_retweets) |&gt;\n  head(5)\n\n# A tibble: 5 × 3\n  screen_name retweet_count avg_retweets\n  &lt;chr&gt;               &lt;dbl&gt;        &lt;dbl&gt;\n1 lisapaus                1         59.0\n2 lisapaus                1         59.0\n3 Wissing                 6         59.0\n4 Wissing                 9         59.0\n5 Wissing                15         59.0\n\n\nmutate() berechnet den Durchschnitt und schreibt ihn in jede Zeile. Der Datensatz bleibt gleich lang. Das ist nützlich, wenn ihr den Durchschnitt als Referenzwert neben jedem einzelnen Tweet sehen wollt.\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  summarise(avg_retweets = mean(retweet_count, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  avg_retweets\n         &lt;dbl&gt;\n1         59.0\n\n\nsummarise() dagegen komprimiert alles auf eine Zeile. Der Datensatz wird kürzer. Das ist nützlich, wenn euch nur die Kennzahl selbst interessiert.\n\n\n\n\n\n\n\n\nmutate()\nsummarise()\n\n\n\nErgebnis\nGleich viele Zeilen wie vorher\nEine Zeile (oder eine pro Gruppe)\n\n\nZweck\nWert als neue Spalte neben die bestehenden Daten schreiben\nDaten auf Kennzahlen verdichten",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Beobachtungen zusammenfassen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/summarize.html#sec-summarize-groupby",
    "href": "03-data-transformation/summarize.html#sec-summarize-groupby",
    "title": "12  Beobachtungen zusammenfassen",
    "section": "\n12.3 Gruppieren mit group_by()\n",
    "text": "12.3 Gruppieren mit group_by()\n\n\n\n\n\n\nAbbildung 12.1: In Kombination mit Gruppierung erzeugt summarize mehrere Zeilen statt nur eine.\n\n\nDie eigentliche Stärke von summarise() zeigt sich erst in Kombination mit group_by(). Ohne Gruppierung bekommt ihr eine einzige Zeile. Mit Gruppierung bekommt ihr eine Zeile pro Gruppe.\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  group_by(screen_name) |&gt;\n  summarise(\n    tweet_count = n(),\n    avg_retweets = mean(retweet_count, na.rm = TRUE),\n    avg_likes = mean(favorite_count, na.rm = TRUE)\n  ) |&gt;\n  arrange(desc(avg_retweets)) |&gt;\n  head(10)\n\n# A tibble: 10 × 4\n   screen_name     tweet_count avg_retweets avg_likes\n   &lt;chr&gt;                 &lt;int&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n 1 Karl_Lauterbach        4018        295.      3020.\n 2 ABaerbock               367        287.      2791.\n 3 Bundeskanzler           715        225.      1919.\n 4 ABaerbockArchiv        1233         99.3     1169.\n 5 cem_oezdemir           1876         57.7      694.\n 6 c_lindner              2931         38.9      518.\n 7 NancyFaeser            1505         34.7      401.\n 8 OlafScholz             1958         33.8      337.\n 9 hubertus_heil          1361         19.8      196.\n10 MarcoBuschmann         4436         14.0      174.\n\n\nWas passiert hier?\n\n\ngroup_by(screen_name) teilt den Datensatz in Gruppen auf, eine pro Account.\n\nsummarise() berechnet die Kennzahlen innerhalb jeder Gruppe.\nDas Ergebnis hat eine Zeile pro Account statt einer Zeile pro Tweet.\n\nAbbildung: Links ein Datensatz mit vielen Zeilen, die farblich nach drei Gruppen markiert sind (zum Beispiel rot, blau, grün). In der Mitte steht group_by() |&gt; summarise(). Rechts ein kleiner Tibble mit drei Zeilen, eine pro Gruppe, mit den Spalten “group”, “count” und “avg_value”. Jede Zeile hat die Farbe ihrer Gruppe. Der Fokus liegt darauf, dass die Zusammenfassung pro Gruppe statt über den gesamten Datensatz erfolgt.\nMehrere Gruppierungsvariablen\nIhr könnt auch nach mehreren Variablen gleichzeitig gruppieren. Dann bekommt ihr eine Zeile pro Kombination:\n\ntweets |&gt;\n  group_by(screen_name, is_retweet) |&gt;\n  summarise(\n    count = n(),\n    avg_likes = mean(favorite_count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt;\n  head(10)\n\n# A tibble: 10 × 4\n   screen_name     is_retweet count avg_likes\n   &lt;chr&gt;           &lt;lgl&gt;      &lt;int&gt;     &lt;dbl&gt;\n 1 ABaerbock       FALSE        367     2791.\n 2 ABaerbock       TRUE          10        0 \n 3 ABaerbockArchiv FALSE       1233     1169.\n 4 ABaerbockArchiv TRUE        1958        0 \n 5 Bundeskanzler   FALSE        715     1919.\n 6 Bundeskanzler   TRUE          18        0 \n 7 Karl_Lauterbach FALSE       4018     3020.\n 8 Karl_Lauterbach TRUE         121        0 \n 9 MarcoBuschmann  FALSE       4436      174.\n10 MarcoBuschmann  TRUE         735        0 \n\n\n.groups = \"drop\" entfernt die Gruppierung nach dem Zusammenfassen. Ohne diesen Parameter bleibt eine Restgruppierung bestehen, was zu unerwartetem Verhalten bei nachfolgenden Operationen führen kann.\n\n\n\n\n\n\nTipp.groups kontrollieren\n\n\n\nWenn ihr .groups nicht angebt, zeigt dplyr eine Meldung an, welche Gruppierung übrig bleibt. Die sicherste Option ist .groups = \"drop\", damit die Gruppierung danach aufgehoben ist. Alternativ könnt ihr ungroup() nach summarise() aufrufen.\n\n\nGruppierung und der Unterschied zu mutate()\n\nIm Kapitel über mutate() habt ihr gesehen, dass group_by() |&gt; mutate() den Datensatz gleich lang lässt und die Kennzahl in jede Zeile schreibt. group_by() |&gt; summarise() dagegen komprimiert den Datensatz auf eine Zeile pro Gruppe.\nHier nochmal der Unterschied im direkten Vergleich:\n\n# mutate: gleich viele Zeilen, Gruppenwert in jeder Zeile\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  group_by(screen_name) |&gt;\n  mutate(group_avg = mean(retweet_count, na.rm = TRUE)) |&gt;\n  select(screen_name, retweet_count, group_avg) |&gt;\n  ungroup() |&gt;\n  head(5)\n\n# A tibble: 5 × 3\n  screen_name retweet_count group_avg\n  &lt;chr&gt;               &lt;dbl&gt;     &lt;dbl&gt;\n1 lisapaus                1      5.56\n2 lisapaus                1      5.56\n3 Wissing                 6     12.5 \n4 Wissing                 9     12.5 \n5 Wissing                15     12.5 \n\n\n\n# summarise: eine Zeile pro Gruppe\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  group_by(screen_name) |&gt;\n  summarise(group_avg = mean(retweet_count, na.rm = TRUE)) |&gt;\n  head(5)\n\n# A tibble: 5 × 2\n  screen_name     group_avg\n  &lt;chr&gt;               &lt;dbl&gt;\n1 ABaerbock           287. \n2 ABaerbockArchiv      99.3\n3 Bundeskanzler       225. \n4 Karl_Lauterbach     295. \n5 MarcoBuschmann       14.0\n\n\nWelche Variante ihr braucht, hängt von eurer Frage ab: Wollt ihr die Kennzahl neben den Originaldaten sehen (→ mutate()), oder braucht ihr eine kompakte Übersicht (→ summarise())?",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Beobachtungen zusammenfassen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/summarize.html#sec-summarize-shortcuts",
    "href": "03-data-transformation/summarize.html#sec-summarize-shortcuts",
    "title": "12  Beobachtungen zusammenfassen",
    "section": "\n12.4 Abkürzungen",
    "text": "12.4 Abkürzungen\nFür die häufigsten Zusammenfassungen gibt es in dplyr kürzere Schreibweisen, die euren Code kompakter und lesbarer machen.\ncount()\nDie mit Abstand häufigste Zusammenfassung ist das Zählen. Wie oft kommt ein bestimmter Wert vor? count() ist die Abkürzung dafür:\n\ntweets |&gt;\n  count(screen_name, sort = TRUE) |&gt;\n  head(10)\n\n# A tibble: 10 × 2\n   screen_name         n\n   &lt;chr&gt;           &lt;int&gt;\n 1 c_lindner        5172\n 2 MarcoBuschmann   5171\n 3 cem_oezdemir     4704\n 4 lisapaus         4260\n 5 Karl_Lauterbach  4139\n 6 W_Schmidt_       3936\n 7 SvenjaSchulze68  3856\n 8 starkwatzinger   3848\n 9 hubertus_heil    3751\n10 SteffiLemke      3581\n\n\nDas ist gleichbedeutend mit:\n\ntweets |&gt;\n  group_by(screen_name) |&gt;\n  summarise(n = n()) |&gt;\n  arrange(desc(n)) |&gt;\n  head(10)\n\n# A tibble: 10 × 2\n   screen_name         n\n   &lt;chr&gt;           &lt;int&gt;\n 1 c_lindner        5172\n 2 MarcoBuschmann   5171\n 3 cem_oezdemir     4704\n 4 lisapaus         4260\n 5 Karl_Lauterbach  4139\n 6 W_Schmidt_       3936\n 7 SvenjaSchulze68  3856\n 8 starkwatzinger   3848\n 9 hubertus_heil    3751\n10 SteffiLemke      3581\n\n\nDer Unterschied: count() spart drei Zeilen Code. Das Argument sort = TRUE sortiert gleich absteigend nach Häufigkeit.\nIhr könnt auch nach mehreren Variablen gleichzeitig zählen:\n\ntweets |&gt;\n  count(screen_name, is_retweet, sort = TRUE) |&gt;\n  head(10)\n\n# A tibble: 10 × 3\n   screen_name     is_retweet     n\n   &lt;chr&gt;           &lt;lgl&gt;      &lt;int&gt;\n 1 MarcoBuschmann  FALSE       4436\n 2 Karl_Lauterbach FALSE       4018\n 3 starkwatzinger  FALSE       2942\n 4 c_lindner       FALSE       2931\n 5 cem_oezdemir    TRUE        2828\n 6 Wissing         FALSE       2447\n 7 hubertus_heil   TRUE        2390\n 8 c_lindner       TRUE        2241\n 9 lisapaus        TRUE        2162\n10 klara_geywitz   FALSE       2118\n\n\ntally()\ntally() ist eine noch einfachere Variante: Es zählt die Zeilen des aktuellen (möglicherweise gruppierten) Datensatzes.\n\ntweets |&gt;\n  group_by(screen_name) |&gt;\n  tally(sort = TRUE) |&gt;\n  head(10)\n\n# A tibble: 10 × 2\n   screen_name         n\n   &lt;chr&gt;           &lt;int&gt;\n 1 c_lindner        5172\n 2 MarcoBuschmann   5171\n 3 cem_oezdemir     4704\n 4 lisapaus         4260\n 5 Karl_Lauterbach  4139\n 6 W_Schmidt_       3936\n 7 SvenjaSchulze68  3856\n 8 starkwatzinger   3848\n 9 hubertus_heil    3751\n10 SteffiLemke      3581\n\n\nDer Unterschied zu count(): Bei tally() müsst ihr vorher selbst group_by() aufrufen. count() macht das intern für euch. In der Praxis ist count() daher oft die bequemere Wahl.\nadd_count()\nManchmal wollt ihr die Häufigkeit nicht als Zusammenfassung, sondern als zusätzliche Spalte neben den Originaldaten. Dafür gibt es add_count():\n\ntweets |&gt;\n  add_count(screen_name, name = \"tweets_per_user\") |&gt;\n  select(screen_name, tweets_per_user, text) |&gt;\n  head(5)\n\n# A tibble: 5 × 3\n  screen_name  tweets_per_user text                                             \n  &lt;chr&gt;                  &lt;int&gt; &lt;chr&gt;                                            \n1 cem_oezdemir            4704 \"RT @BriHasselmann: Endlich! Wir sind drangeblie…\n2 W_Schmidt_              3936 \"RT @aakashg0: Twitter revealed its algorithm to…\n3 lisapaus                4260 \"@HassoSuliak @Storch_i @tagesschau Die EU Richt…\n4 lisapaus                4260 \"@andiewoerle @svenlehmann Nein, sie werden nich…\n5 Wissing                 3446 \"\\U0001f449 https://t.co/NTFHy7j9AT\"             \n\n\nadd_count() verhält sich wie count(), aber der Datensatz behält seine ursprüngliche Länge. Es ist die Abkürzung für group_by() |&gt; mutate(n = n()) |&gt; ungroup().",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Beobachtungen zusammenfassen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/summarize.html#sec-summarize-across",
    "href": "03-data-transformation/summarize.html#sec-summarize-across",
    "title": "12  Beobachtungen zusammenfassen",
    "section": "\n12.5 Mehrere Spalten mit across()\n",
    "text": "12.5 Mehrere Spalten mit across()\n\nWenn ihr dieselbe Zusammenfassung auf mehrere Spalten gleichzeitig anwenden wollt, spart across() viel Tipparbeit:\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  summarise(across(c(retweet_count, favorite_count), mean, na.rm = TRUE))\n\n# A tibble: 1 × 2\n  retweet_count favorite_count\n          &lt;dbl&gt;          &lt;dbl&gt;\n1          59.0           612.\n\n\nacross() nimmt die Spaltenauswahl und die Funktion als Argumente. Für die Spaltenauswahl könnt ihr die gleichen Helfer wie bei select() verwenden:\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  summarise(across(where(is.numeric), mean, na.rm = TRUE))\n\n# A tibble: 1 × 4\n  retweet_count favorite_count quote_count reply_count\n          &lt;dbl&gt;          &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1          59.0           612.           0           0\n\n\nMehrere Funktionen gleichzeitig\nWenn ihr mehr als eine Funktion auf jede Spalte anwenden wollt, übergebt eine benannte Liste:\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  summarise(\n    across(\n      c(retweet_count, favorite_count),\n      list(avg = \\(x) mean(x, na.rm = TRUE), max = \\(x) max(x, na.rm = TRUE))\n    )\n  )\n\n# A tibble: 1 × 4\n  retweet_count_avg retweet_count_max favorite_count_avg favorite_count_max\n              &lt;dbl&gt;             &lt;dbl&gt;              &lt;dbl&gt;              &lt;dbl&gt;\n1              59.0             12652               612.             105493\n\n\nDie Spaltennamen im Ergebnis setzen sich automatisch zusammen: retweet_count_avg, retweet_count_max, und so weiter.\n\nacross() mit Gruppierung\nNatürlich funktioniert across() auch mit group_by():\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  group_by(screen_name) |&gt;\n  summarise(\n    across(c(retweet_count, favorite_count), \\(x) mean(x, na.rm = TRUE)),\n    .groups = \"drop\"\n  ) |&gt;\n  arrange(desc(retweet_count)) |&gt;\n  head(10)\n\n# A tibble: 10 × 3\n   screen_name     retweet_count favorite_count\n   &lt;chr&gt;                   &lt;dbl&gt;          &lt;dbl&gt;\n 1 Karl_Lauterbach         295.           3020.\n 2 ABaerbock               287.           2791.\n 3 Bundeskanzler           225.           1919.\n 4 ABaerbockArchiv          99.3          1169.\n 5 cem_oezdemir             57.7           694.\n 6 c_lindner                38.9           518.\n 7 NancyFaeser              34.7           401.\n 8 OlafScholz               33.8           337.\n 9 hubertus_heil            19.8           196.\n10 MarcoBuschmann           14.0           174.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Beobachtungen zusammenfassen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/summarize.html#sec-summarize-pipe",
    "href": "03-data-transformation/summarize.html#sec-summarize-pipe",
    "title": "12  Beobachtungen zusammenfassen",
    "section": "\n12.6 Zusammenfassungen in der Pipe",
    "text": "12.6 Zusammenfassungen in der Pipe\nIn der Praxis steht summarise() selten allein. Es ist fast immer Teil einer Pipe-Kette, die den Datensatz vorher filtert, gruppiert und nachher sortiert oder weiterverarbeitet.\nHier ist ein typisches Muster, das euch im Buch immer wieder begegnen wird:\n\ntweets |&gt;\n  filter(!is_retweet, !is.na(screen_name)) |&gt;\n  group_by(screen_name) |&gt;\n  summarise(\n    tweets = n(),\n    avg_retweets = mean(retweet_count, na.rm = TRUE),\n    avg_likes = mean(favorite_count, na.rm = TRUE),\n    .groups = \"drop\"\n  ) |&gt;\n  filter(tweets &gt;= 10) |&gt;\n  arrange(desc(avg_retweets)) |&gt;\n  head(10)\n\n# A tibble: 10 × 4\n   screen_name     tweets avg_retweets avg_likes\n   &lt;chr&gt;            &lt;int&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n 1 Karl_Lauterbach   4018        295.      3020.\n 2 ABaerbock          367        287.      2791.\n 3 Bundeskanzler      715        225.      1919.\n 4 ABaerbockArchiv   1233         99.3     1169.\n 5 cem_oezdemir      1876         57.7      694.\n 6 c_lindner         2931         38.9      518.\n 7 NancyFaeser       1505         34.7      401.\n 8 OlafScholz        1958         33.8      337.\n 9 hubertus_heil     1361         19.8      196.\n10 MarcoBuschmann    4436         14.0      174.\n\n\nBeobachtet den Aufbau:\n\n\nFiltern: Nur Original-Tweets, ohne fehlende Accountnamen.\n\nGruppieren: Pro Account.\n\nZusammenfassen: Zählen, Durchschnitte berechnen.\n\nNochmal filtern: Nur Accounts mit mindestens 10 Tweets, damit der Durchschnitt aussagekräftig ist.\n\nSortieren: Die aktivsten Accounts zuerst.\n\nDieser Ablauf ist ein Grundmuster der explorativen Datenanalyse: Daten einschränken, verdichten und sortieren.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Beobachtungen zusammenfassen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/summarize.html#sec-summarize-zusammenfassung",
    "href": "03-data-transformation/summarize.html#sec-summarize-zusammenfassung",
    "title": "12  Beobachtungen zusammenfassen",
    "section": "\n12.7 Kurz zusammengefasst",
    "text": "12.7 Kurz zusammengefasst\n\n\nsummarise() verdichtet einen Datensatz auf eine einzige Zeile mit Kennzahlen.\n\ngroup_by() teilt den Datensatz in Gruppen auf, sodass summarise() eine Zeile pro Gruppe liefert.\n\nmutate() schreibt Aggregatwerte in jede Zeile, summarise() komprimiert den Datensatz.\n\ncount() ist die Abkürzung für group_by() |&gt; summarise(n = n()) und die häufigste Zusammenfassung.\n\ntally() zählt Zeilen eines bereits gruppierten Datensatzes, add_count() fügt die Zählung als Spalte hinzu.\nMit across() wendet ihr Zusammenfassungen auf mehrere Spalten gleichzeitig an.\nKontrolliert die Gruppierung nach summarise() mit .groups = \"drop\" oder ungroup().\n\nMit summarise() könnt ihr eure Daten auf die wesentlichen Kennzahlen verdichten. Im letzten Kapitel dieses Teils lernt ihr, wie ihr mehrere Datensätze über gemeinsame Schlüssel zusammenführt (siehe Kapitel 13).",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Beobachtungen zusammenfassen</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/joining-data.html",
    "href": "03-data-transformation/joining-data.html",
    "title": "13  Datensätze verbinden",
    "section": "",
    "text": "13.1 Beispieldaten\nNachdem ihr nun alle grundlegenden Operationen für einzelne Datensätze wie Filtern, Modifizieren und Aggregieren beherrscht, fehlt noch der Blick über den Tellerrand einer einzelnen Tabelle. In der Praxis liegen Daten fast nie in einer einzigen, sauberen Datei vor. Kundeninformationen stehen in einer Tabelle, Bestellungen in einer anderen und Produktdetails in einer dritten. In diesem Kapitel lernt ihr, wie ihr getrennte Datensätze über gemeinsame Schlüsselspalten – sogenannte Joins – zusammenführt.\nDie Fähigkeit, relationale Datenstrukturen aufzulösen, ist für reale Datenprojekte essenziell. Erst durch das Verknüpfen verschiedener Tabellen erhaltet ihr einen vollständigen Datensatz, in dem sich wirklich komplexe Fragen beantworten lassen. Stellt euch zwei Karteikästen vor: Einer enthält Kundennamen, der andere deren Bestellungen. Um zu wissen, welche Person was gekauft hat, braucht ihr einen Join. Das dplyr-Paket bietet hierfür verschiedene Varianten an, mit denen ihr exakt steuern könnt, welche Daten nach der Verknüpfung behalten oder verworfen werden.\nDie folgende Tabelle zeigt die Funktionen, die wir in diesem Abschnitt kennenlernen.\nUm die Mechanismen der einzelnen Joins bestmöglich zu verstehen, nutzen wir zunächst stark vereinfachte Beispieldaten.\nUm die verschiedenen Join-Typen zu verstehen, arbeiten wir mit zwei kleinen Tabellen, die wir selbst erstellen. So seht ihr genau, was passiert.\ncustomers &lt;- tibble(\n  customer_id = c(1, 2, 3, 4),\n  name = c(\"Anna\", \"Ben\", \"Cleo\", \"David\")\n)\n\npurchases &lt;- tibble(\n  purchase_id = c(101, 102, 103, 104),\n  customer_id = c(1, 2, 2, 5),\n  product = c(\"Laptop\", \"Mouse\", \"Keyboard\", \"Monitor\")\n)\nBeachtet: Anna (ID 1) hat eine Bestellung, Ben (ID 2) hat zwei, Cleo (ID 3) und David (ID 4) haben keine, und es gibt eine Bestellung von Kunde 5, der gar nicht in der Kundentabelle steht. Diese Ungleichheiten sind absichtlich, denn sie zeigen, wie sich die verschiedenen Join-Typen verhalten.\ncustomers\n\n# A tibble: 4 × 2\n  customer_id name \n        &lt;dbl&gt; &lt;chr&gt;\n1           1 Anna \n2           2 Ben  \n3           3 Cleo \n4           4 David\npurchases\n\n# A tibble: 4 × 3\n  purchase_id customer_id product \n        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;   \n1         101           1 Laptop  \n2         102           2 Mouse   \n3         103           2 Keyboard\n4         104           5 Monitor",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Datensätze verbinden</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/joining-data.html#sec-joining-data-grundprinzip",
    "href": "03-data-transformation/joining-data.html#sec-joining-data-grundprinzip",
    "title": "13  Datensätze verbinden",
    "section": "\n13.2 Das Grundprinzip",
    "text": "13.2 Das Grundprinzip\nEin Join verbindet zwei Tabellen über eine oder mehrere gemeinsame Spalten, die sogenannten Schlüssel (keys). Für jede Zeile in der linken Tabelle sucht R passende Zeilen in der rechten Tabelle, und umgekehrt. Was mit Zeilen passiert, die keinen Partner finden, hängt vom Join-Typ ab.\nAbbildung: Zwei Tabellen nebeneinander. Links “customers” mit den Spalten customer_id und name, rechts “purchases” mit den Spalten purchase_id, customer_id und product. Gestrichelte Linien verbinden die customer_id-Werte, die in beiden Tabellen vorkommen (1, 2). Die customer_id 3 und 4 in der linken Tabelle und die customer_id 5 in der rechten Tabelle haben keine Verbindung. Unter den Tabellen steht “Schlüssel: customer_id”.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Datensätze verbinden</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/joining-data.html#sec-joining-data-typen",
    "href": "03-data-transformation/joining-data.html#sec-joining-data-typen",
    "title": "13  Datensätze verbinden",
    "section": "\n13.3 Join-Typen",
    "text": "13.3 Join-Typen\ninner_join()\ninner_join() behält nur die Zeilen, die in beiden Tabellen einen passenden Partner haben. Alles ohne Treffer fällt raus.\n\ncustomers |&gt;\n  inner_join(purchases, by = \"customer_id\")\n\n# A tibble: 3 × 4\n  customer_id name  purchase_id product \n        &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;   \n1           1 Anna          101 Laptop  \n2           2 Ben           102 Mouse   \n3           2 Ben           103 Keyboard\n\n\nAnna und Ben tauchen auf, weil ihre IDs in beiden Tabellen vorkommen. Cleo und David (keine Bestellung) und Kunde 5 (nicht in der Kundentabelle) fehlen. Ben hat zwei Zeilen, weil er zwei Bestellungen hat.\nleft_join()\nleft_join() behält alle Zeilen der linken Tabelle. Wenn es in der rechten Tabelle keinen Treffer gibt, werden die Spalten der rechten Tabelle mit NA aufgefüllt.\n\ncustomers |&gt;\n  left_join(purchases, by = \"customer_id\")\n\n# A tibble: 5 × 4\n  customer_id name  purchase_id product \n        &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;   \n1           1 Anna          101 Laptop  \n2           2 Ben           102 Mouse   \n3           2 Ben           103 Keyboard\n4           3 Cleo           NA &lt;NA&gt;    \n5           4 David          NA &lt;NA&gt;    \n\n\nJetzt erscheinen auch Cleo und David, allerdings mit NA in den Bestellspalten. Die Bestellung von Kunde 5 fehlt weiterhin, weil er nicht in der linken Tabelle (customers) steht.\nleft_join() ist der mit Abstand häufigste Join-Typ. Er garantiert, dass keine Zeilen aus eurer Haupttabelle verloren gehen.\nright_join()\nright_join() ist das Spiegelbild von left_join(): Es behält alle Zeilen der rechten Tabelle.\n\ncustomers |&gt;\n  right_join(purchases, by = \"customer_id\")\n\n# A tibble: 4 × 4\n  customer_id name  purchase_id product \n        &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;   \n1           1 Anna          101 Laptop  \n2           2 Ben           102 Mouse   \n3           2 Ben           103 Keyboard\n4           5 &lt;NA&gt;          104 Monitor \n\n\nJetzt taucht Kunde 5 auf (mit NA beim Namen), aber Cleo und David fehlen, weil sie keine Bestellungen haben. In der Praxis kommt right_join() selten vor, weil ihr den gleichen Effekt erzielen könnt, indem ihr die Reihenfolge der Tabellen tauscht und left_join() verwendet.\nfull_join()\nfull_join() behält alle Zeilen aus beiden Tabellen, egal ob es einen Treffer gibt oder nicht. Fehlende Werte werden mit NA aufgefüllt.\n\ncustomers |&gt;\n  full_join(purchases, by = \"customer_id\")\n\n# A tibble: 6 × 4\n  customer_id name  purchase_id product \n        &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;   \n1           1 Anna          101 Laptop  \n2           2 Ben           102 Mouse   \n3           2 Ben           103 Keyboard\n4           3 Cleo           NA &lt;NA&gt;    \n5           4 David          NA &lt;NA&gt;    \n6           5 &lt;NA&gt;          104 Monitor \n\n\nHier ist wirklich alles dabei: Anna und Ben mit ihren Bestellungen, Cleo und David ohne Bestellungen, und Kunde 5 ohne Namen.\nÜbersicht\n\n\nJoin-Typ\nBehält Zeilen aus\n\n\n\ninner_join()\nNur Zeilen mit Treffer in beiden Tabellen\n\n\nleft_join()\nAlle Zeilen der linken Tabelle\n\n\nright_join()\nAlle Zeilen der rechten Tabelle\n\n\nfull_join()\nAlle Zeilen aus beiden Tabellen\n\n\n\nAbbildung: Vier kleine Diagramme nebeneinander, eines pro Join-Typ. Jedes Diagramm zeigt zwei Mengen (Kreise oder Rechtecke) als Venn-Diagramm. Die farblich hervorgehobene Fläche zeigt, welche Zeilen im Ergebnis enthalten sind. Bei inner_join ist nur die Schnittmenge farbig. Bei left_join ist der gesamte linke Kreis farbig. Bei right_join ist der gesamte rechte Kreis farbig. Bei full_join sind beide Kreise vollständig farbig. Unter jedem Diagramm steht der Funktionsname.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Datensätze verbinden</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/joining-data.html#sec-joining-data-keys",
    "href": "03-data-transformation/joining-data.html#sec-joining-data-keys",
    "title": "13  Datensätze verbinden",
    "section": "\n13.4 Schlüssel festlegen",
    "text": "13.4 Schlüssel festlegen\nAutomatische Erkennung\nWenn ihr by nicht angebt, sucht dplyr automatisch nach Spalten mit dem gleichen Namen in beiden Tabellen und nutzt diese als Schlüssel:\n\ncustomers |&gt;\n  inner_join(purchases)\n\nJoining with `by = join_by(customer_id)`\n\n\n# A tibble: 3 × 4\n  customer_id name  purchase_id product \n        &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;   \n1           1 Anna          101 Laptop  \n2           2 Ben           102 Mouse   \n3           2 Ben           103 Keyboard\n\n\nDie Meldung zeigt euch, welche Spalte als Schlüssel verwendet wurde. Das funktioniert gut, wenn die Spaltennamen eindeutig sind. Allerdings ist es besser, den Schlüssel immer explizit anzugeben, damit der Code auch dann korrekt bleibt, wenn sich die Daten ändern.\nUnterschiedliche Spaltennamen\nWenn die Schlüsselspalten in den beiden Tabellen unterschiedlich heißen, nutzt ihr join_by():\n\norders_renamed &lt;- purchases |&gt;\n  rename(buyer_id = customer_id)\n\ncustomers |&gt;\n  inner_join(orders_renamed, by = join_by(customer_id == buyer_id))\n\n# A tibble: 3 × 4\n  customer_id name  purchase_id product \n        &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;   \n1           1 Anna          101 Laptop  \n2           2 Ben           102 Mouse   \n3           2 Ben           103 Keyboard\n\n\njoin_by() ist die moderne Syntax in dplyr. Die ältere Schreibweise by = c(\"customer_id\" = \"buyer_id\") funktioniert ebenfalls, ist aber weniger lesbar.\nMehrere Schlüsselspalten\nManchmal braucht ihr mehr als eine Spalte, um die Zuordnung eindeutig zu machen. Das passiert zum Beispiel, wenn ihr Daten nach Jahr und Monat verknüpfen wollt:\n\nrevenue &lt;- tibble(\n  year = c(2024, 2024, 2025),\n  month = c(1, 2, 1),\n  total = c(5000, 6200, 5800)\n)\n\ntargets &lt;- tibble(\n  year = c(2024, 2024, 2025),\n  month = c(1, 2, 1),\n  target = c(5500, 6000, 6000)\n)\n\nrevenue |&gt;\n  left_join(targets, by = c(\"year\", \"month\"))\n\n# A tibble: 3 × 4\n   year month total target\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1  2024     1  5000   5500\n2  2024     2  6200   6000\n3  2025     1  5800   6000",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Datensätze verbinden</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/joining-data.html#sec-joining-data-kardinalitaet",
    "href": "03-data-transformation/joining-data.html#sec-joining-data-kardinalitaet",
    "title": "13  Datensätze verbinden",
    "section": "\n13.5 Duplikate und Kardinalität",
    "text": "13.5 Duplikate und Kardinalität\nBei Joins können sich Zeilen vervielfachen. Das habt ihr schon bei Ben gesehen: Weil er zwei Bestellungen hat, erscheint sein Name im Ergebnis zweimal. Das nennt man eine Eins-zu-Viele-Beziehung (one-to-many).\nWas passiert bei einer Viele-zu-Viele-Beziehung (many-to-many)? Dann bildet R das kartesische Produkt, also jede mögliche Kombination:\n\nleft &lt;- tibble(key = c(1, 1), value_left = c(\"a\", \"b\"))\nright &lt;- tibble(key = c(1, 1), value_right = c(\"x\", \"y\"))\n\nleft |&gt;\n  inner_join(right, by = \"key\")\n\nWarning in inner_join(left, right, by = \"key\"): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 1 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n# A tibble: 4 × 3\n    key value_left value_right\n  &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      \n1     1 a          x          \n2     1 a          y          \n3     1 b          x          \n4     1 b          y          \n\n\nAus zwei Zeilen links und zwei Zeilen rechts werden vier Zeilen. In der Praxis ist das fast immer ein Zeichen dafür, dass euer Schlüssel nicht eindeutig genug ist. dplyr gibt euch deshalb eine Warnung aus.\n\n\n\n\n\n\nTippZeilenzahl prüfen\n\n\n\nPrüft nach jedem Join kurz mit nrow(), ob die Zeilenzahl plausibel ist. Wenn sie unerwartet steigt, habt ihr wahrscheinlich Duplikate im Schlüssel. Mit count(key, sort = TRUE) findet ihr die Übeltäter.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Datensätze verbinden</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/joining-data.html#sec-joining-data-filtering",
    "href": "03-data-transformation/joining-data.html#sec-joining-data-filtering",
    "title": "13  Datensätze verbinden",
    "section": "\n13.6 Filtering-Joins",
    "text": "13.6 Filtering-Joins\nNeben den verbindenden Joins gibt es auch Filtering-Joins. Sie verändern die Spalten nicht, sondern filtern nur die Zeilen der linken Tabelle.\nsemi_join()\nsemi_join() behält die Zeilen der linken Tabelle, für die es einen Treffer in der rechten Tabelle gibt. Es fügt aber keine Spalten der rechten Tabelle hinzu:\n\ncustomers |&gt;\n  semi_join(purchases, by = \"customer_id\")\n\n# A tibble: 2 × 2\n  customer_id name \n        &lt;dbl&gt; &lt;chr&gt;\n1           1 Anna \n2           2 Ben  \n\n\nNur Anna und Ben erscheinen, weil sie Bestellungen haben. Aber die Bestellspalten fehlen. Das Ergebnis sieht aus wie ein filter(), und genau das ist der Zweck: Ihr filtert die Kundentabelle danach, welche Kunden überhaupt Bestellungen haben.\nanti_join()\nanti_join() ist das Gegenstück: Es behält die Zeilen der linken Tabelle, für die es keinen Treffer in der rechten Tabelle gibt.\n\ncustomers |&gt;\n  anti_join(purchases, by = \"customer_id\")\n\n# A tibble: 2 × 2\n  customer_id name \n        &lt;dbl&gt; &lt;chr&gt;\n1           3 Cleo \n2           4 David\n\n\nCleo und David erscheinen, weil sie keine Bestellungen haben. anti_join() ist perfekt, um fehlende Zuordnungen zu finden, also Daten, die in einer Tabelle vorhanden sind, aber in der anderen fehlen.\n\npurchases |&gt;\n  anti_join(customers, by = \"customer_id\")\n\n# A tibble: 1 × 3\n  purchase_id customer_id product\n        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  \n1         104           5 Monitor\n\n\nHier findet ihr die Bestellung von Kunde 5, die keinem Kunden zugeordnet werden kann. Das ist ein typischer Einsatz bei der Datenqualitätsprüfung.\nAbbildung: Zwei Diagramme nebeneinander. Links: semi_join. Zwei Tabellen “customers” und “purchases”. Der Pfeil zeigt von purchases auf customers. In der customers-Tabelle sind die Zeilen mit Treffern (Anna, Ben) hervorgehoben. Die purchases-Spalten werden NICHT hinzugefügt. Rechts: anti_join. Gleicher Aufbau, aber in der customers-Tabelle sind die Zeilen OHNE Treffer (Cleo, David) hervorgehoben.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Datensätze verbinden</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/joining-data.html#sec-joining-data-real",
    "href": "03-data-transformation/joining-data.html#sec-joining-data-real",
    "title": "13  Datensätze verbinden",
    "section": "\n13.7 Joins mit echten Daten",
    "text": "13.7 Joins mit echten Daten\nSchauen wir uns einen Join mit dem tweets-Datensatz an. Im Ordner data/ liegt eine CSV-Datei, die den Twitter-Accounts der Ampel-Politiker ihre Parteizugehörigkeit zuordnet. So eine Lookup-Tabelle ist ein typischer Anwendungsfall für Joins: Die Information steckt in einer separaten Datei, und ihr bringt sie per Join in euren Hauptdatensatz.\n\nparty_info &lt;- read_csv(\"data/party_info.csv\")\nparty_info\n\n# A tibble: 17 × 2\n   screen_name     party\n   &lt;chr&gt;           &lt;chr&gt;\n 1 ABaerbock       Grüne\n 2 ABaerbockArchiv Grüne\n 3 Bundeskanzler   SPD  \n 4 c_lindner       FDP  \n 5 cem_oezdemir    Grüne\n 6 hubertus_heil   SPD  \n 7 Karl_Lauterbach SPD  \n 8 klara_geywitz   SPD  \n 9 lisapaus        Grüne\n10 MarcoBuschmann  FDP  \n11 NancyFaeser     SPD  \n12 OlafScholz      SPD  \n13 starkwatzinger  FDP  \n14 SteffiLemke     Grüne\n15 SvenjaSchulze68 SPD  \n16 W_Schmidt_      SPD  \n17 Wissing         FDP  \n\n\nJetzt verbinden wir die Parteizugehörigkeit mit den Tweets und berechnen die durchschnittliche Interaktion pro Partei: tweets |&gt; inner_join(party_info, by = “screen_name”) |&gt; filter(!is_retweet) |&gt; group_by(party) |&gt; summarise( tweets = n(), avg_retweets = mean(retweet_count, na.rm = TRUE), .groups = “drop” )\n\nHier seht ihr, wie sich ein Join nahtlos in eine Pipe-Kette einreiht: Erst verbinden, dann filtern und zusammenfassen. Das ist ein typisches Muster in der Praxis.\n\n## Typische Probleme {#sec-joining-data-probleme}\n\n### Unerwartete Duplikate\n\nWenn euer Ergebnis plötzlich viel mehr Zeilen hat als erwartet, prüft die Eindeutigkeit eurer Schlüssel:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npurchases |&gt;\n  count(customer_id, sort = TRUE)\n\n# A tibble: 3 × 2\n  customer_id     n\n        &lt;dbl&gt; &lt;int&gt;\n1           2     2\n2           1     1\n3           5     1\n\n:::\nWenn dieselbe ID mehrfach vorkommt, bekommt ihr für jede Kombination eine Zeile.\nFehlende Treffer finden\nUm herauszufinden, welche Zeilen beim Join verloren gehen, nutzt anti_join() in beide Richtungen:\n\n# Kunden ohne Bestellungen\ncustomers |&gt;\n  anti_join(purchases, by = \"customer_id\")\n\n# A tibble: 2 × 2\n  customer_id name \n        &lt;dbl&gt; &lt;chr&gt;\n1           3 Cleo \n2           4 David\n\n# Bestellungen ohne Kunden\npurchases |&gt;\n  anti_join(customers, by = \"customer_id\")\n\n# A tibble: 1 × 3\n  purchase_id customer_id product\n        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  \n1         104           5 Monitor\n\n\nSpaltenkonflikte\nWenn beide Tabellen Spalten mit dem gleichen Namen haben, die keine Schlüssel sind, hängt dplyr automatisch Suffixe an:\n\nratings_a &lt;- tibble(customer_id = c(1, 2), rating = c(4, 5))\nratings_b &lt;- tibble(customer_id = c(1, 2), rating = c(3, 4))\n\nratings_a |&gt;\n  inner_join(ratings_b, by = \"customer_id\")\n\n# A tibble: 2 × 3\n  customer_id rating.x rating.y\n        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1           1        4        3\n2           2        5        4\n\n\nIhr könnt die Suffixe über den Parameter suffix anpassen:\n\nratings_a |&gt;\n  inner_join(ratings_b, by = \"customer_id\", suffix = c(\"_store\", \"_online\"))\n\n# A tibble: 2 × 3\n  customer_id rating_store rating_online\n        &lt;dbl&gt;        &lt;dbl&gt;         &lt;dbl&gt;\n1           1            4             3\n2           2            5             4",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Datensätze verbinden</span>"
    ]
  },
  {
    "objectID": "03-data-transformation/joining-data.html#sec-joining-data-zusammenfassung",
    "href": "03-data-transformation/joining-data.html#sec-joining-data-zusammenfassung",
    "title": "13  Datensätze verbinden",
    "section": "\n13.8 Kurz zusammengefasst",
    "text": "13.8 Kurz zusammengefasst\n\nJoins verbinden zwei Tabellen über gemeinsame Schlüsselspalten.\n\ninner_join() behält nur Zeilen mit Treffern in beiden Tabellen.\n\nleft_join() behält alle Zeilen der linken Tabelle, ist der häufigste Join-Typ.\n\nright_join() und full_join() behalten Zeilen der rechten beziehungsweise beider Tabellen.\nGebt den Schlüssel immer explizit mit by an. Bei unterschiedlichen Spaltennamen nutzt join_by().\n\nsemi_join() und anti_join() filtern die linke Tabelle, ohne Spalten hinzuzufügen.\nPrüft nach jedem Join die Zeilenzahl mit nrow(), um unerwartete Duplikate zu erkennen.\n\nDamit habt ihr alle wichtigen Werkzeuge für die Datentransformation kennengelernt. Ihr wisst, wie ihr Daten ladet (siehe Kapitel 5), Spalten auswählt (siehe Kapitel 8), Variablen verändert und neue berechnet (siehe Kapitel 9 und Kapitel 10), Zeilen filtert (siehe Kapitel 11), Daten zusammenfasst (siehe Kapitel 12) und Tabellen verbindet. Im nächsten Teil des Buches geht es darum, eure Ergebnisse sichtbar zu machen: mit Datenvisualisierungen.",
    "crumbs": [
      "Datentransformation",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Datensätze verbinden</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/grammar-of-graphics.html",
    "href": "04-data-visualization/grammar-of-graphics.html",
    "title": "14  Grammar of Graphics",
    "section": "",
    "text": "14.1 Die Idee\nBis hierhin habt ihr gelernt, Daten zu laden, zu filtern, zu verändern und zusammenzufassen. Jetzt kommt der Schritt, auf den viele am meisten warten: die Visualisierung. Denn ein gutes Diagramm zeigt in Sekunden, wofür ihr sonst Dutzende Zahlen lesen müsstet.\nIn R nutzen wir dafür ggplot2, das meistgenutzte Visualisierungspaket. Der Name steht für Grammar of Graphics, ein Konzept, das die Art und Weise, wie wir über Diagramme denken, grundlegend verändert hat. Statt einzelne Diagrammtypen auswendig zu lernen (Balkendiagramm, Liniendiagramm, Streudiagramm …), beschreibt ihr ein Diagramm als Kombination aus Bausteinen. Und genau diese Denkweise macht ggplot2 so mächtig.\nDie Grammar of Graphics stammt aus dem Buch The Grammar of Graphics von Leland Wilkinson (1999). Die Grundidee: Jedes statistische Diagramm lässt sich als Kombination unabhängiger Bausteine beschreiben, genau wie ein Satz in einer natürlichen Sprache aus Subjekt, Verb und Objekt besteht.\nHadley Wickham hat diese Idee aufgegriffen und in ggplot2 umgesetzt. In ggplot2 baut ihr ein Diagramm Schicht für Schicht auf, indem ihr Bausteine mit dem +-Operator verbindet.\nDie wichtigste Erkenntnis dabei ist: Ein Balkendiagramm und ein Liniendiagramm unterscheiden sich nicht grundlegend. Beide haben Daten, eine Zuordnung von Variablen zu visuellen Eigenschaften und eine geometrische Form. Der einzige Unterschied ist die Form: Balken statt Linie. Wenn ihr das verinnerlicht habt, könnt ihr jedes Diagramm bauen, das ihr euch vorstellen könnt.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Grammar of Graphics</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/grammar-of-graphics.html#die-drei-essenziellen-bausteine",
    "href": "04-data-visualization/grammar-of-graphics.html#die-drei-essenziellen-bausteine",
    "title": "14  Grammar of Graphics",
    "section": "\n14.2 Die drei essenziellen Bausteine",
    "text": "14.2 Die drei essenziellen Bausteine\nJedes Diagramm in ggplot2 braucht exakt drei Dinge:\n\n\nDaten (data): Welcher Datensatz wird dargestellt?\n\nZuordnungen (aesthetic mappings): Welche Variable wird auf welche visuelle Eigenschaft abgebildet?\n\nGeometrien (geoms): Welche geometrische Form stellt die Daten dar?\n\nSchauen wir uns das an einem Beispiel an. Wir wollen wissen, welche Accounts am meisten twittern. Dafür bereiten wir kurz die Top-10-Accounts vor und zeigen sie als Balkendiagramm:\n\ntop_accounts &lt;- tweets |&gt;\n  count(screen_name, sort = TRUE) |&gt;\n  head(10)\n\n\ntop_accounts |&gt;\n  ggplot() +\n  aes(x = screen_name, y = n) +\n  geom_col()\n\n\n\n\n\n\nAbbildung 14.1: Ein einfaches Balkendiagramm: Daten, Mapping, Geometrie.\n\n\n\n\nDrei Zeilen, drei Bausteine, drei +:\n\n\ntop_accounts |&gt; ggplot() übergibt den Datensatz per Pipe.\n\naes(x = screen_name, y = n) ist das Mapping: Der Accountname auf die x-Achse, die Anzahl auf die y-Achse.\n\ngeom_col() zeichnet Balken mit den vorberechneten Werten.\n\nDas Ergebnis sieht noch nicht besonders schön aus (die Namen überlappen sich, die Reihenfolge ist alphabetisch statt nach Häufigkeit), aber es ist ein vollständiges Diagramm. Alles, was danach kommt, ist Feinschliff.\n\n\n\n\n\n\nTippWarum diese Schreibweise?\n\n\n\nIn vielen Tutorials seht ihr aes() innerhalb von ggplot(), zum Beispiel ggplot(data, aes(x = ..., y = ...)). Das funktioniert genauso, denn ggplot2 ist sehr flexibel. In diesem Buch schreiben wir jede Ebene als eigenen Baustein mit +, weil es die Idee der Grammar of Graphics am deutlichsten zeigt: Jede Zeile ist eine eigene Schicht, die ihr unabhängig ändern, entfernen oder ersetzen könnt.\n\n\nDaten\nDer Datensatz ist immer ein Tibble oder Data Frame. Ihr übergebt ihn per Pipe an ggplot(). Oft kommt er direkt aus einer Aufbereitungskette:\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  count(screen_name, sort = TRUE) |&gt;\n  head(10) |&gt;\n  ggplot() +\n  aes(x = screen_name, y = n) +\n  geom_col()\n\n\n\n\n\n\nAbbildung 14.2: Der Datensatz kommt direkt aus einer Pipe-Kette.\n\n\n\n\nBeachtet den Wechsel: Innerhalb der Datenaufbereitung nutzt ihr |&gt;, aber ab ggplot() wechselt ihr zu +. Das liegt daran, dass ggplot2 seine eigene Verkettungslogik hat. Das + fügt Ebenen zum Diagramm hinzu.\n\n\n\n\n\n\nTippPipe und Plus\n\n\n\nSolange ihr mit dem Datensatz arbeitet, pipt ihr (|&gt;). Sobald ihr am Diagramm arbeitet, plust ihr (+). Die Grenze ist ggplot().\n\n\nAesthetic Mappings\nDas Mapping (aes()) ist das Herzstück. Es sagt ggplot2, welche Variable auf welche visuelle Eigenschaft abgebildet wird. Die häufigsten Aesthetics sind:\n\n\nAesthetic\nBeschreibung\n\n\n\nx\nPosition auf der x-Achse\n\n\ny\nPosition auf der y-Achse\n\n\ncolor\nFarbe (Linien, Punkte)\n\n\nfill\nFüllfarbe (Balken, Flächen)\n\n\nsize\nGröße\n\n\nshape\nForm (Punkte)\n\n\nalpha\nTransparenz\n\n\n\nIm Beispiel oben haben wir x und y verwendet. Probieren wir ein Beispiel mit fill, um die Balken nach einer zweiten Variable einzufärben:\n\ntweets |&gt;\n  count(screen_name, is_retweet) |&gt;\n  ggplot() +\n  aes(x = screen_name, y = n, fill = is_retweet) +\n  geom_col() +\n  coord_flip()\n\n\n\n\n\n\nAbbildung 14.3: Mit fill werden die Balken nach einer zweiten Variable eingefärbt.\n\n\n\n\nJetzt sehen wir für jeden Account, wie viele Original-Tweets und wie viele Retweets es gibt. ggplot2 erstellt automatisch eine Legende. Das ist die Stärke des Mapping-Konzepts: Ihr beschreibt was dargestellt werden soll, nicht wie es aussehen soll.\nGeometrien\nDie Geometrie bestimmt die visuelle Form. Jede geom_*-Funktion zeichnet eine andere Art von Grafik. Hier sind die wichtigsten:\n\n\nGeom\nDarstellung\nTypischer Einsatz\n\n\n\ngeom_bar()\nBalken\nHäufigkeiten zählen\n\n\ngeom_col()\nBalken\nVorberechnete Werte darstellen\n\n\ngeom_point()\nPunkte\nStreudiagramme\n\n\ngeom_line()\nLinien\nZeitreihen\n\n\ngeom_histogram()\nHistogramm\nVerteilungen\n\n\ngeom_boxplot()\nBoxplot\nVerteilungsvergleiche\n\n\n\nDer Unterschied zwischen geom_bar() und geom_col() ist wichtig: geom_bar() zählt die Häufigkeit selbst, geom_col() erwartet, dass ihr den y-Wert schon berechnet habt.\n\ntweets |&gt;\n  ggplot() +\n  aes(x = screen_name) +\n  geom_bar()\n\n\n\n\n\n\nAbbildung 14.4: geom_bar() zählt selbst, geom_col() nimmt vorberechnete Werte.\n\n\n\n\nHier zählt geom_bar() die Häufigkeit jedes Accountnamens selbst. Das Ergebnis ist unübersichtlich, weil es sehr viele Accounts gibt. In der Praxis bereitet ihr die Daten deshalb vorher auf und nutzt geom_col():\n\ntop_accounts |&gt;\n  ggplot() +\n  aes(x = screen_name, y = n) +\n  geom_col()\n\n\n\n\n\n\nAbbildung 14.5: geom_col() braucht einen vorberechneten y-Wert.\n\n\n\n\nAbbildung: Drei Karten nebeneinander, die die drei essenziellen Bausteine zeigen. Karte 1: “Data” mit einem Tabellensymbol und dem Label “top_accounts”. Karte 2: “Mapping” mit dem Label “aes(x = screen_name, y = n)” und Pfeilen von den Variablen zu den Achsen. Karte 3: “Geom” mit dem Label “geom_col()” und einer kleinen Balkengrafik. Unter den drei Karten steht ein Pluszeichen zwischen jeder Karte, und darunter das fertige Diagramm.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Grammar of Graphics</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/grammar-of-graphics.html#die-weiteren-ebenen",
    "href": "04-data-visualization/grammar-of-graphics.html#die-weiteren-ebenen",
    "title": "14  Grammar of Graphics",
    "section": "\n14.3 Die weiteren Ebenen",
    "text": "14.3 Die weiteren Ebenen\nNeben den drei essenziellen Bausteinen kennt die Grammar of Graphics noch weitere Ebenen. Diese sind optional und dienen dazu, das Diagramm zu verfeinern. Ihr müsst sie nicht für jedes Diagramm kennen, aber es hilft zu wissen, dass sie existieren.\nStatistische Transformationen\nManchmal wollt ihr die Daten nicht direkt darstellen, sondern erst eine statistische Zusammenfassung berechnen. Tatsächlich tut geom_bar() genau das bereits: Es zählt die Häufigkeiten für euch. Hinter jeder Geometrie steckt eine statistische Transformation (stat).\nIn den meisten Fällen müsst ihr euch darum nicht kümmern, weil die Geoms eine sinnvolle Voreinstellung mitbringen. Es gibt aber Situationen, in denen ihr die Statistik explizit wechseln wollt:\n\ntop_accounts |&gt;\n  ggplot() +\n  aes(x = screen_name, y = n) +\n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\nAbbildung 14.6: Mit stat = ‘identity’ nimmt geom_bar() die Werte direkt, statt zu zählen.\n\n\n\n\nDas ist gleichbedeutend mit geom_col(). In der Praxis nutzt ihr fast immer die Standardeinstellung und greift nur ein, wenn ihr einen speziellen Fall habt.\nSkalen\nSkalen (scale_*) steuern, wie die Werte auf visuelle Eigenschaften abgebildet werden. Zum Beispiel, welche Farben verwendet werden oder wie die Achsen beschriftet sind.\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  ggplot() +\n  aes(x = lang, fill = lang) +\n  geom_bar() +\n  scale_fill_brewer(palette = \"Set2\")\n\n\n\n\n\n\nAbbildung 14.7: Skalen steuern Farben und Achsenbeschriftungen.\n\n\n\n\nAuch hier gilt: Die Standardeinstellungen sind meistens ausreichend. Skalen werden vor allem dann wichtig, wenn ihr Farben anpassen, Achsen formatieren oder Legenden steuern wollt. Das vertiefen wir im Kapitel über das Verfeinern von Diagrammen.\nKoordinatensysteme\nDas Koordinatensystem bestimmt, wie x und y auf die Fläche abgebildet werden. Das Standard-Koordinatensystem ist kartesisch (rechtwinklig). Für manche Diagramme ist ein anderes System sinnvoller:\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  ggplot() +\n  aes(x = lang) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\nAbbildung 14.8: coord_flip() dreht die Achsen um 90 Grad.\n\n\n\n\ncoord_flip() tauscht x- und y-Achse. Das macht Balkendiagramme mit langen Beschriftungen lesbarer. Es gibt auch coord_polar() für Kreisdiagramme, aber die werden in der explorativen Analyse selten gebraucht.\nFacetten\nFacetten teilen ein Diagramm in mehrere kleine Teildiagramme auf, eines pro Ausprägung einer Variable. Das ist nützlich, um Vergleiche übersichtlich darzustellen:\n\ntweets |&gt;\n  filter(!is_retweet, lang %in% c(\"de\", \"en\", \"fr\")) |&gt;\n  ggplot() +\n  aes(x = retweet_count) +\n  geom_histogram(bins = 30) +\n  facet_wrap(~ lang)\n\n\n\n\n\n\nAbbildung 14.9: Facetten erzeugen ein Teildiagramm pro Sprache.\n\n\n\n\nfacet_wrap(~ lang) erstellt ein Histogramm pro Sprache. Das ist oft aussagekräftiger als ein einzelnes Diagramm mit Farbcodierung, weil die Teildiagramme leichter zu vergleichen sind.\nThemes\nThemes steuern das Gesamtaussehen des Diagramms: Hintergrundfarbe, Schriftart, Gitterlinien und so weiter. Sie haben nichts mit den Daten zu tun, sondern nur mit der Optik.\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  ggplot() +\n  aes(x = lang) +\n  geom_bar() +\n  theme_minimal()\n\n\n\n\n\n\nAbbildung 14.10: Verschiedene Themes ändern das Aussehen, nicht die Daten.\n\n\n\n\nggplot2 bringt mehrere Themes mit: theme_minimal(), theme_classic(), theme_light(), theme_dark() und andere. Im Kapitel über das Verfeinern von Diagrammen gehen wir ausführlicher darauf ein.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Grammar of Graphics</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/grammar-of-graphics.html#alles-zusammen",
    "href": "04-data-visualization/grammar-of-graphics.html#alles-zusammen",
    "title": "14  Grammar of Graphics",
    "section": "\n14.4 Alles zusammen",
    "text": "14.4 Alles zusammen\nHier ist die vollständige Schichtung, die die Grammar of Graphics beschreibt:\n\n\nEbene\nFunktion in ggplot2\nRolle\n\n\n\nDaten\ndata |&gt; ggplot()\nWas wird dargestellt?\n\n\nMapping\naes(...)\nWelche Variable wird wohin abgebildet?\n\n\nGeometrie\ngeom_*()\nWelche Form?\n\n\nStatistik\nstat_*()\nWelche Berechnung? (meist automatisch)\n\n\nSkalen\nscale_*()\nWie werden Werte in Optik übersetzt?\n\n\nKoordinaten\ncoord_*()\nWelches Koordinatensystem?\n\n\nFacetten\nfacet_*()\nAufteilen in Teildiagramme?\n\n\nTheme\ntheme_*()\nWie sieht es insgesamt aus?\n\n\n\nDie ersten drei Zeilen (fett) braucht ihr immer. Der Rest ist optional und dient dazu, das Diagramm zu verfeinern. Für die explorative Analyse reicht es oft völlig, nur die drei essenziellen Bausteine zu verwenden und den Rest den Standards zu überlassen.\nAbbildung: Ein Schichtenmodell wie ein Stapel Folien oder ein Sandwich von unten nach oben. Ganz unten liegt die Schicht “Data” (blau). Darüber “Mapping / Aesthetics” (grün). Darüber “Geom” (orange). Darüber, etwas abgesetzt und leicht transparent: “Stat” (grau), “Scale” (grau), “Coord” (grau), “Facet” (grau), “Theme” (grau). Die unteren drei Schichten sind groß und kräftig gefärbt, die oberen fünf kleiner und dezent. Eine Klammer links umfasst die unteren drei mit der Beschriftung “Essenziell”. Eine Klammer rechts umfasst die oberen fünf mit der Beschriftung “Verfeinern”.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Grammar of Graphics</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/grammar-of-graphics.html#der-typische-ablauf",
    "href": "04-data-visualization/grammar-of-graphics.html#der-typische-ablauf",
    "title": "14  Grammar of Graphics",
    "section": "\n14.5 Der typische Ablauf",
    "text": "14.5 Der typische Ablauf\nIn der Praxis baut ihr ein Diagramm fast immer so auf:\n\nDaten aufbereiten (filtern, gruppieren, zusammenfassen)\n\nggplot() aufrufen und das Mapping festlegen\nGeometrie hinzufügen\nBei Bedarf verfeinern (Achsen, Farben, Theme)\n\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  count(screen_name, sort = TRUE) |&gt;\n  head(10) |&gt;\n  ggplot() +\n  aes(x = reorder(screen_name, n), y = n) +\n  geom_col() +\n  coord_flip() +\n  labs(x = \"Account\", y = \"Tweets\")\n\n\n\n\n\n\nAbbildung 14.11: Ein typischer Ablauf: Daten aufbereiten, dann visualisieren.\n\n\n\n\nHier sehen wir die Pipe-Kette und ggplot2 zusammenarbeiten: Erst filtern wir, dann zählen wir die Tweets pro Account, nehmen die Top 10 und visualisieren sie als horizontales Balkendiagramm. reorder(screen_name, n) sortiert die Balken nach Häufigkeit statt alphabetisch.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Grammar of Graphics</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/grammar-of-graphics.html#kurz-zusammengefasst",
    "href": "04-data-visualization/grammar-of-graphics.html#kurz-zusammengefasst",
    "title": "14  Grammar of Graphics",
    "section": "\n14.6 Kurz zusammengefasst",
    "text": "14.6 Kurz zusammengefasst\n\nDie Grammar of Graphics beschreibt Diagramme als Kombination unabhängiger Bausteine.\nJedes Diagramm in ggplot2 braucht drei Dinge: Daten (data), Zuordnungen (aes()) und eine Geometrie (geom_*()).\nWeitere Ebenen wie Skalen, Koordinaten, Facetten und Themes verfeinern das Diagramm, sind aber optional.\nInnerhalb der Datenaufbereitung nutzt ihr |&gt;, ab ggplot() nutzt ihr +.\n\ngeom_bar() zählt Häufigkeiten selbst, geom_col() erwartet vorberechnete Werte.\nFacetten (facet_wrap()) teilen ein Diagramm in Teildiagramme auf und erleichtern Vergleiche.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Grammar of Graphics</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/bar-charts.html",
    "href": "04-data-visualization/bar-charts.html",
    "title": "15  Balkendiagramme",
    "section": "",
    "text": "15.1 Einfaches Balkendiagramm\nBalkendiagramme sind das Arbeitspferd der explorativen Datenanalyse. Wenn ihr wissen wollt, wie oft etwas vorkommt oder wie sich Kategorien vergleichen lassen, greift ihr fast immer zu einem Balkendiagramm. Claus Wilke nennt sie in Fundamentals of Data Visualization das Standardwerkzeug für die Darstellung von Mengen und Proportionen (Wilke 2019).\nIn diesem Kapitel zeigen wir, wie ihr Balkendiagramme mit ggplot2 baut, wann ihr geom_bar() und wann geom_col() nutzt, und welche Varianten es gibt.\nDie einfachste Variante: Wie viele Tweets hat jeder Account veröffentlicht? Wir bereiten die Daten vor und nutzen geom_col():\ntweets |&gt;\n  count(screen_name, sort = TRUE) |&gt;\n  head(10) |&gt;\n  ggplot() +\n  aes(x = reorder(screen_name, n), y = n) +\n  geom_col() +\n  coord_flip() +\n  labs(x = NULL, y = \"Anzahl Tweets\")\n\n\n\n\n\n\nAbbildung 15.1: Anzahl der Tweets pro Account (Top 10).\nDrei Dinge, die dieses Diagramm besser machen:",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Balkendiagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/bar-charts.html#einfaches-balkendiagramm",
    "href": "04-data-visualization/bar-charts.html#einfaches-balkendiagramm",
    "title": "15  Balkendiagramme",
    "section": "",
    "text": "reorder(screen_name, n) sortiert die Balken nach Häufigkeit statt alphabetisch.\n\ncoord_flip() dreht die Achsen, damit die Accountnamen links lesbar sind.\n\nlabs(x = NULL) entfernt die überflüssige Achsenbeschriftung.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Balkendiagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/bar-charts.html#geom_bar-vs-geom_col",
    "href": "04-data-visualization/bar-charts.html#geom_bar-vs-geom_col",
    "title": "15  Balkendiagramme",
    "section": "\n15.2 geom_bar() vs geom_col()\n",
    "text": "15.2 geom_bar() vs geom_col()\n\nIn ggplot2 gibt es zwei Geoms für Balkendiagramme:\n\n\nGeom\nZählt selbst?\nBraucht y?\nTypischer Einsatz\n\n\n\ngeom_bar()\nJa\nNein\nRohdaten, Häufigkeiten zählen\n\n\ngeom_col()\nNein\nJa\nVorberechnete Werte darstellen\n\n\n\ngeom_bar() zählt automatisch, wie oft jeder x-Wert vorkommt:\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  ggplot() +\n  aes(x = lang) +\n  geom_bar()\n\n\n\n\n\n\nAbbildung 15.2: geom_bar() zählt die Häufigkeit selbst.\n\n\n\n\ngeom_col() erwartet, dass ihr die Werte vorher berechnet habt:\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  count(lang) |&gt;\n  ggplot() +\n  aes(x = lang, y = n) +\n  geom_col()\n\n\n\n\n\n\nAbbildung 15.3: geom_col() nimmt vorberechnete Werte.\n\n\n\n\nIn der Praxis nutzt ihr meist geom_col(), weil ihr die Daten vorher ohnehin mit count() oder summarise() aufbereitet.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Balkendiagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/bar-charts.html#gestapelte-balken",
    "href": "04-data-visualization/bar-charts.html#gestapelte-balken",
    "title": "15  Balkendiagramme",
    "section": "\n15.3 Gestapelte Balken",
    "text": "15.3 Gestapelte Balken\nWenn ihr eine zweite Variable als Farbe einbringt, stapelt ggplot2 die Balken automatisch:\n\ntweets |&gt;\n  count(screen_name, is_retweet, sort = TRUE) |&gt;\n  filter(screen_name %in% (tweets |&gt; count(screen_name, sort = TRUE) |&gt; head(10) |&gt; pull(screen_name))) |&gt;\n  ggplot() +\n  aes(x = reorder(screen_name, n), y = n, fill = is_retweet) +\n  geom_col() +\n  coord_flip() +\n  labs(x = NULL, y = \"Anzahl Tweets\", fill = \"Retweet?\")\n\n\n\n\n\n\nAbbildung 15.4: Gestapelte Balken zeigen die Zusammensetzung.\n\n\n\n\nGestapelte Balken zeigen die Zusammensetzung jedes Balkens. Das ist nützlich, wenn euch sowohl die Gesamtzahl als auch der Anteil interessiert.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Balkendiagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/bar-charts.html#gruppierte-balken",
    "href": "04-data-visualization/bar-charts.html#gruppierte-balken",
    "title": "15  Balkendiagramme",
    "section": "\n15.4 Gruppierte Balken",
    "text": "15.4 Gruppierte Balken\nWenn die Teile schwer zu vergleichen sind, weil die Balken unterschiedlich hoch sind, hilft position = \"dodge\":\n\ntweets |&gt;\n  count(screen_name, is_retweet, sort = TRUE) |&gt;\n  filter(screen_name %in% (tweets |&gt; count(screen_name, sort = TRUE) |&gt; head(10) |&gt; pull(screen_name))) |&gt;\n  ggplot() +\n  aes(x = reorder(screen_name, n), y = n, fill = is_retweet) +\n  geom_col(position = \"dodge\") +\n  coord_flip() +\n  labs(x = NULL, y = \"Anzahl Tweets\", fill = \"Retweet?\")\n\n\n\n\n\n\nAbbildung 15.5: Gruppierte Balken machen Teilmengen vergleichbar.\n\n\n\n\nJetzt stehen die Balken nebeneinander statt übereinander. Das macht den Vergleich zwischen Original-Tweets und Retweets pro Account leichter.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Balkendiagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/bar-charts.html#prozentuale-balken",
    "href": "04-data-visualization/bar-charts.html#prozentuale-balken",
    "title": "15  Balkendiagramme",
    "section": "\n15.5 Prozentuale Balken",
    "text": "15.5 Prozentuale Balken\nMit position = \"fill\" werden die Balken auf 100% normiert. Das zeigt reine Proportionen:\n\ntweets |&gt;\n  count(screen_name, is_retweet) |&gt;\n  filter(screen_name %in% (tweets |&gt; count(screen_name, sort = TRUE) |&gt; head(10) |&gt; pull(screen_name))) |&gt;\n  ggplot() +\n  aes(x = reorder(screen_name, -n), y = n, fill = is_retweet) +\n  geom_col(position = \"fill\") +\n  coord_flip() +\n  labs(x = NULL, y = \"Anteil\", fill = \"Retweet?\")\n\n\n\n\n\n\nAbbildung 15.6: Prozentuale Balken zeigen Anteile.\n\n\n\n\nHier seht ihr sofort, welcher Account den höchsten Anteil an Retweets hat — unabhängig davon, wie viele Tweets insgesamt veröffentlicht wurden. Diese Darstellung eignet sich besonders gut, wenn euch Proportionen wichtiger sind als absolute Zahlen (Wilke 2019).",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Balkendiagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/bar-charts.html#balken-nach-wert",
    "href": "04-data-visualization/bar-charts.html#balken-nach-wert",
    "title": "15  Balkendiagramme",
    "section": "\n15.6 Balken nach Wert",
    "text": "15.6 Balken nach Wert\nBisher haben wir Häufigkeiten gezählt. Oft wollt ihr aber einen berechneten Wert darstellen, zum Beispiel den durchschnittlichen Umsatz:\n\norders |&gt;\n  group_by(financial_status) |&gt;\n  summarise(avg_price = mean(total_price, na.rm = TRUE), .groups = \"drop\") |&gt;\n  ggplot() +\n  aes(x = reorder(financial_status, avg_price), y = avg_price) +\n  geom_col() +\n  coord_flip() +\n  labs(x = NULL, y = \"Ø Umsatz (€)\")\n\n\n\n\n\n\nAbbildung 15.7: Durchschnittlicher Umsatz nach Zahlungsstatus.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Balkendiagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/bar-charts.html#typische-fehler",
    "href": "04-data-visualization/bar-charts.html#typische-fehler",
    "title": "15  Balkendiagramme",
    "section": "\n15.7 Typische Fehler",
    "text": "15.7 Typische Fehler\nZu viele Kategorien\nBalkendiagramme mit mehr als 10–15 Balken werden schnell unlesbar. Filtert vorher auf die relevantesten Kategorien. Ein guter Ansatz: Die Top N anzeigen und den Rest ausblenden oder zusammenfassen.\nUnsortierte Balken\nAlphabetisch sortierte Balken erschweren den Vergleich. Nutzt reorder() oder fct_reorder(), um die Balken nach Wert zu sortieren.\nY-Achse beginnt nicht bei Null\nBei Balkendiagrammen muss die y-Achse immer bei Null beginnen, weil die Länge des Balkens die zentrale Information trägt. ggplot2 tut das standardmäßig, aber wenn ihr die Achse manuell anpasst, achtet darauf.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Balkendiagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/bar-charts.html#kurz-zusammengefasst",
    "href": "04-data-visualization/bar-charts.html#kurz-zusammengefasst",
    "title": "15  Balkendiagramme",
    "section": "\n15.8 Kurz zusammengefasst",
    "text": "15.8 Kurz zusammengefasst\n\n\ngeom_bar() zählt Häufigkeiten selbst, geom_col() nimmt vorberechnete Werte.\n\nposition = \"stack\" (Standard) stapelt, \"dodge\" gruppiert, \"fill\" normiert auf 100%.\nSortiert Balken mit reorder() nach Wert statt alphabetisch.\nNutzt coord_flip() für horizontale Balken mit langen Beschriftungen.\nHaltet die Anzahl der Kategorien übersichtlich (maximal 10–15).\n\n\n\n\n\nWilke, C. 2019. Fundamentals of data visualization: a primer on making informative and compelling figures. First edition. O’Reilly Media.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Balkendiagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/scatter-plots.html",
    "href": "04-data-visualization/scatter-plots.html",
    "title": "16  Punktediagramme",
    "section": "",
    "text": "16.1 Einfaches Punktediagramm\nPunktediagramme (Scatter Plots) zeigen die Beziehung zwischen zwei numerischen Variablen. Jede Beobachtung wird als Punkt dargestellt, wobei die Position durch die Werte der beiden Variablen bestimmt wird. Claus Wilke beschreibt sie als das wichtigste Werkzeug, um Zusammenhänge zwischen Variablen zu erkennen (Wilke 2019).\nGibt es einen Zusammenhang zwischen Retweets und Likes? Das lässt sich am schnellsten mit geom_point() prüfen:\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  ggplot() +\n  aes(x = retweet_count, y = favorite_count) +\n  geom_point()\n\n\n\n\n\n\nAbbildung 16.1: Zusammenhang zwischen Retweets und Likes.\nJeder Punkt ist ein Tweet. Die meisten Punkte kleben in der unteren linken Ecke, weil die Mehrheit der Tweets nur wenige Retweets und Likes bekommt. Ein paar Ausreißer stechen heraus.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Punktediagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/scatter-plots.html#overplotting-vermeiden",
    "href": "04-data-visualization/scatter-plots.html#overplotting-vermeiden",
    "title": "16  Punktediagramme",
    "section": "\n16.2 Overplotting vermeiden",
    "text": "16.2 Overplotting vermeiden\nWenn viele Punkte übereinander liegen, seht ihr nicht, wie viele es tatsächlich sind. Es gibt mehrere Strategien:\nTransparenz\nMit alpha macht ihr die Punkte halbtransparent. Dort, wo viele Punkte überlagern, wird es dunkler:\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  ggplot() +\n  aes(x = retweet_count, y = favorite_count) +\n  geom_point(alpha = 0.2)\n\n\n\n\n\n\nAbbildung 16.2: Transparente Punkte zeigen die Dichte.\n\n\n\n\nJitter\ngeom_jitter() verschiebt die Punkte leicht zufällig, damit sie sich nicht exakt überlagern:\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  ggplot() +\n  aes(x = retweet_count, y = favorite_count) +\n  geom_jitter(alpha = 0.2, width = 5, height = 5)\n\n\n\n\n\n\nAbbildung 16.3: Jitter verschiebt Punkte leicht, um Überlagerung zu reduzieren.\n\n\n\n\nLogarithmische Skalen\nWenn die Daten stark rechtsschief verteilt sind (wenige sehr hohe Werte), hilft eine logarithmische Skala:\n\ntweets |&gt;\n  filter(!is_retweet, retweet_count &gt; 0, favorite_count &gt; 0) |&gt;\n  ggplot() +\n  aes(x = retweet_count, y = favorite_count) +\n  geom_point(alpha = 0.2) +\n  scale_x_log10() +\n  scale_y_log10()\n\n\n\n\n\n\nAbbildung 16.4: Logarithmische Achsen spreizen die niedrigen Werte.\n\n\n\n\nJetzt ist der Zusammenhang viel besser zu erkennen. Die Punkte verteilen sich gleichmäßiger, und ihr seht ein klares Muster.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Punktediagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/scatter-plots.html#farbe-als-dritte-variable",
    "href": "04-data-visualization/scatter-plots.html#farbe-als-dritte-variable",
    "title": "16  Punktediagramme",
    "section": "\n16.3 Farbe als dritte Variable",
    "text": "16.3 Farbe als dritte Variable\nMit color könnt ihr eine dritte Variable einbringen:\n\ntweets |&gt;\n  filter(!is_retweet, retweet_count &gt; 0, favorite_count &gt; 0) |&gt;\n  ggplot() +\n  aes(x = retweet_count, y = favorite_count, color = is_quote_status) +\n  geom_point(alpha = 0.3) +\n  scale_x_log10() +\n  scale_y_log10()\n\n\n\n\n\n\nAbbildung 16.5: Farbe zeigt eine kategoriale Variable.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Punktediagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/scatter-plots.html#größe-als-vierte-variable",
    "href": "04-data-visualization/scatter-plots.html#größe-als-vierte-variable",
    "title": "16  Punktediagramme",
    "section": "\n16.4 Größe als vierte Variable",
    "text": "16.4 Größe als vierte Variable\nNeben Farbe könnt ihr auch die Größe der Punkte an eine Variable koppeln. Diesen Diagrammtyp nennt man Bubble Chart:\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  group_by(screen_name) |&gt;\n  summarise(\n    avg_retweets = mean(retweet_count, na.rm = TRUE),\n    avg_likes = mean(favorite_count, na.rm = TRUE),\n    tweet_count = n(),\n    .groups = \"drop\"\n  ) |&gt;\n  filter(tweet_count &gt;= 5) |&gt;\n  ggplot() +\n  aes(x = avg_retweets, y = avg_likes, size = tweet_count) +\n  geom_point(alpha = 0.5) +\n  scale_size_area(max_size = 10) +\n  labs(x = \"Ø Retweets\", y = \"Ø Likes\", size = \"Tweets\")\n\n\n\n\n\n\nAbbildung 16.6: Die Größe der Punkte kodiert eine zusätzliche Variable.\n\n\n\n\nscale_size_area() sorgt dafür, dass die Fläche proportional zum Wert ist, nicht der Radius. Das ist wichtig für eine korrekte visuelle Wahrnehmung (Wilke 2019).",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Punktediagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/scatter-plots.html#trendlinien",
    "href": "04-data-visualization/scatter-plots.html#trendlinien",
    "title": "16  Punktediagramme",
    "section": "\n16.5 Trendlinien",
    "text": "16.5 Trendlinien\nUm einen Trend sichtbar zu machen, fügt ihr eine Glättungslinie mit geom_smooth() hinzu:\n\ntweets |&gt;\n  filter(!is_retweet, retweet_count &gt; 0, favorite_count &gt; 0) |&gt;\n  ggplot() +\n  aes(x = retweet_count, y = favorite_count) +\n  geom_point(alpha = 0.1) +\n  geom_smooth() +\n  scale_x_log10() +\n  scale_y_log10()\n\n\n\n\n\n\nAbbildung 16.7: Eine Glättungslinie zeigt den Trend.\n\n\n\n\nStandardmäßig nutzt geom_smooth() eine LOESS-Kurve. Für eine lineare Regression nutzt ihr method = \"lm\":\n\ntweets |&gt;\n  filter(!is_retweet, retweet_count &gt; 0, favorite_count &gt; 0) |&gt;\n  ggplot() +\n  aes(x = retweet_count, y = favorite_count) +\n  geom_point(alpha = 0.1) +\n  geom_smooth(method = \"lm\") +\n  scale_x_log10() +\n  scale_y_log10()\n\n\n\n\n\n\nAbbildung 16.8: Eine lineare Regressionslinie.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Punktediagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/scatter-plots.html#typische-fehler",
    "href": "04-data-visualization/scatter-plots.html#typische-fehler",
    "title": "16  Punktediagramme",
    "section": "\n16.6 Typische Fehler",
    "text": "16.6 Typische Fehler\nKategoriale Variablen auf den Achsen\nPunktediagramme sind für zwei numerische Variablen gedacht. Wenn eine Variable kategorial ist, nutzt Boxplots oder Violin-Plots statt Punkte.\nZu viele Punkte ohne Transparenz\nTausende Punkte ohne alpha oder Jitter erzeugen einen schwarzen Klecks. Nutzt immer mindestens Transparenz.\nFehlende Null-Filter bei Log-Skalen\nlog10(0) ist -Inf. Filtert Nullwerte heraus, bevor ihr logarithmische Skalen verwendet.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Punktediagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/scatter-plots.html#kurz-zusammengefasst",
    "href": "04-data-visualization/scatter-plots.html#kurz-zusammengefasst",
    "title": "16  Punktediagramme",
    "section": "\n16.7 Kurz zusammengefasst",
    "text": "16.7 Kurz zusammengefasst\n\n\ngeom_point() zeigt die Beziehung zwischen zwei numerischen Variablen.\nNutzt alpha, geom_jitter() oder logarithmische Skalen gegen Overplotting.\nMit color und size könnt ihr weitere Variablen einbringen (Bubble Charts).\n\ngeom_smooth() zeigt Trends, mit method = \"lm\" als lineare Regression.\nPunktediagramme sind für numerische Variablen, nicht für kategoriale.\n\n\n\n\n\nWilke, C. 2019. Fundamentals of data visualization: a primer on making informative and compelling figures. First edition. O’Reilly Media.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Punktediagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/histograms.html",
    "href": "04-data-visualization/histograms.html",
    "title": "17  Histogramme",
    "section": "",
    "text": "17.1 Einfaches Histogramm\nHistogramme zeigen, wie sich die Werte einer numerischen Variable verteilen. Statt einzelne Datenpunkte darzustellen, werden die Werte in Intervalle (Bins) eingeteilt und die Häufigkeit pro Intervall als Balken dargestellt. Claus Wilke beschreibt Histogramme als die natürliche Wahl, wenn ihr die Form einer Verteilung untersuchen wollt — ob symmetrisch, schief oder mit mehreren Gipfeln (Wilke 2019).\nWie sieht die Verteilung der Retweet-Zahlen aus? Die meisten Tweets bekommen wenige Retweets, einige wenige bekommen sehr viele:\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  ggplot() +\n  aes(x = retweet_count) +\n  geom_histogram()\n\n\n\n\n\n\nAbbildung 17.1: Verteilung der Retweet-Zahlen.\nggplot2 zeigt eine Meldung, dass es 30 Bins verwendet hat (bins = 30). Das ist der Standardwert, aber nicht immer ideal.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Histogramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/histograms.html#bins-einstellen",
    "href": "04-data-visualization/histograms.html#bins-einstellen",
    "title": "17  Histogramme",
    "section": "\n17.2 Bins einstellen",
    "text": "17.2 Bins einstellen\nDie Anzahl der Bins beeinflusst, wie viel Detail ihr seht. Zu wenige Bins verbergen Muster, zu viele erzeugen Rauschen:\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  ggplot() +\n  aes(x = retweet_count) +\n  geom_histogram(bins = 10)\n\n\n\n\n\n\nAbbildung 17.2: Histogramm mit 10 Bins: grob, aber übersichtlich.\n\n\n\n\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  ggplot() +\n  aes(x = retweet_count) +\n  geom_histogram(bins = 100)\n\n\n\n\n\n\nAbbildung 17.3: Histogramm mit 100 Bins: mehr Detail, aber auch mehr Rauschen.\n\n\n\n\nAlternativ könnt ihr statt der Anzahl die Breite der Bins festlegen:\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  ggplot() +\n  aes(x = retweet_count) +\n  geom_histogram(binwidth = 50)\n\n\n\n\n\n\nAbbildung 17.4: Histogramm mit einer Binbreite von 50.\n\n\n\n\n\n\n\n\n\n\nTippBins ausprobieren\n\n\n\nEs gibt keine perfekte Bin-Anzahl. Probiert zwei, drei Werte aus und schaut, welcher die Verteilung am klarsten zeigt. Das ist ein normaler Teil der explorativen Analyse.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Histogramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/histograms.html#schiefe-verteilungen",
    "href": "04-data-visualization/histograms.html#schiefe-verteilungen",
    "title": "17  Histogramme",
    "section": "\n17.3 Schiefe Verteilungen",
    "text": "17.3 Schiefe Verteilungen\nDaten wie Retweet-Zahlen, Umsätze oder Follower-Zahlen sind oft stark rechtsschief: Die meisten Werte sind klein, einige wenige sind extrem groß. In solchen Fällen hilft es, den Blick auf einen Ausschnitt zu richten:\n\ntweets |&gt;\n  filter(!is_retweet, retweet_count &lt;= 500) |&gt;\n  ggplot() +\n  aes(x = retweet_count) +\n  geom_histogram(binwidth = 10)\n\n\n\n\n\n\nAbbildung 17.5: Histogramm mit Fokus auf den Bereich 0–500 Retweets.\n\n\n\n\nAlternativ könnt ihr eine logarithmische Skala verwenden:\n\ntweets |&gt;\n  filter(!is_retweet, retweet_count &gt; 0) |&gt;\n  ggplot() +\n  aes(x = retweet_count) +\n  geom_histogram(bins = 30) +\n  scale_x_log10()\n\n\n\n\n\n\nAbbildung 17.6: Histogramm mit logarithmischer x-Achse.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Histogramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/histograms.html#gruppen-vergleichen",
    "href": "04-data-visualization/histograms.html#gruppen-vergleichen",
    "title": "17  Histogramme",
    "section": "\n17.4 Gruppen vergleichen",
    "text": "17.4 Gruppen vergleichen\nÜberlagerte Histogramme\nUm die Verteilung zweier Gruppen zu vergleichen, könnt ihr sie überlagern. alpha sorgt dafür, dass beide sichtbar bleiben:\n\ntweets |&gt;\n  ggplot() +\n  aes(x = retweet_count, fill = is_retweet) +\n  geom_histogram(bins = 30, alpha = 0.5, position = \"identity\") +\n  scale_x_log10()\n\n\n\n\n\n\nAbbildung 17.7: Überlagerte Histogramme vergleichen zwei Gruppen.\n\n\n\n\nposition = \"identity\" ist hier wichtig, sonst stapelt ggplot2 die Histogramme übereinander statt sie zu überlagern.\nFacetten\nBei mehr als zwei Gruppen werden überlagerte Histogramme schnell unlesbar. Facetten sind dann die bessere Wahl:\n\ntweets |&gt;\n  filter(!is_retweet, lang %in% c(\"de\", \"en\", \"fr\"), retweet_count &gt; 0) |&gt;\n  ggplot() +\n  aes(x = retweet_count) +\n  geom_histogram(bins = 30) +\n  facet_wrap(~ lang) +\n  scale_x_log10()\n\n\n\n\n\n\nAbbildung 17.8: Facetten zeigen die Verteilung pro Sprache.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Histogramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/histograms.html#dichtekurven-als-alternative",
    "href": "04-data-visualization/histograms.html#dichtekurven-als-alternative",
    "title": "17  Histogramme",
    "section": "\n17.5 Dichtekurven als Alternative",
    "text": "17.5 Dichtekurven als Alternative\ngeom_density() zeichnet eine geglättete Kurve statt diskreter Balken. Das kann hilfreich sein, wenn ihr die Form der Verteilung hervorheben wollt:\n\ntweets |&gt;\n  filter(!is_retweet, retweet_count &gt; 0) |&gt;\n  ggplot() +\n  aes(x = retweet_count, fill = is_quote_status) +\n  geom_density(alpha = 0.4) +\n  scale_x_log10()\n\n\n\n\n\n\nAbbildung 17.9: Dichtekurven glätten die Verteilung.\n\n\n\n\nDichtekurven eignen sich besonders gut für Vergleiche, weil sich die Kurven leichter überlagern lassen als Balken (Wilke 2019).",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Histogramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/histograms.html#typische-fehler",
    "href": "04-data-visualization/histograms.html#typische-fehler",
    "title": "17  Histogramme",
    "section": "\n17.6 Typische Fehler",
    "text": "17.6 Typische Fehler\nStandardwerte nicht hinterfragen\nDie 30 Standard-Bins sind ein Startpunkt, nicht die richtige Wahl. Passt bins oder binwidth immer bewusst an.\nGruppen ohne position = \"identity\"\n\nWenn ihr Histogramme zweier Gruppen überlagern wollt, vergesst nicht position = \"identity\". Sonst werden sie gestapelt, und ihr seht nicht die echte Verteilung.\nNullwerte bei Log-Skalen\nlog10(0) ist nicht definiert. Filtert Nullwerte heraus, wenn ihr logarithmische Skalen verwendet.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Histogramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/histograms.html#kurz-zusammengefasst",
    "href": "04-data-visualization/histograms.html#kurz-zusammengefasst",
    "title": "17  Histogramme",
    "section": "\n17.7 Kurz zusammengefasst",
    "text": "17.7 Kurz zusammengefasst\n\n\ngeom_histogram() zeigt die Verteilung einer numerischen Variable.\nSteuert die Auflösung mit bins oder binwidth. Probiert verschiedene Werte aus.\nBei schiefen Verteilungen helfen Zoom (filter) oder logarithmische Skalen.\nVergleicht Gruppen mit fill + position = \"identity\" oder mit facet_wrap().\n\ngeom_density() ist eine geglättete Alternative, besonders gut für Gruppenvergleiche.\n\n\n\n\n\nWilke, C. 2019. Fundamentals of data visualization: a primer on making informative and compelling figures. First edition. O’Reilly Media.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Histogramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/boxplots.html",
    "href": "04-data-visualization/boxplots.html",
    "title": "18  Boxplots",
    "section": "",
    "text": "18.1 Aufbau eines Boxplots\nBoxplots fassen die Verteilung einer numerischen Variable in fünf Kennzahlen zusammen: Minimum, erstes Quartil, Median, drittes Quartil und Maximum. Im Gegensatz zu Histogrammen zeigen sie die Verteilung extrem kompakt, was sie ideal für Vergleiche zwischen Gruppen macht (Wilke 2019).\nBevor wir loslegen, kurz zur Anatomie:\nAbbildung: Ein einzelner Boxplot mit Beschriftungen aller fünf Bestandteile: Whisker unten (“Minimum ohne Ausreißer”), untere Boxgrenze (“Q1 = 25%”), Linie in der Mitte (“Median = 50%”), obere Boxgrenze (“Q3 = 75%”), Whisker oben (“Maximum ohne Ausreißer”). Einzelne Punkte jenseits der Whiskers sind mit “Ausreißer” beschriftet. Eine geschweifte Klammer an der Box zeigt “IQR” (Interquartilsabstand).",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Boxplots</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/boxplots.html#aufbau-eines-boxplots",
    "href": "04-data-visualization/boxplots.html#aufbau-eines-boxplots",
    "title": "18  Boxplots",
    "section": "",
    "text": "Die Box reicht vom ersten Quartil (Q1, 25%) bis zum dritten Quartil (Q3, 75%). Sie enthält die mittleren 50% der Daten.\nDie Linie in der Box ist der Median (50%).\nDie Whiskers (Antennen) reichen bis zum weitesten Datenpunkt innerhalb von 1,5 × IQR (Interquartilsabstand) ab der Box.\n\nAusreißer sind Punkte jenseits der Whiskers und werden einzeln dargestellt.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Boxplots</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/boxplots.html#einfacher-boxplot",
    "href": "04-data-visualization/boxplots.html#einfacher-boxplot",
    "title": "18  Boxplots",
    "section": "\n18.2 Einfacher Boxplot",
    "text": "18.2 Einfacher Boxplot\nWie verteilen sich die Retweet-Zahlen?\n\ntweets |&gt;\n  filter(!is_retweet) |&gt;\n  ggplot() +\n  aes(y = retweet_count) +\n  geom_boxplot()\n\n\n\n\n\n\nAbbildung 18.1: Boxplot der Retweet-Zahlen.\n\n\n\n\nDer Boxplot zeigt sofort: Die meisten Tweets haben wenige Retweets (die Box ist sehr komprimiert), aber es gibt einige extreme Ausreißer.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Boxplots</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/boxplots.html#gruppen-vergleichen",
    "href": "04-data-visualization/boxplots.html#gruppen-vergleichen",
    "title": "18  Boxplots",
    "section": "\n18.3 Gruppen vergleichen",
    "text": "18.3 Gruppen vergleichen\nDie eigentliche Stärke von Boxplots entfaltet sich, wenn ihr mehrere Gruppen nebeneinander zeigt:\n\ntop_accounts &lt;- tweets |&gt;\n  filter(!is_retweet) |&gt;\n  count(screen_name, sort = TRUE) |&gt;\n  head(8) |&gt;\n  pull(screen_name)\n\ntweets |&gt;\n  filter(!is_retweet, screen_name %in% top_accounts) |&gt;\n  ggplot() +\n  aes(x = reorder(screen_name, retweet_count, FUN = median), y = retweet_count) +\n  geom_boxplot() +\n  coord_flip() +\n  labs(x = NULL, y = \"Retweets\")\n\n\n\n\n\n\nAbbildung 18.2: Retweet-Verteilung nach Account.\n\n\n\n\nreorder(screen_name, retweet_count, FUN = median) sortiert die Accounts nach dem Median ihrer Retweet-Zahlen. So seht ihr sofort, welcher Account typischerweise die meisten Retweets bekommt.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Boxplots</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/boxplots.html#boxplot-verfeinern",
    "href": "04-data-visualization/boxplots.html#boxplot-verfeinern",
    "title": "18  Boxplots",
    "section": "\n18.4 Boxplot verfeinern",
    "text": "18.4 Boxplot verfeinern\nFarbe nach Gruppe\nMit fill färbt ihr die Boxen nach einer Gruppierungsvariable ein:\n\ntweets |&gt;\n  filter(!is_retweet, screen_name %in% top_accounts) |&gt;\n  ggplot() +\n  aes(x = reorder(screen_name, retweet_count, FUN = median), y = retweet_count, fill = screen_name) +\n  geom_boxplot(show.legend = FALSE) +\n  coord_flip() +\n  labs(x = NULL, y = \"Retweets\")\n\n\n\n\n\n\nAbbildung 18.3: Eingefärbte Boxplots.\n\n\n\n\nBreite nach Gruppengröße\nMit varwidth = TRUE werden die Boxen proportional zur Gruppengröße breiter. So seht ihr auf einen Blick, welche Gruppen mehr Daten haben:\n\ntweets |&gt;\n  filter(!is_retweet, screen_name %in% top_accounts) |&gt;\n  ggplot() +\n  aes(x = reorder(screen_name, retweet_count, FUN = median), y = retweet_count) +\n  geom_boxplot(varwidth = TRUE) +\n  coord_flip() +\n  labs(x = NULL, y = \"Retweets\")\n\n\n\n\n\n\nAbbildung 18.4: Die Breite zeigt die Gruppengröße.\n\n\n\n\nAusreißer unterdrücken\nBei sehr vielen Ausreißern wird der Plot unübersichtlich. Ihr könnt die Ausreißer-Punkte ausblenden und stattdessen die Whiskers verlängern lassen:\n\ntweets |&gt;\n  filter(!is_retweet, screen_name %in% top_accounts) |&gt;\n  ggplot() +\n  aes(x = reorder(screen_name, retweet_count, FUN = median), y = retweet_count) +\n  geom_boxplot(outlier.shape = NA) +\n  coord_flip() +\n  coord_flip(ylim = c(0, 2000)) +\n  labs(x = NULL, y = \"Retweets\")\n\n\n\n\n\n\nAbbildung 18.5: Boxplot ohne einzelne Ausreißer-Punkte.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Boxplots</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/boxplots.html#alternativen-und-ergänzungen",
    "href": "04-data-visualization/boxplots.html#alternativen-und-ergänzungen",
    "title": "18  Boxplots",
    "section": "\n18.5 Alternativen und Ergänzungen",
    "text": "18.5 Alternativen und Ergänzungen\nViolin-Plot\ngeom_violin() zeigt die Verteilung als geglättete Dichtekurve statt als Box. Das gibt mehr Einblick in die Form der Verteilung:\n\ntweets |&gt;\n  filter(!is_retweet, screen_name %in% top_accounts) |&gt;\n  ggplot() +\n  aes(x = reorder(screen_name, retweet_count, FUN = median), y = retweet_count) +\n  geom_violin() +\n  coord_flip() +\n  labs(x = NULL, y = \"Retweets\")\n\n\n\n\n\n\nAbbildung 18.6: Violin-Plots zeigen die Form der Verteilung.\n\n\n\n\nBoxplot + Punkte\nBei kleineren Datensätzen kann es sinnvoll sein, die einzelnen Datenpunkte über den Boxplot zu legen:\n\ntweets |&gt;\n  filter(!is_retweet, screen_name %in% top_accounts, retweet_count &lt;= 2000) |&gt;\n  ggplot() +\n  aes(x = reorder(screen_name, retweet_count, FUN = median), y = retweet_count) +\n  geom_boxplot(outlier.shape = NA) +\n  geom_jitter(alpha = 0.1, width = 0.2) +\n  coord_flip() +\n  labs(x = NULL, y = \"Retweets\")\n\n\n\n\n\n\nAbbildung 18.7: Boxplot mit einzelnen Datenpunkten.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Boxplots</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/boxplots.html#typische-fehler",
    "href": "04-data-visualization/boxplots.html#typische-fehler",
    "title": "18  Boxplots",
    "section": "\n18.6 Typische Fehler",
    "text": "18.6 Typische Fehler\nZu wenige Datenpunkte pro Gruppe\nBoxplots brauchen ausreichend Daten, um sinnvoll zu sein. Bei weniger als etwa 10 Beobachtungen pro Gruppe zeigt der Boxplot ein irreführendes Bild. Nutzt in dem Fall lieber geom_point() oder geom_jitter().\nMedian vs. Mittelwert verwechseln\nDie Linie in der Box ist der Median, nicht der Mittelwert. Bei schiefen Verteilungen können die beiden stark auseinander liegen.\nVerteilungsform ignorieren\nZwei Gruppen können den gleichen Boxplot haben, aber völlig unterschiedliche Verteilungen. Wenn euch die Form wichtig ist, nutzt Violin-Plots oder Histogramme als Ergänzung (Wilke 2019).",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Boxplots</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/boxplots.html#kurz-zusammengefasst",
    "href": "04-data-visualization/boxplots.html#kurz-zusammengefasst",
    "title": "18  Boxplots",
    "section": "\n18.7 Kurz zusammengefasst",
    "text": "18.7 Kurz zusammengefasst\n\n\ngeom_boxplot() fasst die Verteilung in fünf Kennzahlen zusammen.\nSortiert Gruppen mit reorder() nach dem Median für leichteren Vergleich.\n\nvarwidth = TRUE zeigt die Gruppengröße über die Boxbreite.\n\ngeom_violin() zeigt zusätzlich die Form der Verteilung.\nBoxplots brauchen mindestens ~10 Beobachtungen pro Gruppe, um aussagekräftig zu sein.\n\n\n\n\n\nWilke, C. 2019. Fundamentals of data visualization: a primer on making informative and compelling figures. First edition. O’Reilly Media.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Boxplots</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/line-charts.html",
    "href": "04-data-visualization/line-charts.html",
    "title": "19  Liniendiagramme",
    "section": "",
    "text": "19.1 Daten vorbereiten\nLiniendiagramme zeigen, wie sich ein numerischer Wert über eine geordnete Achse verändert, fast immer über die Zeit. Claus Wilke betont, dass Linien eine Verbindung und Kontinuität zwischen den Datenpunkten suggerieren. Deshalb sind sie nur sinnvoll, wenn die Datenpunkte tatsächlich in einer natürlichen Reihenfolge stehen (Wilke 2019).\nFür Liniendiagramme brauchen wir eine Zeitachse. Wir wandeln die created_at-Spalte in ein Datum um und zählen die Tweets pro Tag:\ntweets_per_day &lt;- tweets |&gt;\n  mutate(date = as.Date(created_at)) |&gt;\n  count(date)\n\ntweets_per_day |&gt;\n  head()\n\n# A tibble: 6 × 2\n  date           n\n  &lt;date&gt;     &lt;int&gt;\n1 2012-06-27     5\n2 2012-06-28     6\n3 2012-06-29     1\n4 2012-07-01     1\n5 2012-07-02     1\n6 2012-08-02     1",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Liniendiagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/line-charts.html#einfaches-liniendiagramm",
    "href": "04-data-visualization/line-charts.html#einfaches-liniendiagramm",
    "title": "19  Liniendiagramme",
    "section": "\n19.2 Einfaches Liniendiagramm",
    "text": "19.2 Einfaches Liniendiagramm\n\ntweets_per_day |&gt;\n  ggplot() +\n  aes(x = date, y = n) +\n  geom_line()\n\n\n\n\n\n\nAbbildung 19.1: Tweets pro Tag im Zeitverlauf.\n\n\n\n\ngeom_line() verbindet die Datenpunkte in der Reihenfolge der x-Achse. Ihr seht sofort, an welchen Tagen besonders viele oder wenige Tweets veröffentlicht wurden.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Liniendiagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/line-charts.html#linie-und-punkte",
    "href": "04-data-visualization/line-charts.html#linie-und-punkte",
    "title": "19  Liniendiagramme",
    "section": "\n19.3 Linie und Punkte",
    "text": "19.3 Linie und Punkte\nManchmal ist es hilfreich, die einzelnen Datenpunkte zusätzlich zur Linie zu zeigen:\n\ntweets_per_day |&gt;\n  ggplot() +\n  aes(x = date, y = n) +\n  geom_line() +\n  geom_point(size = 1)\n\n\n\n\n\n\nAbbildung 19.2: Linie mit Datenpunkten.\n\n\n\n\nDie Punkte zeigen, wo tatsächlich Daten vorhanden sind. Bei Lücken in der Zeitreihe werden die Punkte fehlen, die Linie wird aber trotzdem durchgezogen.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Liniendiagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/line-charts.html#mehrere-linien",
    "href": "04-data-visualization/line-charts.html#mehrere-linien",
    "title": "19  Liniendiagramme",
    "section": "\n19.4 Mehrere Linien",
    "text": "19.4 Mehrere Linien\nUm mehrere Gruppen im selben Diagramm zu vergleichen, nutzt ihr color oder group:\n\nselected &lt;- c(\"cem_oezdemir\", \"Karl_Lauterbach\", \"c_lindner\")\n\ntweets |&gt;\n  filter(screen_name %in% selected) |&gt;\n  mutate(date = as.Date(created_at)) |&gt;\n  count(screen_name, date) |&gt;\n  ggplot() +\n  aes(x = date, y = n, color = screen_name) +\n  geom_line() +\n  labs(x = NULL, y = \"Tweets pro Tag\", color = \"Account\")\n\n\n\n\n\n\nAbbildung 19.3: Tweets pro Tag für ausgewählte Accounts.\n\n\n\n\nJede Gruppe bekommt automatisch eine eigene Farbe und einen Eintrag in der Legende.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Liniendiagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/line-charts.html#glättung",
    "href": "04-data-visualization/line-charts.html#glättung",
    "title": "19  Liniendiagramme",
    "section": "\n19.5 Glättung",
    "text": "19.5 Glättung\nWenn die Linie stark schwankt, hilft eine Glättung mit geom_smooth(), um den langfristigen Trend zu erkennen:\n\ntweets_per_day |&gt;\n  ggplot() +\n  aes(x = date, y = n) +\n  geom_line(alpha = 0.3) +\n  geom_smooth(se = FALSE)\n\n\n\n\n\n\nAbbildung 19.4: Geglätteter Trend der täglichen Tweets.\n\n\n\n\nDie Originallinie wird transparent dargestellt (alpha = 0.3), und die geglättete Kurve zeigt den Trend. se = FALSE blendet das Konfidenzband aus.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Liniendiagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/line-charts.html#flächendiagramme",
    "href": "04-data-visualization/line-charts.html#flächendiagramme",
    "title": "19  Liniendiagramme",
    "section": "\n19.6 Flächendiagramme",
    "text": "19.6 Flächendiagramme\ngeom_area() füllt die Fläche unter der Linie aus. Das funktioniert besonders gut, wenn die y-Achse bei Null beginnt:\n\ntweets_per_day |&gt;\n  ggplot() +\n  aes(x = date, y = n) +\n  geom_area(alpha = 0.3) +\n  geom_line()\n\n\n\n\n\n\nAbbildung 19.5: Flächendiagramm der täglichen Tweets.\n\n\n\n\nGestapelte Flächen\nMehrere Gruppen als gestapelte Flächen zeigen sowohl den Gesamttrend als auch die Zusammensetzung:\n\ntweets |&gt;\n  filter(screen_name %in% selected) |&gt;\n  mutate(date = as.Date(created_at)) |&gt;\n  count(screen_name, date) |&gt;\n  ggplot() +\n  aes(x = date, y = n, fill = screen_name) +\n  geom_area(alpha = 0.6) +\n  labs(x = NULL, y = \"Tweets pro Tag\", fill = \"Account\")\n\n\n\n\n\n\nAbbildung 19.6: Gestapelte Flächen zeigen den Anteil jedes Accounts.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Liniendiagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/line-charts.html#zeitachse-formatieren",
    "href": "04-data-visualization/line-charts.html#zeitachse-formatieren",
    "title": "19  Liniendiagramme",
    "section": "\n19.7 Zeitachse formatieren",
    "text": "19.7 Zeitachse formatieren\nggplot2 erkennt Datumswerte automatisch und beschriftet die x-Achse entsprechend. Wenn ihr die Beschriftung anpassen wollt, nutzt scale_x_date():\n\ntweets_per_day |&gt;\n  ggplot() +\n  aes(x = date, y = n) +\n  geom_line() +\n  scale_x_date(date_labels = \"%b %Y\", date_breaks = \"1 month\") +\n  labs(x = NULL, y = \"Tweets pro Tag\")\n\n\n\n\n\n\nAbbildung 19.7: Angepasste Datumsbeschriftung.\n\n\n\n\ndate_labels steuert das Format (z.B. \"%b %Y\" für “Jan 2021”), date_breaks den Abstand der Achsenbeschriftungen.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Liniendiagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/line-charts.html#typische-fehler",
    "href": "04-data-visualization/line-charts.html#typische-fehler",
    "title": "19  Liniendiagramme",
    "section": "\n19.8 Typische Fehler",
    "text": "19.8 Typische Fehler\nKategoriale Daten mit Linien verbinden\nLinien suggerieren Kontinuität zwischen den Datenpunkten. Wenn die x-Achse kategorial ist (z.B. Länder oder Accounts), ist ein Balkendiagramm die richtige Wahl, nicht ein Liniendiagramm.\nFehlende Werte ignorieren\nWenn an manchen Tagen keine Beobachtungen vorliegen, fehlen diese Tage in eurem gezählten Datensatz. geom_line() verbindet dann die vorhandenen Punkte direkt, was einen falschen Eindruck erwecken kann. Füllt fehlende Tage vorher mit complete() und replace_na() auf.\nZu viele Linien\nMehr als vier oder fünf Linien in einem Diagramm sind schwer voneinander zu unterscheiden. Nutzt stattdessen Facetten oder zeigt nur die wichtigsten Gruppen.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Liniendiagramme</span>"
    ]
  },
  {
    "objectID": "04-data-visualization/line-charts.html#kurz-zusammengefasst",
    "href": "04-data-visualization/line-charts.html#kurz-zusammengefasst",
    "title": "19  Liniendiagramme",
    "section": "\n19.9 Kurz zusammengefasst",
    "text": "19.9 Kurz zusammengefasst\n\n\ngeom_line() verbindet Datenpunkte in der Reihenfolge der x-Achse.\nNutzt Liniendiagramme nur, wenn die x-Achse eine natürliche Reihenfolge hat (meistens Zeit).\nMit color zeigt ihr mehrere Gruppen, mit geom_area() Flächen unter der Linie.\n\ngeom_smooth() zeigt den Trend hinter den Schwankungen.\n\nscale_x_date() formatiert die Zeitachse nach euren Wünschen.\nBegrenzt die Anzahl der Linien auf vier bis fünf pro Diagramm.\n\n\n\n\n\nWilke, C. 2019. Fundamentals of data visualization: a primer on making informative and compelling figures. First edition. O’Reilly Media.",
    "crumbs": [
      "Datenvisualisierung",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Liniendiagramme</span>"
    ]
  },
  {
    "objectID": "project-1-survey/survey-data.html",
    "href": "project-1-survey/survey-data.html",
    "title": "21  Umfragedaten",
    "section": "",
    "text": "21.1 Daten laden mit R\nIn diesem Projekt geht es um die Analyse eines Umfragedatensatzes. Umfragen sind ein praktisches Werkzeug, wenn wir etwas über Einstellungen, Präferenzen oder Verhalten von Menschen herausfinden wollen – und genau solche Datensätze begegnen euch später auch im Job ziemlich häufig.\nBevor wir loslegen, eine Leitfrage: Wenn ihr eine Tabelle mit hunderten Spalten vor euch habt – woher wisst ihr eigentlich, was ihr da seht? Was ist eine Zeile? Was ist eine Spalte? Und wie könnt ihr schnell prüfen, ob die Daten überhaupt korrekt in R angekommen sind? Genau darum geht es in diesem Abschnitt.\nIn jedem Projekt steht am Anfang das Laden der Daten. In diesem Buch gehen wir davon aus, dass ein Datensatz bereits erhoben wurde. Die Datenerhebung ist nicht direkt Bestandteil dieses Buches – es geht primär um die Datenanalyse.\nDie Umfrageergebnisse wurden mit der Software Limesurvey erhoben und als CSV-Datei exportiert. Wenn ihr das GitHub-Repository für dieses Buch auf euren Rechner heruntergeladen habt, dann liegen die Daten im Ordner /data und können so geladen werden:\nlibrary(tidyverse)\nsurvey &lt;- read_csv(\"data/mds12_schoko_milch.csv\")\nNach Ausführung des Codeblocks stehen die Daten auf dem Objekt survey als Tibble bereit. Es ist eine gute Idee, für häufig verwendete Objekte kurze, aber sprechende Namen zu wählen – survey ist hier ein guter Kompromiss.\nZum Laden der Daten gehört immer auch ein kurzer Reality-Check: Sind wirklich alle Beobachtungen (Zeilen) und Variablen (Spalten) da? Genau diese Frage beantworten wir im nächsten Abschnitt.",
    "crumbs": [
      "Projekt 1: Umfragen",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Umfragedaten</span>"
    ]
  },
  {
    "objectID": "project-1-survey/survey-data.html#daten-laden-mit-r",
    "href": "project-1-survey/survey-data.html#daten-laden-mit-r",
    "title": "21  Umfragedaten",
    "section": "",
    "text": "WarnungAchtet auf den Unterstrich\n\n\n\nBitte achtet auf die Verwendung der richtigen Funktion read_csv. Es gibt in R auch eine Funktion mit dem Namen read.csv, die sehr ähnlich ist, aber keinen Tibble erzeugt. Wir verwenden in diesem Buch durchgehend das Tidyverse und Tibbles.\n\n\n\n\n\n\n\n\n\n\nHinweisMehr zum Laden von Daten laden (auch weitere Formate)\n\n\n\nAn dieser Stelle gehen wir nicht tiefer auf das Laden von Daten und andere Formate ein. Einen detaillierten Einblick findet ihr in Kapitel 5.",
    "crumbs": [
      "Projekt 1: Umfragen",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Umfragedaten</span>"
    ]
  },
  {
    "objectID": "project-1-survey/survey-data.html#kontext-und-metainformationen",
    "href": "project-1-survey/survey-data.html#kontext-und-metainformationen",
    "title": "21  Umfragedaten",
    "section": "21.2 Kontext und Metainformationen",
    "text": "21.2 Kontext und Metainformationen\n\nStellt euch vor, ihr bekommt eine Excel-Datei per Mail – ohne Begleittext. Ihr könnt sie öffnen, aber ihr wisst nicht, wer befragt wurde, wann die Erhebung stattgefunden hat oder was die Antwortcodes bedeuten. Ihr könnt dann zwar rechnen, aber ihr lauft Gefahr, das Falsche zu interpretieren. Ein paar Begleitinformationen in der E-Mail wären daher nicht schlecht. Vielleicht so etwas:\n\n“Der verwendete Datensatz wurde am Fachgebiet Agrarökonomie der Hochschule Osnabrück unter Leitung von Prof. Dr. Ulrich Enneking im Jahr 2025 erhoben. In einer umfangreichen, mehrteiligen Online-Umfrage wurden deutschlandweit Menschen zu Einstellungen und Kaufverhalten bei Lebensmitteln befragt. An der Umfrage haben 2.811 Personen teilgenommen.”\nSolche Informationen nennen wir Metainformationen (meta = über) oder Kontextinformationen. Häufig lassen sie sich als W‑Fragen formulieren. Tabelle 21.1 fasst die wichtigsten für unseren Datensatz zusammen:\n\n\n\nTabelle 21.1: Metainformationen zum Umfragedatensatz\n\n\n\n\n\n\n\n\n\nW‑Frage\nAntwort\n\n\n\n\nWer hat die Daten erhoben?\nProf. Dr. Enneking\n\n\nWie wurden die Daten erhoben?\nOnline-Umfrage\n\n\nWann wurden die Daten erhoben?\n2025\n\n\nWo wurden die Daten erhoben?\nonline\n\n\nWer wurde befragt?\n2.811 Menschen deutschlandweit\n\n\nWas wurde erhoben?\nEinstellungen und Kaufverhalten bei Lebensmitteln\n\n\n\n\n\n\nEine Frage ist dabei besonders wichtig, weil sie bestimmt, wie wir später Zahlen interpretieren: Was repräsentiert eine Zeile in den Daten? Was sehen wir eigentlich, wenn wir eine Zeile betrachten? Auf diese Frage brauchen wir eine klare Antwort, bevor wir mit der Analyse beginnen. Manchmal kann man es durch genaues Hinschauen erraten – aber der Schein kann trügen. Wenn wir die Daten nicht selbst erhoben haben, sollten wir diese Information aus sicherer Quelle bekommen. In diesem Beispiel habe ich nachgefragt: Eine Zeile entspricht den Antworten einer Person auf die Online‑Umfrage. In der empirischen Forschung sprechen wir dann von Beobachtungen.\n\nEmpirical research is any research that uses structured observations from the real world to attempt to answer questions. (Huntington-Klein 2026)\n\nWenn wir wissen, dass jede Zeile eine befragte Person ist, können wir auch sauber begründen, warum die Anzahl der Zeilen gleich der Anzahl der Teilnehmenden ist.",
    "crumbs": [
      "Projekt 1: Umfragen",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Umfragedaten</span>"
    ]
  },
  {
    "objectID": "project-1-survey/survey-data.html#dimensionierung-der-daten",
    "href": "project-1-survey/survey-data.html#dimensionierung-der-daten",
    "title": "21  Umfragedaten",
    "section": "21.3 Dimensionierung der Daten",
    "text": "21.3 Dimensionierung der Daten\nEs gibt mehrere Wege, die Anzahl der Beobachtungen zu bestimmen. Ein sehr direkter ist count(): Wenn wir count() ohne Variable aufrufen, zählt R schlicht die Zeilen.\n\nsurvey |&gt;\n1  count()\n\n\n1\n\nDer Befehl count() zählt die Beobachtungen (Zeilen) in einem Datensatz.\n\n\n\n\n# A tibble: 1 × 1\n      n\n  &lt;int&gt;\n1  2811\n\n\nEine zweite, oft sehr praktische Möglichkeit ist: Gebt einfach den Namen des Tibbles aus. Tibbles zeigen euch direkt eine kompakte Zusammenfassung inkl. Dimensionen (Zeilen x Spalten) und eine Vorschau.\n\nsurvey\n\n# A tibble: 2,811 × 813\n   q001hheinkauf q002geburt q003land q004geschlecht q005os v041nofleisch\n           &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;\n 1             2       1970        1              1      0             0\n 2             1       1990        7              1      0             0\n 3             2       1963        6              1      0             0\n 4             2       1989       13              2      0             1\n 5             2       1965        4              1      0             1\n 6             2       1957        2              1      0             0\n 7             2       1960       14              2      0             1\n 8             2       1984       13              1      0             0\n 9             2       1974        1              2      0             0\n10             2       1954       13              2      0             0\n# ℹ 2,801 more rows\n# ℹ 807 more variables: v041nofleisch_other &lt;chr&gt;, v041diaet_0nodiaet &lt;dbl&gt;,\n#   v041diaet_1lowcarb &lt;dbl&gt;, v041diaet_2laktose &lt;dbl&gt;,\n#   v041diaet_3gluten &lt;dbl&gt;, v041diaet_4paleo &lt;dbl&gt;, v041diaet_5ketogen &lt;dbl&gt;,\n#   v041diaet_6rohkost &lt;dbl&gt;, v041diaet_7makro &lt;dbl&gt;, v041diaet_8trenn &lt;dbl&gt;,\n#   v041diaet_9frutarisch &lt;dbl&gt;, v041diaet_10fleisch &lt;dbl&gt;,\n#   v041diaet_11mediterran &lt;dbl&gt;, v041diaet_12histaminarm &lt;dbl&gt;, …\n\n\nIn der ersten Zeile der Ausgabe steht die Dimensionierung der Daten. Wir bekommen also nicht nur die Information, wie viele Beobachtungen (2.811) vorhanden sind, sondern auch, wie viele Variablen der Datensatz hat (813). Danach folgen die ersten Zeilen (und so viele Spalten, wie auf die Konsole passen). Tibbles achten darauf, die Konsole nicht komplett mit Text zu fluten, und schneiden daher irgendwann ab.\nManchmal wollen wir die Anzahl Zeilen und Spalten nicht nur wissen, sondern weiterverwenden. Wir können sie dann auf Objekten speichern:\n\nrows &lt;- nrow(survey)\ncols &lt;- ncol(survey)\n\nprint(str_glue(\"Der Datensatz hat {rows} Zeilen und {cols} Spalten.\"))\n\nDer Datensatz hat 2811 Zeilen und 813 Spalten.",
    "crumbs": [
      "Projekt 1: Umfragen",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Umfragedaten</span>"
    ]
  },
  {
    "objectID": "project-1-survey/survey-data.html#variablen-spalten",
    "href": "project-1-survey/survey-data.html#variablen-spalten",
    "title": "21  Umfragedaten",
    "section": "21.4 Variablen (Spalten)",
    "text": "21.4 Variablen (Spalten)\nNeben der Frage „Was ist eine Zeile?“ ist die zweite Kernfrage: „Was misst jede Spalte?“ In Umfragen steckt hinter fast jeder Frage (und oft hinter jeder Antwortoption) eine eigene Variable – deshalb werden solche Datensätze schnell sehr „spaltenreich“.\n\nA variable, in the context of empirical research, is a bunch of observations of the same measurement. (Huntington-Klein 2026)\n\nBeobachtungen stellen wir typischerweise horizontal (in Zeilen) dar, Variablen vertikal (in Spalten).\n\n\n\n\n\n\nAbbildung 21.1: Beobachtungen repräsentieren wir als Zeilen, Variablen als Spalten.\n\n\n\nIm Idealfall gibt es zu einem Datensatz ein Data Dictionary (oder Codebuch): eine Art Wörterbuch, in dem jede Variable aufgeführt und inhaltlich erläutert ist. Das ist Gold wert – denn aus reinen Spaltennamen wie q001hheinkauf könnt ihr die Bedeutung oft nicht zuverlässig ableiten.\nDamit ihr trotzdem schnell arbeitsfähig werdet, schauen wir uns jetzt Werkzeuge an, mit denen ihr Variablen in R systematisch „abklopfen“ könnt:\n\nWie viele Variablen gibt es?\nWelche Namen und Datentypen haben sie?\nWelche Werte kommen in einer Variable überhaupt vor?\n\n\nWie viele Variablen?\nDie Anzahl der Variablen habt ihr bereits über die Tibble-Ausgabe gesehen. Ihr könnt sie aber auch direkt als Wert auslesen. Hier die Variante mit der Pipe:\n\nsurvey |&gt;\n  ncol()\n\n[1] 813\n\n\nDen Wert könnt ihr auf einem neuen Objekt speichern und später wiederverwenden , das ist in Skripten häufig nützlich:\n\nvariable_count &lt;- ncol(survey)\n1print(str_glue(\"Der Datensatz hat {variable_count} Variablen.\"))\n\n\n1\n\nMit str_glue() könnt ihr Zeichenketten mit Platzhaltern versehen, die bei der Ausführung mit Werten ersetzt werden.\n\n\n\n\nDer Datensatz hat 813 Variablen.\n\n\n\n\nNamen, Typen, erste Werte: select() + glimpse()\nSchauen wir uns fürs Erste nur die ersten 10 Variablen im Datensatz an:\n\nsurvey |&gt;\n1  select(1:10) |&gt;\n2  glimpse()\n\n\n1\n\nMit select() könnt ihr Variablen auswählen. Die Notation 1:10 bedeutet: Variablen an Position 1 bis 10.\n\n2\n\nMit glimpse() bekommt ihr schnell eine Übersicht der Namen, Datentypen und ersten Werte der Variablen.\n\n\n\n\nRows: 2,811\nColumns: 10\n$ q001hheinkauf       &lt;dbl&gt; 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1,…\n$ q002geburt          &lt;dbl&gt; 1970, 1990, 1963, 1989, 1965, 1957, 1960, 1984, 19…\n$ q003land            &lt;dbl&gt; 1, 7, 6, 13, 4, 2, 14, 13, 1, 13, 5, 14, 9, 4, 3, …\n$ q004geschlecht      &lt;dbl&gt; 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1,…\n$ q005os              &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ v041nofleisch       &lt;dbl&gt; 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,…\n$ v041nofleisch_other &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ v041diaet_0nodiaet  &lt;dbl&gt; 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,…\n$ v041diaet_1lowcarb  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ v041diaet_2laktose  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,…\n\n\nHier steckt direkt ein wichtiges Muster drin: Wir bauen eine kleine „Befehlskette“. Das etwas merkwürdig aussehende Symbol |&gt; (Pipe) sorgt dafür, dass das Ergebnis links an den nächsten Befehl rechts übergeben wird. Eine dedizierte Einführung in die Pipe findet ihr in Kapitel 6.\nMit der Flexibilität einer Programmiersprache wie R könnt ihr jede beliebige Menge an Spalten auswählen – zum Beispiel auch die letzten 10:\n\nsurvey |&gt;\n  select(tail(everything(), 10))\n\n# A tibble: 2,811 × 10\n   M070handeldiff3_1hochwertig M070handeldiff3_2regio M070handeldiff3_3preis\n                         &lt;dbl&gt;                  &lt;dbl&gt;                  &lt;dbl&gt;\n 1                          NA                     NA                     NA\n 2                          -1                      1                      2\n 3                          NA                     NA                     NA\n 4                          NA                     NA                     NA\n 5                          NA                     NA                     NA\n 6                          NA                     NA                     NA\n 7                          NA                     NA                     NA\n 8                          NA                     NA                     NA\n 9                           2                      2                     -2\n10                          NA                     NA                     NA\n# ℹ 2,801 more rows\n# ℹ 7 more variables: M070handeldiff3_4tierwohl &lt;dbl&gt;,\n#   M070handeldiff3_5vielfalt &lt;dbl&gt;, M070handeldiff3_6vetrauen &lt;dbl&gt;,\n#   M070handeldiff3_7nachhaltig &lt;dbl&gt;, M070handeldiff3_8gesund &lt;dbl&gt;,\n#   M070handeldiff3_9kauf &lt;dbl&gt;, M070handeldiff3_10trends &lt;dbl&gt;\n\n\nMit tail() ermitteln wir die letzten n Elemente einer Liste. everything() gibt uns (innerhalb von select()) die Liste aller Spalten. Der Ausdruck lässt sich also übersetzen als: Gib mir die letzten 10 Elemente aus der Liste aller Spalten. Gerade bei Umfragen mit vielen Spalten ist dieses gezielte Auswählen extrem nützlich. Noch mehr Möglichkeiten, Spalten auszuwählen, lernen wir im Verlauf des Projekts und im dedizierten Kapitel 8.\n\n\n\n\n\n\nHinweisVariablen haben eine feste Position\n\n\n\nVariablen (Spalten) haben eine feste Reihenfolge und Position in einem Datensatz. Ihr könnt eine Spalte daher nicht nur über ihren Namen, sondern auch über ihre Position ansprechen.\n\n\n\n\nWelchen Wertebereich hat eine Variable?\nglimpse() ist super, um schnell einen Eindruck zu bekommen, aber es zeigt euch nur die ersten Werte. Wenn ihr wirklich wissen wollt, welche Ausprägungen vorkommen, müsst ihr gezielt nachsehen.\nNehmen wir die Variable q001hheinkauf. Sie gehört zur Frage, ob die teilnehmende Person für den Lebensmitteleinkauf hauptverantwortlich ist oder ob die Aufgabe mit einer anderen Person geteilt wird. Im Codebuch zur Umfrage lesen wir nach, dass “1” für “Ich selbst und eine andere Person” steht, während “2” für “Hauptsächlich ich selbst” steht. Der Wert “0” stünde für “Fast immer eine andere Person”. Aber kommen wirklich nur diese Werte vor? Oder kommen überhaupt alle vor?\nZuerst können wir uns die Spalte als Tibble ausgeben lassen:\n\nsurvey |&gt;\n  select(q001hheinkauf)\n\n# A tibble: 2,811 × 1\n   q001hheinkauf\n           &lt;dbl&gt;\n 1             2\n 2             1\n 3             2\n 4             2\n 5             2\n 6             2\n 7             2\n 8             2\n 9             2\n10             2\n# ℹ 2,801 more rows\n\n\nStandardmäßig zeigt R dabei nur die ersten 10 Zeilen. Das könnt ihr ändern:\n\nsurvey |&gt;\n  select(q001hheinkauf) |&gt;\n  print(n = 20)\n\n# A tibble: 2,811 × 1\n   q001hheinkauf\n           &lt;dbl&gt;\n 1             2\n 2             1\n 3             2\n 4             2\n 5             2\n 6             2\n 7             2\n 8             2\n 9             2\n10             2\n11             2\n12             1\n13             2\n14             1\n15             2\n16             2\n17             1\n18             1\n19             2\n20             1\n# ℹ 2,791 more rows\n\n\nAlle Zeilen auszugeben würde dieses Kapitel sehr lang machen und wäre gleichzeitig aufwändig zu prüfen. Um dennoch sicher zu wissen, welche Werteausprägungen existieren, können wir uns die eindeutigen Werte ausgeben lassen:\n\nsurvey |&gt;\n  distinct(q001hheinkauf)\n\n# A tibble: 2 × 1\n  q001hheinkauf\n          &lt;dbl&gt;\n1             2\n2             1\n\n\nEine kleine Überraschung, denn die “0” ist nicht vertreten. Hat scheinbar niemand geantwortet. Wenn ihr zusätzlich wissen wollt, wie häufig die Ausprägungen angekreuzt wurden:\n\nsurvey |&gt;\n  count(q001hheinkauf)\n\n# A tibble: 2 × 2\n  q001hheinkauf     n\n          &lt;dbl&gt; &lt;int&gt;\n1             1   919\n2             2  1892\n\n\nDie Funktion count() gruppiert die Daten nach der übergebenen Variable und zählt die Beobachtungen pro Gruppe. Wir stecken schon mittem in der Analyse der Daten 🤓.\n\n\n\n\n\n\nHinweisAggregieren von Daten\n\n\n\nDie Funktion count() ist eine Aggregationsfunktion. Eine dedizierte Einführung, wie man mit R und dem dplyr‑Paket Daten zusammenfasst, findet ihr in Kapitel 12.\n\n\nUnd weil es gerade passt: Wenn wir Daten analysieren, dann bevorzugen wir in dem allermeisten Fällen eine aussagekräftige Visualisierung über eine tabellarische Ausgabe. Die Häufigkeiten der beiden Antwortmöglichkeiten können wir wunderbar als Balkendiagramm visualisieren:\n\nsurvey |&gt;\n  count(q001hheinkauf) |&gt;\n  ggplot() +\n  aes(x = q001hheinkauf, y = n) +\n  geom_col()\n\n\n\n\n\n\n\n\nZugegeben: Das Balkendiagramm ist verbesserungswürdig, dennoch zeigt es einen wichtigen Aspekt der explorativen Datenanalyse und warum R dafür so gut geeignet ist. Mit nur drei Zeilen Code erstellen wir ein Balkendiagramm, das uns die Verhältnisse der Anworten zur ersten Frage im Datensatz visuell aufzeigt. Und das Diagramm ist inhaltlich korrekt, dafür sorgt die Bibliothek ggplot2, die wir hier verwenden. Es ist dafür nicht wirklich ansprechend (schaut etwas mal die Labels auf der x-Achse an). Aber darum geht es in der explorativen Datenanalyse nicht. Wir wollen schhnell Ergebnisse sehen und flexibel in den Daten wühlen können. Das funktioniert mit R und dem Tidyverse perfekt!\nWir lernen in Kapitel 22 noch mehr darüber, wie wir schnell den Wertebereich einer Variable überblicken können. Als nächstes schauen wir auf den zweiten wichtigen Aspekt: Die Beobachtungen.",
    "crumbs": [
      "Projekt 1: Umfragen",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Umfragedaten</span>"
    ]
  },
  {
    "objectID": "project-1-survey/survey-data.html#beobachtungen-zeilen",
    "href": "project-1-survey/survey-data.html#beobachtungen-zeilen",
    "title": "21  Umfragedaten",
    "section": "21.5 Beobachtungen (Zeilen)",
    "text": "21.5 Beobachtungen (Zeilen)\nWas für Variablen gilt, gilt auch für Zeilen: Jede hat eine feste Position. Bei Zeilen nennen wir das auch die row number (Zeilennummer). Mit row_number() könnt ihr diese Position abfragen und damit gezielt Zeilen auswählen.\n\nsurvey |&gt;\n  select(1:10) |&gt;\n1  filter(row_number() &lt;= 10)\n\n\n1\n\nMit row_number() bekommen wir die Position (Zeilennummer) einer Beobachtung.\n\n\n\n\n# A tibble: 10 × 10\n   q001hheinkauf q002geburt q003land q004geschlecht q005os v041nofleisch\n           &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;\n 1             2       1970        1              1      0             0\n 2             1       1990        7              1      0             0\n 3             2       1963        6              1      0             0\n 4             2       1989       13              2      0             1\n 5             2       1965        4              1      0             1\n 6             2       1957        2              1      0             0\n 7             2       1960       14              2      0             1\n 8             2       1984       13              1      0             0\n 9             2       1974        1              2      0             0\n10             2       1954       13              2      0             0\n# ℹ 4 more variables: v041nofleisch_other &lt;chr&gt;, v041diaet_0nodiaet &lt;dbl&gt;,\n#   v041diaet_1lowcarb &lt;dbl&gt;, v041diaet_2laktose &lt;dbl&gt;\n\n\nDie Funktion filter() verwenden wir, um Beobachtungen nach Kriterien einzugrenzen – zum Beispiel um nur weibliche Personen zu betrachten. Mit row_number() könnt ihr stattdessen nach Position filtern, z. B. um „Beispielzeilen“ für einen ersten Blick zu nehmen.\nStatt „kleiner-gleich“ (&lt;=) könnt ihr natürlich auch andere Operatoren verwenden:\n\nsurvey |&gt;\n  filter(row_number() == 42) |&gt;\n  select(q004geschlecht)\n\n# A tibble: 1 × 1\n  q004geschlecht\n           &lt;dbl&gt;\n1              2\n\n\nDamit habt ihr jetzt die wichtigsten Werkzeuge für den Start: Daten laden, Kontext verstehen, Dimensionen prüfen, Variablen überblicken und Wertebereiche testen. Im nächsten Schritt geht es darum, die Variablen inhaltlich zu interpretieren (Codebuch/Data Dictionary) und die Daten für Analysen vorzubereiten.\n\n\n\n\nHuntington-Klein, Nick. 2026. The effect: an introduction to research design and causality. Second edition. A Chapman & Hall Book. CRC Press.",
    "crumbs": [
      "Projekt 1: Umfragen",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Umfragedaten</span>"
    ]
  },
  {
    "objectID": "project-1-survey/types-of-variables.html",
    "href": "project-1-survey/types-of-variables.html",
    "title": "22  Arten von Variablen",
    "section": "",
    "text": "22.1 Ein Schema zur Orientierung\nIn Kapitel 21 haben wir gesehen, dass Umfragedaten aus vielen unterschiedlichen Spalten bestehen: Manche Spalten sind Zahlen, andere sind Kategorien wie „männlich/weiblich/divers“, wieder andere enthalten Freitext. Das ist nicht nur „Kosmetik“, der Variablentyp entscheidet ganz praktisch darüber,\nLasst uns deshalb Ordnung in die Spalten bringen: Welche Arten von Variablen gibt es und woran erkennt ihr sie in R?\nUm Variablen sauber abzugrenzen, hilft ein einfaches Schema. Laut Huntington-Klein (2026) unterscheiden wir in der empirischen Forschung zwischen:\nIch würde einen Schritt weiter gehen und kontinuierliche und Zählvariablen zur Klasse der numerischen Variablen zusammenfassen. Da ordinale Variablen ebenfalls Katgeorien darstellen, die zusätzlich geordnet sind, werden Sie ihnen untergeordnet. Daneben gibt es dann die kategorialien Variablen ohne Reihenfolge, die wir nominale Variablen nennen. Qualitative Variablen (sowas wie Texte) bilden ihre eigene Klasse. In Abbildung 22.1 ist das Schema zusammengefasst dargestellt.\nWichtig: Diese Einteilung beschreibt das Messniveau (also: was wird gemessen?). Der Datentyp in R (&lt;dbl&gt;, &lt;int&gt;, &lt;chr&gt;, …) ist ein Hinweis, aber nicht die ganze Wahrheit. In Umfragen werden Kategorien z. B. oft als Zahlen kodiert (1, 2, 3 …) oder als viele 0/1‑Spalten (Mehrfachauswahl). Ohne Codebuch/Data Dictionary kann man das leicht falsch lesen.\nSchauen wir uns jetzt die Typen nacheinander an – jeweils mit Beispielen aus unserem Datensatz.",
    "crumbs": [
      "Projekt 1: Umfragen",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arten von Variablen</span>"
    ]
  },
  {
    "objectID": "project-1-survey/types-of-variables.html#ein-schema-zur-orientierung",
    "href": "project-1-survey/types-of-variables.html#ein-schema-zur-orientierung",
    "title": "22  Arten von Variablen",
    "section": "",
    "text": "Kontinuierlichen Variablen\nZählvariablen\nOrdinalen Variablen\nKategorialen Variablen\nQualitativen Variablen\n\n\n\n\n\n\n\n\nAbbildung 22.1: Klassifizierungsschema für Arten von Variablen.",
    "crumbs": [
      "Projekt 1: Umfragen",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arten von Variablen</span>"
    ]
  },
  {
    "objectID": "project-1-survey/types-of-variables.html#numerische-variablen",
    "href": "project-1-survey/types-of-variables.html#numerische-variablen",
    "title": "22  Arten von Variablen",
    "section": "22.2 Numerische Variablen",
    "text": "22.2 Numerische Variablen\nNumerische (quantitative) Variablen messen eine Menge oder Größe. Mit ihnen können wir rechnen, im Sinne von Mittelwerte bilden, den Median bestimmen oder eine Spannweite berechnen. Wir unterscheiden dabei zwei grundlende numerische Arten: kontinuierlich und diskret. Anders ausgedrückt: Zahlen mit Kommastelle und ganze Zahlen (ohne Kommastellen).\n\nKontinuierliche Variablen\n\nContinuous variables are variables that could take any value (perhaps within some range). (Huntington-Klein 2026)\n\nIm Umfragedatensatz fragt eine Frage nach der Eingabe eines Preises, den die Teilnehmenden bereit wären, für einen Liter Milch einer vorgegebenen Marke zu bezahlen:\n“Geben Sie für die 3 Marken bitte den Preis an, den Sie für angemessen halten und bei dem Sie zugreifen würden! Als Dezimaltrennzeichen verwenden Sie bitte das Komma.”\nSchauen wir auf ein paar Beobachtungen. Wie sehen die Antworten aus?\n\nsurvey |&gt;\n  select(u013pzahl_1weihen)\n\n# A tibble: 2,811 × 1\n   u013pzahl_1weihen\n               &lt;dbl&gt;\n 1              1.49\n 2             NA   \n 3             NA   \n 4             NA   \n 5             NA   \n 6             NA   \n 7             NA   \n 8             NA   \n 9            150   \n10             NA   \n# ℹ 2,801 more rows\n\n\nAnhand der Ausgabe erkennt ihr typischerweise drei Dinge:\n\nDer Datentyp ist &lt;dbl&gt; (double). Das passt zu Dezimalzahlen und ist daher typisch für kontinuierliche Variablen.\nViele Werte sind NA – es fehlen also Angaben. Später müssen wir klären, warum Werte fehlen und wie wir damit umgehen.\nManchmal seht ihr sehr ungewöhnliche Werte (z. B. 150 €). Das sind oft Ausreißer – z. B. durch Tippfehler.\n\n\nFehlende Werte („NA“) kurz behandeln\nFür einen ersten Überblick können wir fehlende Werte herausfiltern (auch wenn das nicht immer die richtige Entscheidung für eine echte Analyse ist). Das geht mit drop_na():\n\nsurvey |&gt;\n  select(u013pzahl_1weihen) |&gt;\n  drop_na()\n\n# A tibble: 231 × 1\n   u013pzahl_1weihen\n               &lt;dbl&gt;\n 1              1.49\n 2            150   \n 3              1.19\n 4              3   \n 5              2   \n 6              1.6 \n 7              1.09\n 8              3   \n 9              1.8 \n10              2.2 \n# ℹ 221 more rows\n\n\nJetzt sehen wir mehr „echte“ Preise. Für kontinuierliche Variablen ist typisch: Es gibt keine feste Liste an Ausprägungen, sondern (theoretisch) unendlich viele Werte auf einem Kontinuum. Das merkt ihr auch daran, dass distinct() bei solchen Variablen schnell sehr viele unterschiedliche Werte liefern kann:\n\nsurvey |&gt;\n  select(u013pzahl_1weihen) |&gt;\n  drop_na() |&gt;\n  distinct()\n\n# A tibble: 48 × 1\n   u013pzahl_1weihen\n               &lt;dbl&gt;\n 1              1.49\n 2            150   \n 3              1.19\n 4              3   \n 5              2   \n 6              1.6 \n 7              1.09\n 8              1.8 \n 9              2.2 \n10            120   \n# ℹ 38 more rows\n\n\nZwar sieht es hier so aus, als wären die eindeutigen Werte mit 48 gar nicht so zahlreich. Trotzdem ist klar: theoretisch könnten viel mehr unterschiedliche Preise eingegeben werden – und „Preis“ ist von Natur aus eine numerische Größe.\n\n\nAusreißer, Mittelwert und Median\nBei kontinuierlichen Variablen spielt häufig das Problem der Ausreißer eine Rolle. Gerade in Umfragen ist ein Tippfehler eine naheliegende Ursache. Je nach Ursprung sind unterschiedliche Maßnahmen möglich: Tippfehler sollten wir korrigieren – oder (wenn wir nicht sicher korrigieren können) pragmatisch filtern.\nStarten wir mit dem Durchschnittspreis als arithmetischem Mittel:\n\nsurvey |&gt;\n  summarize(avg_price = mean(u013pzahl_1weihen))\n\n# A tibble: 1 × 1\n  avg_price\n      &lt;dbl&gt;\n1        NA\n\n\nWarum steht dort NA? Weil R nicht „raten“ will, wie NA in Berechnungen behandelt werden soll. Sobald ein NA in die Rechnung eingeht, wird das Ergebnis NA. Für einen ersten Blick entfernen wir also die fehlenden Werte:\n\nsurvey |&gt;\n1  drop_na(u013pzahl_1weihen) |&gt;\n  summarize(avg_price = mean(u013pzahl_1weihen))\n\n\n1\n\ndrop_na() entfernt alle Zeilen mit fehlenden Werten. Wenn ihr Spalten angebt, bezieht sich das Entfernen nur auf diese Spalten.\n\n\n\n\n# A tibble: 1 × 1\n  avg_price\n      &lt;dbl&gt;\n1      4.58\n\n\nIm Durchschnitt halten die Probanden also einen Preis von 4,58 € für einen Liter Milch für gerechtfertigt. Klingt das plausibel? Prüfen wir das mit einer robusteren Kenngröße: dem Median.\n\nsurvey |&gt;\n  drop_na(u013pzahl_1weihen) |&gt;\n  summarize(avg_price = median(u013pzahl_1weihen))\n\n# A tibble: 1 × 1\n  avg_price\n      &lt;dbl&gt;\n1      1.49\n\n\nDer Median ist mit 1,49 € deutlich kleiner. Woran liegt das? Der Median ist robust gegenüber Ausreißern, das arithmetische Mittel dagegen nicht.\nDas arithmetische Mittel ist:\n\\[\n\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i\n\\]\nDer Median ist der mittlere Wert der sortierten Daten; bei geradem \\(n\\) ist er der Mittelwert der beiden mittleren Werte:\n\\[\n\\tilde{x} =\n\\begin{cases}\nx_{\\left(\\frac{n+1}{2}\\right)}, & \\text{falls } n \\text{ ungerade ist},\\\\[6pt]\n\\frac{1}{2}\\left(x_{\\left(\\frac{n}{2}\\right)} + x_{\\left(\\frac{n}{2}+1\\right)}\\right), & \\text{falls } n \\text{ gerade ist}.\n\\end{cases}\n\\]\nWas also tun? Da wir nicht sicher wissen, welche Eingabe „eigentlich gemeint“ war, entscheiden wir uns hier pragmatisch für ein Filtern unplausibler Werte. Schauen wir zuerst, welche extrem hohen Werte vorkommen:\n\nsurvey |&gt;\n  select(u013pzahl_1weihen) |&gt;\n  arrange(desc(u013pzahl_1weihen))\n\n# A tibble: 2,811 × 1\n   u013pzahl_1weihen\n               &lt;dbl&gt;\n 1               150\n 2               150\n 3               129\n 4               120\n 5               109\n 6                50\n 7                 7\n 8                 4\n 9                 4\n10                 3\n# ℹ 2,801 more rows\n\n\nGar nicht so einfach, eine Grenze festzulegen. Für dieses Beispiel wählen wir 10 € als Obergrenze:\n\nsurvey |&gt;\n  filter(u013pzahl_1weihen &lt; 10.0) |&gt;\n  summarize(avg_price = mean(u013pzahl_1weihen))\n\n# A tibble: 1 × 1\n  avg_price\n      &lt;dbl&gt;\n1      1.56\n\n\nGibt es auch Ausreißer nach unten?\n\nsurvey |&gt;\n  select(u013pzahl_1weihen) |&gt;\n  arrange(u013pzahl_1weihen)\n\n# A tibble: 2,811 × 1\n   u013pzahl_1weihen\n               &lt;dbl&gt;\n 1              0   \n 2              0   \n 3              0   \n 4              0.09\n 5              0.89\n 6              0.95\n 7              0.99\n 8              0.99\n 9              0.99\n10              0.99\n# ℹ 2,801 more rows\n\n\nAuch hier sehen wir unplausible Werte (z. B. 0 €). Filtern wir beide Seiten:\n\nsurvey |&gt;\n  filter(u013pzahl_1weihen &lt; 10.0) |&gt;\n  filter(u013pzahl_1weihen &gt; 0.1) |&gt;\n  summarize(avg_price = mean(u013pzahl_1weihen))\n\n# A tibble: 1 × 1\n  avg_price\n      &lt;dbl&gt;\n1      1.59\n\n\nDurch die Pipeline werden die Filter nacheinander angewendet: zuerst „zu groß“, danach „zu klein“. Danach berechnen wir erneut den Mittelwert.\n\n\n\n\n\n\nHinweisFiltern von Daten\n\n\n\nDie Funktion filter() ist zentral für die Auswahl der richtigen Beobachtungen. Eine Einführung, wie man mit R und dem dplyr‑Paket Daten filtert, findet ihr in Kapitel 11.\n\n\n\n\nAusreißer sehen: Boxplot und Histogramm\nVisualisierungen helfen, Ausreißer schnell zu erkennen. Ein Boxplot stellt Ausreißer als Punkte außerhalb der Box dar:\n\nsurvey |&gt;\n  ggplot() +\n  aes(x = u013pzahl_1weihen) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nMan erkennt hier sehr schön die Handvoll Ausreißer. Die Box selbst ist dadurch kaum sichtbar. Was tun? Bei einem Boxplot solltet ihr nicht einfach filtern, „nur damit es schöner aussieht“, weil der Boxplot Kennzahlen wie den Median und Quartile aus den gefilterten Daten berechnen würde – und ihr damit den Plot inhaltlich verändert.\nDie Lösung: Reinzoomen statt filtern. Wir begrenzen nur die Achsenansicht:\n\nsurvey |&gt;\n  ggplot() +\n  aes(x = u013pzahl_1weihen) +\n  geom_boxplot() +\n  coord_cartesian(xlim = c(0, 10))\n\n\n\n\n\n\n\n\nSchon besser. Die „Whisker“ des Boxplots reichen typischerweise bis zum 1,5‑fachen Interquartilsabstand (IQR) über/unter die Quartile:\n\\[\n\\left[\\, Q_1 - 1.5\\cdot\\mathrm{IQR},\\; Q_3 + 1.5\\cdot\\mathrm{IQR} \\,\\right]\n\\]\nwobei gilt:\n\\[\n\\mathrm{IQR} = Q_3 - Q_1\n\\]\nZoomen wir noch ein Stück weiter hinein:\n\nsurvey |&gt;\n  ggplot() +\n  aes(x = u013pzahl_1weihen) +\n  geom_boxplot() +\n  coord_cartesian(xlim = c(0, 5))\n\n\n\n\n\n\n\n\nEine Alternative ist ein Histogramm:\n\nsurvey |&gt;\n  ggplot() +\n  aes(x = u013pzahl_1weihen) +\n  geom_histogram()\n\n\n\n\n\n\n\n\nAuch hier „ziehen“ Ausreißer die Skala auseinander. Beim Histogramm dürft ihr für die Darstellung pragmatisch filtern, weil es nur Häufigkeiten pro Klasse zählt:\n\nsurvey |&gt;\n  filter(u013pzahl_1weihen &lt; 10.0) |&gt;\n  ggplot() +\n  aes(x = u013pzahl_1weihen) +\n  geom_histogram()\n\n\n\n\n\n\n\n\nWenn ihr keine Klassenbreite angebt, wählt ggplot2 etwas Passendes. Ihr könnt das aber steuern, z. B. mit 50‑Cent‑Klassen:\n\nsurvey |&gt;\n  filter(u013pzahl_1weihen &lt; 10.0) |&gt;\n  ggplot() +\n  aes(x = u013pzahl_1weihen) +\n  geom_histogram(binwidth = 0.5)\n\n\n\n\n\n\n\n\nFür jetzt merken wir uns: Kontinuierliche Variablen sind oft &lt;dbl&gt;, können viele Ausprägungen haben und sind empfindlich gegenüber Ausreißern. Boxplot/Histogramm geben euch schnell ein Gefühl für die Verteilung.\n\n\n\nZählvariablen\n\nCount variables are those that, well, count something. Perhaps how many times something happened or how many of something there are. (Huntington-Klein 2026)\n\nDer Unterschied zur kontinuierlichen Variable ist (ganz pragmatisch): Zählvariablen haben keine Nachkommastellen. Typische Beispiele:\n\nAlter (in Jahren)\nAnzahl Käufe pro Monat\nAnzahl verkaufter Produkte\n\nZählvariablen können sehr viele Ausprägungen haben und werden dann in der explorativen Analyse oft ähnlich behandelt wie kontinuierliche Variablen. Trotzdem ist das Messniveau ein anderes: Es sind diskrete, abzählbare Werte.\n\nBeispiel: Alter aus dem Geburtsjahr ableiten\nDas Alter wurde nicht direkt gefragt, steckt aber indirekt in der Frage: „In welchem Jahr sind Sie geboren?“.\n\nsurvey |&gt; \n  select(q002geburt)\n\n# A tibble: 2,811 × 1\n   q002geburt\n        &lt;dbl&gt;\n 1       1970\n 2       1990\n 3       1963\n 4       1989\n 5       1965\n 6       1957\n 7       1960\n 8       1984\n 9       1974\n10       1954\n# ℹ 2,801 more rows\n\n\nWenn wir das Geburtsjahr kennen, können wir das Alter (mit kleiner Restunsicherheit) schätzen:\n\nsurvey |&gt;\n  transmute(age = 2025 - q002geburt)\n\n# A tibble: 2,811 × 1\n     age\n   &lt;dbl&gt;\n 1    55\n 2    35\n 3    62\n 4    36\n 5    60\n 6    68\n 7    65\n 8    41\n 9    51\n10    71\n# ℹ 2,801 more rows\n\n\nWie viele unterschiedliche Alterswerte gibt es?\n\nsurvey |&gt;\n  transmute(age = 2025 - q002geburt) |&gt;\n  distinct()\n\n# A tibble: 61 × 1\n     age\n   &lt;dbl&gt;\n 1    55\n 2    35\n 3    62\n 4    36\n 5    60\n 6    68\n 7    65\n 8    41\n 9    51\n10    71\n# ℹ 51 more rows\n\n\nEs sind mit 61 sogar noch mehr Ausprägungen als beim Preis. Ein Histogramm mit 5‑Jahres‑Klassen gibt schnell einen Überblick:\n\nsurvey |&gt;\n  transmute(age = 2025 - q002geburt) |&gt;\n  ggplot() +\n  aes(x = age) +\n  geom_histogram(binwidth = 5, fill = \"lightblue\", alpha = 0.8) +\n  labs(y = \"Häufigkeit\", x = \"Alter\", title = \"Altersverteilung der Probanden\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nHier steckt nebenbei ein wichtiger Punkt: Auch in der explorativen Analyse lohnt es sich manchmal, Visualisierungen kurz lesbarer zu machen (Beschriftungen, Theme, Farben).\n\n\n\n\n\n\nHinweisVisualisierungen polieren\n\n\n\nWährend wir in der explorativen Datenanalyse Wert auf schnelle Ergebnisse legen, wollen wir für Publikationen ansprechende Visualisierungen im Hochglanzformat erstellen. In Kapitel 20 schauen wir explizit auf die Möglichkeiten, Visualisierungen aufzupolieren.\n\n\n\n\nGanze Zahlen (int)\nZählvariablen bestehen aus ganzen Zahlen (mathematisch: natürlichen Zahlen). In R gibt es dafür den Datentyp int, der in Abbildung 22.1 auch für Zählvariablen angegeben ist.\nIn der Praxis macht es oft keinen großen Unterschied, ob ihr eine Zählvariable als double oder int speichert. Zwei Vorteile von int sind:\n\nint benötigt weniger Speicher (bei sehr großen Daten relevant).\nEs signalisiert klar: „Hier sind nur ganze Zahlen sinnvoll“ – das hilft auch anderen, die den Datensatz später nutzen.\n\nWandeln wir das Alter in int um und speichern es als neue Variable im Tibble:\n\nsurvey &lt;- \n  survey |&gt;\n  mutate(Q002age = as.integer(2025 - q002geburt), .after = \"q002geburt\")\n\nMit mutate() erzeugen wir eine neue Spalte. as.integer() klappt nur, wenn der Wert als ganze Zahl darstellbar ist; sonst gibt es einen Fehler. Mit .after steuern wir die Position der neuen Variable.\n\nsurvey |&gt;\n  select(q002geburt, Q002age)\n\n# A tibble: 2,811 × 2\n   q002geburt Q002age\n        &lt;dbl&gt;   &lt;int&gt;\n 1       1970      55\n 2       1990      35\n 3       1963      62\n 4       1989      36\n 5       1965      60\n 6       1957      68\n 7       1960      65\n 8       1984      41\n 9       1974      51\n10       1954      71\n# ℹ 2,801 more rows\n\n\nWie alt ist der älteste Teilnehmende?\n\nsurvey |&gt;\n  select(Q002age) |&gt;\n  arrange(desc(Q002age)) |&gt;\n  head(1)\n\n# A tibble: 1 × 1\n  Q002age\n    &lt;int&gt;\n1      80\n\n\nUnd der jüngste?\n\nsurvey |&gt;\n  select(Q002age) |&gt;\n  arrange(Q002age) |&gt;\n  head(1)\n\n# A tibble: 1 × 1\n  Q002age\n    &lt;int&gt;\n1      18\n\n\n\n\nSchneller Überblick über eine Spalte mit skim()\nEs gibt ein nützliches Paket namens skimr, das unter anderem die Funktion skim() bereitstellt. Sie gibt euch einen schnellen Überblick über einzelne Variablen oder sogar den gesamten Datensatz.\n\nlibrary(skimr)\nsurvey |&gt; \n  select(Q002age) |&gt; \n  skim() |&gt;\n  as_tibble()\n\n# A tibble: 1 × 12\n  skim_type skim_variable n_missing complete_rate numeric.mean numeric.sd\n  &lt;chr&gt;     &lt;chr&gt;             &lt;int&gt;         &lt;dbl&gt;        &lt;dbl&gt;      &lt;dbl&gt;\n1 numeric   Q002age               0             1         48.4       14.7\n# ℹ 6 more variables: numeric.p0 &lt;dbl&gt;, numeric.p25 &lt;dbl&gt;, numeric.p50 &lt;dbl&gt;,\n#   numeric.p75 &lt;dbl&gt;, numeric.p100 &lt;dbl&gt;, numeric.hist &lt;chr&gt;\n\n\nDen letzten Schritt as_tibble() benötigt ihr nicht – er ist nur notwendig, damit in diesem Buch eine Konsolenausgabe entsteht. In RStudio wird die Ausgabe automatisch passend dargestellt.\nskim() erzeugt einen Tibble mit Kennzahlen zur Variable Q002age, z. B.:\n\nDatentyp (skim_type)\nAnzahl fehlender Werte (n_missing) und Füllgrad (complete_rate)\nMittelwert, Standardabweichung, Quartile, Minimum/Maximum\nein kleines ASCII‑Histogramm (numeric.hist)\n\nUnd weil es ein Tibble ist, könnt ihr damit wie mit jedem anderen Datensatz weiterarbeiten – zum Beispiel nur Mittelwert und Median auswählen:\n\nsurvey |&gt; \n  select(Q002age) |&gt; \n  skim() |&gt;\n  yank(\"numeric\") |&gt;\n  select(mean_age = mean, median_age = p50) \n\nVariable type: numeric\n\n\n\nmean_age\nmedian_age\n\n\n\n\n48.39\n50",
    "crumbs": [
      "Projekt 1: Umfragen",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arten von Variablen</span>"
    ]
  },
  {
    "objectID": "project-1-survey/types-of-variables.html#kategoriale-variablen",
    "href": "project-1-survey/types-of-variables.html#kategoriale-variablen",
    "title": "22  Arten von Variablen",
    "section": "22.3 Kategoriale Variablen",
    "text": "22.3 Kategoriale Variablen\nKategoriale Variablen ordnen Beobachtungen in Kategorien ein. Oft sind sie in Umfragen sogar der häufigste Typ.\n\nNominale Variablen\n\nCategorical variables are variables recording which category an observation is in - simple enough! The color of a flower is an example of a categorical variable. Is the flower white, orange, or red? None of those options is “more” than the others; they’re just different. (Huntington-Klein 2026)\n\nNominale Variablen haben Kategorien ohne natürliche Reihenfolge. Typische Beispiele in Umfragen sind Geschlecht, Bundesland oder „Hauptverantwortlich für den Einkauf: ja/nein“.\nIn R wollt ihr bei nominalen Variablen meist wissen:\n\nWelche Kategorien kommen vor?\nWie häufig sind sie?\n\nDas geht schnell mit distinct() oder (noch praktischer) count():\n\nsurvey |&gt;\n  count(q004geschlecht)\n\n# A tibble: 3 × 2\n  q004geschlecht     n\n           &lt;dbl&gt; &lt;int&gt;\n1              1  1328\n2              2  1481\n3              3     2\n\n\nViele nominale Variablen sind als Zahlen kodiert (z. B. 1/2/3). Ohne Codebuch wisst ihr dann noch nicht, welche Zahl für welche Kategorie steht – ihr könnt aber trotzdem schon prüfen, ob es „unerwartete“ Codes gibt.\n\n\nOrdinale Variablen\n\nOrdinal variables are variables where some values are “more” and others are “less,” but there’s not necessarily a rule as to how much more “more” is. (Huntington-Klein 2026)\n\nOrdinale Variablen haben eine Reihenfolge (z. B. Zustimmung von 1 bis 7), aber die Abstände zwischen den Stufen sind nicht zwingend gleich groß. Das ist wichtig für die Auswertung: Häufig sind Median und Häufigkeiten sinnvoller als ein Mittelwert, und Visualisierungen sind oft Balkendiagramme.\nIn unserem Datensatz tauchen solche Skalenfragen z. B. in Variablen mit „…diff7…“ im Namen auf. Ein schneller Check:\n\nsurvey |&gt;\n  count(ax010midiff7, sort = TRUE)\n\n# A tibble: 8 × 2\n  ax010midiff7     n\n         &lt;dbl&gt; &lt;int&gt;\n1           NA   478\n2            5   345\n3            6   341\n4            7   340\n5            1   339\n6            4   329\n7            3   323\n8            2   316\n\n\nWenn ihr ordinale Variablen später modellieren oder sauber visualisieren wollt, ist es oft sinnvoll, sie als ordered factor zu behandeln (statt als „normale“ Zahl). Das machen wir an anderer Stelle im Buch noch ausführlicher.\n\nSonderfall: Mehrfachauswahl als viele 0/1‑Spalten\nIn Umfragen werden Mehrfachauswahl‑Fragen häufig als mehrere Dummy‑Spalten gespeichert (0/1). Inhaltlich sind das kategoriale Informationen – gespeichert als Zahlen.\nZum Beispiel gibt es im Datensatz mehrere Spalten, die mit v008ort_ beginnen (Einkaufsorte). Ein erster Blick auf ein paar davon:\n\nsurvey |&gt;\n  select(v008ort_1discount, v008ort_2super, v008ort_9online, v008ort_other) |&gt;\n  glimpse()\n\nRows: 2,811\nColumns: 4\n$ v008ort_1discount &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0…\n$ v008ort_2super    &lt;dbl&gt; 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0…\n$ v008ort_9online   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0…\n$ v008ort_other     &lt;chr&gt; \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0…\n\n\nDie Interpretation ist hier: „Hat Person X diese Option gewählt – ja/nein?“.",
    "crumbs": [
      "Projekt 1: Umfragen",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arten von Variablen</span>"
    ]
  },
  {
    "objectID": "project-1-survey/types-of-variables.html#qualitative-variablen",
    "href": "project-1-survey/types-of-variables.html#qualitative-variablen",
    "title": "22  Arten von Variablen",
    "section": "22.4 Qualitative Variablen",
    "text": "22.4 Qualitative Variablen\n\nQualitative variables are a sort of catch-all category for everything else. They aren’t numeric in nature, but also they’re not categorical. The text of a Washington Post headline is an example of a qualitative variable. (Huntington-Klein 2026)\n\nQualitative Variablen sind häufig Freitext: Antworten, die nicht in eine feste Kategorienliste passen. In Umfragen sind das oft „Other“-Felder. In unserem Datensatz findet ihr solche Spalten z. B. an Namen wie …_other:\n\nsurvey |&gt;\n  select(v041nofleisch_other)\n\n# A tibble: 2,811 × 1\n   v041nofleisch_other\n   &lt;chr&gt;              \n 1 &lt;NA&gt;               \n 2 &lt;NA&gt;               \n 3 &lt;NA&gt;               \n 4 &lt;NA&gt;               \n 5 &lt;NA&gt;               \n 6 &lt;NA&gt;               \n 7 &lt;NA&gt;               \n 8 &lt;NA&gt;               \n 9 &lt;NA&gt;               \n10 &lt;NA&gt;               \n# ℹ 2,801 more rows\n\n\nFür qualitative Variablen ist in der explorativen Analyse oft ein sinnvoller Start:\n\nzuerst die häufigsten Texte anschauen,\nTippfehler/Varianten vereinheitlichen,\nund dann entscheiden, ob man Kategorien daraus macht oder Textanalyse einsetzt.",
    "crumbs": [
      "Projekt 1: Umfragen",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arten von Variablen</span>"
    ]
  },
  {
    "objectID": "project-1-survey/types-of-variables.html#zusammenfassung-welcher-typ-welche-werkzeuge",
    "href": "project-1-survey/types-of-variables.html#zusammenfassung-welcher-typ-welche-werkzeuge",
    "title": "22  Arten von Variablen",
    "section": "22.5 Zusammenfassung: Welcher Typ → welche Werkzeuge?",
    "text": "22.5 Zusammenfassung: Welcher Typ → welche Werkzeuge?\n\nKontinuierlich (dbl): NA/Ausreißer prüfen, Histogramm/Boxplot, Median als robuste Ergänzung.\nZählvariable (diskret, oft int): Häufig wie kontinuierlich auswerten, aber „ganzzahlig“ im Kopf behalten.\nNominal (Kategorien): count()/Balkenplot, Kodierungen über Codebuch prüfen.\nOrdinal (geordnete Kategorien): Häufigkeiten + Median; vorsichtig mit Mittelwert/Standardabweichung.\nQualitativ (Text): erst sichten/aufräumen, dann strukturieren.\n\n\n\n\n\nHuntington-Klein, Nick. 2026. The effect: an introduction to research design and causality. Second edition. A Chapman & Hall Book. CRC Press.",
    "crumbs": [
      "Projekt 1: Umfragen",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Arten von Variablen</span>"
    ]
  },
  {
    "objectID": "project-2-news/load.html",
    "href": "project-2-news/load.html",
    "title": "23  Laden der Daten",
    "section": "",
    "text": "23.1 Tagesschau-Beiträge\nIn diesem ersten Kapitel des Projekts erkunden wir wie immer den neuen Datensatz. Dazu laden wir ihn mit R, und zwar als Tibble, damit wir auf alle Funktionen des Tidyverse zurükgreifen können. Anschließend lernen wir etwas über die enthaltenen Informationen.\nDie Daten stammen von der Webseite Tagesschau.de, die täglich aktuelle Nachrichten veröffentlicht. Für dieses Projekt wurden für den Zeitraum 05.01.2006 bis 31.12.2025 insgesamt 59.500 Nachrichtenartikel gesammelt. Wer gerne mehr über den Prozess der Datensammlung erfahren möchte findet im Anhang eine detaillierte Beschreibung der Python-Skripte, die für die Erstellung dieses Datensatzes verwendet wurden.\nFür unsere Analysen gehen wir wie immer davon aus, dass die Daten bereits vorliegen. In diesem Fall als CSV-Datei, die wir sofort als Tibble in R laden können.\nlibrary(tidyverse)\nts &lt;- read_csv(\"data/tagesschau.csv\")\nMit der Funktion glimpse() bekommen wir einen schnellen Überblick über die Struktur des Datensatzes.\nts |&gt;\n  glimpse()    \n\nRows: 59,500\nColumns: 21\n$ supertitle     &lt;chr&gt; \"ARD-DeutschlandTrend Januar 2006\", \"Treffen der EU-Inn…\n$ title          &lt;chr&gt; \"ARD-DeutschlandTrend Januar 2006\", \"Grundzüge für geme…\n$ date_time      &lt;dttm&gt; 2006-01-05 10:50:33, 2006-01-13 13:47:00, 2006-01-13 1…\n$ author         &lt;chr&gt; \"Jörg Schönenborn\", \"tagesschau.de\", \"tagesschau.de\", \"…\n$ ressort        &lt;chr&gt; \"inland\", \"ausland\", \"inland\", \"ausland\", \"wirtschaft\",…\n$ url            &lt;chr&gt; \"https://www.tagesschau.de/inland/deutschlandtrend/meld…\n$ thumbnail      &lt;chr&gt; \"\\\"https://images.tagesschau.de/image/47dedcab-ee73-4e8…\n$ tag            &lt;chr&gt; NA, NA, \"INTERVIEW\", NA, \"HINTERGRUND\", NA, NA, NA, \"IN…\n$ shorttext      &lt;chr&gt; \"Angela Merkel hat in den ersten sechs Wochen ihrer Amt…\n$ description    &lt;chr&gt; \"Angela Merkel hat in den ersten sechs Wochen ihrer Amt…\n$ keywords       &lt;chr&gt; \"[\\\"DeutschlandTrend\\\"]\", \"[\\\"Meldung\\\"]\", \"[\\\"Intervie…\n$ date_modified  &lt;dttm&gt; 2021-01-28 10:32:31, 2023-03-01 23:51:29, 2023-03-01 1…\n$ canonical_url  &lt;chr&gt; \"https://www.tagesschau.de/inland/deutschlandtrend/meld…\n$ language       &lt;chr&gt; \"de\", \"de\", \"de\", \"de\", \"de\", \"de\", \"de\", \"de\", \"de\", \"…\n$ paragraphs     &lt;chr&gt; \"[\\\"Bundeskanzlerin Angela Merkel hat in den ersten sec…\n$ text           &lt;chr&gt; \"Bundeskanzlerin Angela Merkel hat in den ersten sechs …\n$ word_count     &lt;dbl&gt; 569, 406, 658, 264, 601, 399, 262, 516, 801, 433, 567, …\n$ image_urls     &lt;chr&gt; \"[\\\"https://images.tagesschau.de/image/47dedcab-ee73-4e…\n$ image_captions &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ related_links  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ source_file    &lt;chr&gt; \"2006-01-05-articles.jsonl\", \"2006-01-13-articles.jsonl…\nWir sehen, dass der Datensatz 59.500 Zeilen und 21 Spalten enthält. Jede Zeile entspricht einem Nachrichtenbeitrag, und jede Spalte enthält Informationen über diesen Beitrag, wie zum Beispiel den Titel, den Text, das Veröffentlichungsdatum und einige interessante Informationen mehr. Lasst uns einen Blick auf ein paar ausgewählte Spalten werfen.",
    "crumbs": [
      "Projekt 2: News",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Laden der Daten</span>"
    ]
  },
  {
    "objectID": "project-2-news/factors.html",
    "href": "project-2-news/factors.html",
    "title": "\n24  Faktoren\n",
    "section": "",
    "text": "24.1 Überblick: Welche Variablen sind gute Faktoren?\nViele Variablen im Tagesschau-Datensatz sind kategorial: ressort, language, author, manchmal auch tag oder supertitle. In R werden solche Kategorien häufig als Faktoren (factors) dargestellt. Ein Faktor ist im Kern ein Vektor mit festen Ausprägungen (levels). Das ist in der Datenanalyse nützlich, weil\nIm Tidyverse ist forcats (Teil von tidyverse) das Werkzeug für Faktor-Operationen.\nEin schneller Check ist: Welche Spalten sind Text (&lt;chr&gt;) und haben eher wenige unterschiedliche Werte?\n# Anzahl unterschiedlicher Werte je Zeichen-Spalte\nchar_uniques &lt;- ts |&gt;\n  summarise(\n    across(where(is.character), ~ n_distinct(.x, na.rm = TRUE))\n  ) |&gt;\n  pivot_longer(everything(), names_to = \"variable\", values_to = \"n_distinct\") |&gt;\n  arrange(n_distinct)\n\nchar_uniques\n\n# A tibble: 18 × 2\n   variable       n_distinct\n   &lt;chr&gt;               &lt;int&gt;\n 1 language                4\n 2 ressort                38\n 3 tag                   375\n 4 author               5216\n 5 source_file          6351\n 6 image_captions       9434\n 7 related_links       17122\n 8 thumbnail           41449\n 9 keywords            41962\n10 supertitle          46474\n11 image_urls          48806\n12 title               58902\n13 paragraphs          58986\n14 text                58986\n15 shorttext           59056\n16 description         59059\n17 canonical_url       59231\n18 url                 59433\nInterpretation:",
    "crumbs": [
      "Projekt 2: News",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Faktoren</span>"
    ]
  },
  {
    "objectID": "project-2-news/factors.html#überblick-welche-variablen-sind-gute-faktoren",
    "href": "project-2-news/factors.html#überblick-welche-variablen-sind-gute-faktoren",
    "title": "\n24  Faktoren\n",
    "section": "",
    "text": "Kleine n_distinct (z.B. language) → sehr gute Kandidaten für Faktoren.\nGroße n_distinct (z.B. title, url) → eher Identifikatoren/Free-Text, meistens kein Faktor.",
    "crumbs": [
      "Projekt 2: News",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Faktoren</span>"
    ]
  },
  {
    "objectID": "project-2-news/factors.html#häufigkeiten-ressorts-zählen-und-visualisieren",
    "href": "project-2-news/factors.html#häufigkeiten-ressorts-zählen-und-visualisieren",
    "title": "\n24  Faktoren\n",
    "section": "\n24.2 Häufigkeiten: Ressorts zählen und visualisieren",
    "text": "24.2 Häufigkeiten: Ressorts zählen und visualisieren\nBei News-Daten ist ressort meist eine der wichtigsten Kategorien.\n\n# Häufigkeitstabelle\nressort_counts &lt;- ts |&gt;\n  count(ressort, sort = TRUE)\n\nressort_counts\n\n# A tibble: 39 × 2\n   ressort          n\n   &lt;chr&gt;        &lt;int&gt;\n 1 ausland      22675\n 2 wirtschaft   15935\n 3 inland       13463\n 4 wissen        2045\n 5 faktenfinder  1059\n 6 investigativ  1042\n 7 newsticker    1021\n 8 multimedia     650\n 9 kommentar      468\n10 kultur         340\n# ℹ 29 more rows\n\n\nFür eine Visualisierung ist es hilfreich, ressort als Faktor zu nutzen und nach Häufigkeit zu ordnen.\n\nressort_counts |&gt;\n  filter(!is.na(ressort)) |&gt;\n  mutate(ressort = fct_reorder(ressort, n)) |&gt;\n  ggplot(aes(x = ressort, y = n)) +\n  geom_col() +\n  coord_flip() +\n  theme_bw() +\n  labs(x = \"Ressort\", y = \"Anzahl der Beiträge\")\n\n\n\n\n\n\n\nWarum ist das nützlich?\n\nDu erkennst sofort, welche Ressorts dominieren (wichtig für Stichproben, Bias, Gewichtung).\nViele weitere Analysen (Zeitreihen, Textfeatures) lassen sich sinnvoll nach Ressort splitten.",
    "crumbs": [
      "Projekt 2: News",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Faktoren</span>"
    ]
  },
  {
    "objectID": "project-2-news/factors.html#zu-viele-kategorien-lumpen-seltene-werte-zusammenfassen",
    "href": "project-2-news/factors.html#zu-viele-kategorien-lumpen-seltene-werte-zusammenfassen",
    "title": "\n24  Faktoren\n",
    "section": "\n24.3 Zu viele Kategorien: Lumpen (seltene Werte zusammenfassen)",
    "text": "24.3 Zu viele Kategorien: Lumpen (seltene Werte zusammenfassen)\nBei Kategorien wie author gibt es oft sehr viele Ausprägungen. Für Auswertungen und Plots ist es dann sinnvoll, seltene Werte in Other zusammenzufassen.\n\n# Top-Autor:innen + Other\n# (Falls author sehr oft NA ist: NAs explizit als Kategorie behandeln)\n\nts |&gt;\n  mutate(\n    author = fct_explicit_na(author, na_level = \"(fehlend)\"),\n    author = fct_lump_n(author, n = 15)\n  ) |&gt;\n  count(author, sort = TRUE)\n\n# A tibble: 16 × 2\n   author                    n\n   &lt;fct&gt;                 &lt;int&gt;\n 1 Other                 20487\n 2 tagesschau.de         19926\n 3 (fehlend)             16625\n 4 Kai Küstner             387\n 5 Martin Bohne            207\n 6 Silvia Stöber           201\n 7 Stephan Ueberbach       185\n 8 Helga Schmidt           184\n 9 Ralph Sina              182\n10 Jakob Mayr              177\n11 Karin Bensch            177\n12 Patrick Gensing         176\n13 Frank Bräutigam         157\n14 Angela Göpfert          149\n15 Christoph Prössl        148\n16 Jan-Christoph Kitzler   132\n\n\nDas ist ein typischer Schritt in der Datenanalyse:\n\nreduziert visuelle Unordnung,\nverhindert, dass „Einzelfälle“ die Story dominieren,\nstabilisiert Modelle (zu viele Kategorien führen sonst schnell zu Overfitting).",
    "crumbs": [
      "Projekt 2: News",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Faktoren</span>"
    ]
  },
  {
    "objectID": "project-2-news/factors.html#sinnvolle-reihenfolgen-faktoren-nach-kennzahlen-ordnen",
    "href": "project-2-news/factors.html#sinnvolle-reihenfolgen-faktoren-nach-kennzahlen-ordnen",
    "title": "\n24  Faktoren\n",
    "section": "\n24.4 Sinnvolle Reihenfolgen: Faktoren nach Kennzahlen ordnen",
    "text": "24.4 Sinnvolle Reihenfolgen: Faktoren nach Kennzahlen ordnen\nEin Faktor muss nicht alphabetisch sortiert sein. Häufig willst du Kategorien nach einer analytischen Kennzahl ordnen.\nBeispiel: Welche Ressorts haben im Median die längsten Texte (über word_count)?\n\nressort_wordcount &lt;- ts |&gt;\n  filter(!is.na(ressort), !is.na(word_count)) |&gt;\n  group_by(ressort) |&gt;\n  summarise(\n    n = n(),\n    median_word_count = median(word_count),\n    .groups = \"drop\"\n  ) |&gt;\n  arrange(desc(median_word_count))\n\nressort_wordcount\n\n# A tibble: 32 × 3\n   ressort                                   n median_word_count\n   &lt;chr&gt;                                 &lt;int&gt;             &lt;dbl&gt;\n 1 incels                                    1             2589 \n 2 newsticker                             1021             1987 \n 3 geschichte                                1             1451 \n 4 ueber-uns                                 2             1010.\n 5 fussball                                  4              864.\n 6 ratgeber                                  2              820.\n 7 investigativ                           1042              804.\n 8 faktenfinder                           1059              754 \n 9 news                                      8              678.\n10 Einstellungen einblenden Pfeil rechts   210              657 \n# ℹ 22 more rows\n\n\nUnd als Plot, nach Median-Wortanzahl geordnet:\n\nressort_wordcount |&gt;\n  mutate(ressort = fct_reorder(ressort, median_word_count)) |&gt;\n  ggplot(aes(x = ressort, y = median_word_count)) +\n  geom_col() +\n  coord_flip() +\n  theme_bw() +\n  labs(x = \"Ressort\", y = \"Median Wortanzahl\")\n\n\n\n\n\n\n\nSo ein Plot ist ein guter Einstieg, um Hypothesen zu formulieren (z.B. „Politikartikel sind länger als Sportmeldungen“).",
    "crumbs": [
      "Projekt 2: News",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Faktoren</span>"
    ]
  },
  {
    "objectID": "project-2-news/factors.html#kategorien-bereinigen-recoding-und-missingness-sichtbar-machen",
    "href": "project-2-news/factors.html#kategorien-bereinigen-recoding-und-missingness-sichtbar-machen",
    "title": "\n24  Faktoren\n",
    "section": "\n24.5 Kategorien bereinigen: Recoding und Missingness sichtbar machen",
    "text": "24.5 Kategorien bereinigen: Recoding und Missingness sichtbar machen\nOft sind Kategorien „nicht sauber“: unterschiedliche Schreibweisen, leere Strings, oder NAs. Für Analytics ist es wichtig, diese Fälle bewusst zu behandeln.\nBeispiel: language sollte im Datensatz meistens de sein.\n\n# Sprache: NA explizit machen + Häufigkeiten\n\nts |&gt;\n  mutate(language = fct_explicit_na(language, na_level = \"(fehlend)\")) |&gt;\n  count(language, sort = TRUE)\n\n# A tibble: 5 × 2\n  language      n\n  &lt;fct&gt;     &lt;int&gt;\n1 de        59495\n2 en            2\n3 es            1\n4 it            1\n5 (fehlend)     1\n\n\nWenn du Kategorien zusammenführen möchtest (z.B. Synonyme), hilft fct_recode():\n\n# Beispiel-Recode (nur als Muster; passe Mapping bei Bedarf an deine Daten an)\n\nts |&gt;\n  mutate(\n    ressort = fct_recode(\n      ressort,\n      inland = \"inland\",\n      ausland = \"ausland\"\n    )\n  ) |&gt;\n  count(ressort, sort = TRUE)\n\n# A tibble: 39 × 2\n   ressort          n\n   &lt;fct&gt;        &lt;int&gt;\n 1 ausland      22675\n 2 wirtschaft   15935\n 3 inland       13463\n 4 wissen        2045\n 5 faktenfinder  1059\n 6 investigativ  1042\n 7 newsticker    1021\n 8 multimedia     650\n 9 kommentar      468\n10 kultur         340\n# ℹ 29 more rows",
    "crumbs": [
      "Projekt 2: News",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Faktoren</span>"
    ]
  },
  {
    "objectID": "project-2-news/factors.html#abgeleitete-faktoren-wochentag-und-tageszeit",
    "href": "project-2-news/factors.html#abgeleitete-faktoren-wochentag-und-tageszeit",
    "title": "\n24  Faktoren\n",
    "section": "\n24.6 Abgeleitete Faktoren: Wochentag und Tageszeit",
    "text": "24.6 Abgeleitete Faktoren: Wochentag und Tageszeit\nFaktoren entstehen nicht nur aus Textspalten. Gerade Zeitstempel werden in Analytics oft in kategoriale Einheiten transformiert, um Muster sichtbar zu machen.\n\n# Wochentag (deutsche Labels) und Stunde\n# Hinweis: base::weekdays() hängt von der Locale ab; daher nutzen wir lubridate::wday()\n\nts |&gt;\n  mutate(\n    weekday = wday(date_time, label = TRUE, abbr = FALSE, week_start = 1),\n    hour = hour(date_time)\n  ) |&gt;\n  count(weekday, sort = TRUE)\n\n# A tibble: 8 × 2\n  weekday        n\n  &lt;ord&gt;      &lt;int&gt;\n1 Donnerstag 10649\n2 Mittwoch   10503\n3 Dienstag   10158\n4 Freitag     9345\n5 Montag      8979\n6 Samstag     5107\n7 Sonntag     4730\n8 &lt;NA&gt;          29\n\n\nWochentage als Faktor sind besonders nützlich für:\n\nPublikationsmuster (z.B. weniger Beiträge am Wochenende?),\nKontrollvariablen in Modellen,\nsegmentierte Reports (“Mo–Fr” vs. Wochenende).",
    "crumbs": [
      "Projekt 2: News",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Faktoren</span>"
    ]
  },
  {
    "objectID": "project-2-news/variables.html",
    "href": "project-2-news/variables.html",
    "title": "\n25  Variablen\n",
    "section": "",
    "text": "25.1 Übersicht der Variablen\nNachdem wir in Kapitel 23 die Tagesschau-Daten geladen und einen ersten Überblick über die enthaltenen Informationen gewonnen haben, wollen wir uns nun genauer mit den einzelnen Variablen beschäftigen.\nUm eine Übersicht über die in einem Datensatz enthaltenen Variablen zu bekommen, können wir die Funktion glimpse() verwenden. Sie gibt uns einen schnellen Überblick über die Struktur des Datensatzes, einschließlich der Namen der Variablen, ihrer Datentypen und einiger Beispielwerte.\nts |&gt;\n  glimpse()\n\nRows: 59,500\nColumns: 21\n$ supertitle     &lt;chr&gt; \"ARD-DeutschlandTrend Januar 2006\", \"Treffen der EU-Inn…\n$ title          &lt;chr&gt; \"ARD-DeutschlandTrend Januar 2006\", \"Grundzüge für geme…\n$ date_time      &lt;dttm&gt; 2006-01-05 10:50:33, 2006-01-13 13:47:00, 2006-01-13 1…\n$ author         &lt;chr&gt; \"Jörg Schönenborn\", \"tagesschau.de\", \"tagesschau.de\", \"…\n$ ressort        &lt;chr&gt; \"inland\", \"ausland\", \"inland\", \"ausland\", \"wirtschaft\",…\n$ url            &lt;chr&gt; \"https://www.tagesschau.de/inland/deutschlandtrend/meld…\n$ thumbnail      &lt;chr&gt; \"\\\"https://images.tagesschau.de/image/47dedcab-ee73-4e8…\n$ tag            &lt;chr&gt; NA, NA, \"INTERVIEW\", NA, \"HINTERGRUND\", NA, NA, NA, \"IN…\n$ shorttext      &lt;chr&gt; \"Angela Merkel hat in den ersten sechs Wochen ihrer Amt…\n$ description    &lt;chr&gt; \"Angela Merkel hat in den ersten sechs Wochen ihrer Amt…\n$ keywords       &lt;chr&gt; \"[\\\"DeutschlandTrend\\\"]\", \"[\\\"Meldung\\\"]\", \"[\\\"Intervie…\n$ date_modified  &lt;dttm&gt; 2021-01-28 10:32:31, 2023-03-01 23:51:29, 2023-03-01 1…\n$ canonical_url  &lt;chr&gt; \"https://www.tagesschau.de/inland/deutschlandtrend/meld…\n$ language       &lt;chr&gt; \"de\", \"de\", \"de\", \"de\", \"de\", \"de\", \"de\", \"de\", \"de\", \"…\n$ paragraphs     &lt;chr&gt; \"[\\\"Bundeskanzlerin Angela Merkel hat in den ersten sec…\n$ text           &lt;chr&gt; \"Bundeskanzlerin Angela Merkel hat in den ersten sechs …\n$ word_count     &lt;dbl&gt; 569, 406, 658, 264, 601, 399, 262, 516, 801, 433, 567, …\n$ image_urls     &lt;chr&gt; \"[\\\"https://images.tagesschau.de/image/47dedcab-ee73-4e…\n$ image_captions &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ related_links  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ source_file    &lt;chr&gt; \"2006-01-05-articles.jsonl\", \"2006-01-13-articles.jsonl…",
    "crumbs": [
      "Projekt 2: News",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Übersicht der Variablen</span>"
    ]
  },
  {
    "objectID": "project-2-news/variables.html#fehlende-werte",
    "href": "project-2-news/variables.html#fehlende-werte",
    "title": "\n25  Variablen\n",
    "section": "\n25.2 Fehlende Werte",
    "text": "25.2 Fehlende Werte\nFehlende Werte (missing values) sind in realen Datensätzen völlig normal: Manche Informationen sind für einen Beitrag nicht vorhanden (z.B. kein:e Autor:in), wurden beim Scraping nicht gefunden oder sind nur für bestimmte Ressorts sinnvoll.\nEin erster, sehr nützlicher Schritt ist ein „Missingness-Profil“: Welche Spalten haben überhaupt fehlende Werte – und wie viele?\n\nts |&gt;\n  summarise(\n    across(\n      everything(),\n      list(n_missing = ~ sum(is.na(.x)), pct_missing = ~ mean(is.na(.x))),\n      .names = \"{.col}__{.fn}\"\n    )\n  ) |&gt;\n  pivot_longer(everything(), names_to = \"metric\", values_to = \"value\") |&gt;\n  separate(metric, into = c(\"variable\", \"metric\"), sep = \"__\") |&gt;\n  pivot_wider(names_from = metric, values_from = value) |&gt;\n  arrange(desc(pct_missing))\n\n# A tibble: 21 × 3\n   variable       n_missing pct_missing\n   &lt;chr&gt;              &lt;dbl&gt;       &lt;dbl&gt;\n 1 image_captions     49446     0.831  \n 2 related_links      42196     0.709  \n 3 tag                32797     0.551  \n 4 author             16625     0.279  \n 5 image_urls          6140     0.103  \n 6 keywords             638     0.0107 \n 7 date_modified        627     0.0105 \n 8 paragraphs           323     0.00543\n 9 text                 323     0.00543\n10 word_count           323     0.00543\n# ℹ 11 more rows\n\n\nDas Ergebnis hilft dir analytisch sofort weiter:\n\nSpalten mit sehr vielen fehlenden Werten eignen sich oft eher als optionale Zusatzinformationen.\nSpalten mit wenigen fehlenden Werten sind meist robuste „Kernvariablen“.\nWenn wichtige Variablen viele NAs enthalten, lohnt sich Ursachenforschung (Erhebung, Scraper, Parsing, Definition der Variable).\n\nWenn du eine kompakte, gut lesbare Gesamtsicht möchtest, ist skimr sehr praktisch (inkl. Missingness, Verteilungen, Beispiele). Damit die Kapitel auch ohne das Paket rendern, ist es hier optional:\n\nif (requireNamespace(\"skimr\", quietly = TRUE)) {\n  skimr::skim(ts)\n} else {\n  cat(\"Optional: install.packages('skimr') für eine kompakte Variable-Übersicht.\\n\")\n}\n\n\nData summary\n\n\nName\nts\n\n\nNumber of rows\n59500\n\n\nNumber of columns\n21\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n18\n\n\nnumeric\n1\n\n\nPOSIXct\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\nsupertitle\n0\n1.00\n3\n67\n0\n46474\n0\n\n\ntitle\n0\n1.00\n3\n146\n0\n58902\n0\n\n\nauthor\n16625\n0.72\n3\n476\n0\n5216\n0\n\n\nressort\n5\n1.00\n2\n37\n0\n38\n0\n\n\nurl\n0\n1.00\n38\n174\n0\n59433\n0\n\n\nthumbnail\n22\n1.00\n67\n320\n0\n41449\n0\n\n\ntag\n32797\n0.45\n2\n76\n0\n375\n0\n\n\nshorttext\n7\n1.00\n10\n717\n0\n59056\n0\n\n\ndescription\n7\n1.00\n10\n807\n0\n59059\n0\n\n\nkeywords\n638\n0.99\n5\n763\n0\n41962\n0\n\n\ncanonical_url\n6\n1.00\n31\n174\n0\n59231\n0\n\n\nlanguage\n1\n1.00\n2\n2\n0\n4\n0\n\n\nparagraphs\n323\n0.99\n22\n84250\n0\n58986\n0\n\n\ntext\n323\n0.99\n18\n84140\n0\n58986\n0\n\n\nimage_urls\n6140\n0.90\n128\n166482\n0\n48806\n0\n\n\nimage_captions\n49446\n0.17\n10\n4379\n0\n9434\n0\n\n\nrelated_links\n42196\n0.29\n42\n27104\n0\n17122\n0\n\n\nsource_file\n0\n1.00\n25\n25\n0\n6351\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\nword_count\n323\n0.99\n540.12\n402.18\n3\n320\n461\n657\n11165\n▇▁▁▁▁\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\ndate_time\n29\n1.00\n2006-01-05 10:50:33\n2025-12-31 20:29:48\n2023-06-05 17:39:28\n59372\n\n\ndate_modified\n627\n0.99\n2007-05-10 14:15:00\n2026-02-09 17:57:43\n2024-11-07 18:20:14\n58867",
    "crumbs": [
      "Projekt 2: News",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Übersicht der Variablen</span>"
    ]
  },
  {
    "objectID": "project-2-news/variables.html#duplikate",
    "href": "project-2-news/variables.html#duplikate",
    "title": "\n25  Variablen\n",
    "section": "\n25.3 Duplikate",
    "text": "25.3 Duplikate\nDuplikate können in News-Daten aus verschiedenen Gründen entstehen: ein Artikel wurde mehrfach gespeichert, die gleiche URL taucht in mehreren Quellfiles auf, oder Inhalte sind sehr ähnlich.\nIn der Praxis definieren wir Duplikate über eine eindeutige ID. Bei Webdaten ist das häufig die url (oder canonical_url). Schauen wir zuerst, ob es URLs gibt, die mehrfach vorkommen:\n\nts |&gt;\n  count(url, sort = TRUE) |&gt;\n  filter(!is.na(url), n &gt; 1)\n\n# A tibble: 11 × 2\n   url                                                                         n\n   &lt;chr&gt;                                                                   &lt;int&gt;\n 1 https://www.tagesschau.de/multimedia/podcast/11km/11km-feed-100.html       53\n 2 https://www.phoenix.de/livestream.html                                      5\n 3 https://www.tagesschau.de/multimedia/podcasts/podcast-11km-101.html         4\n 4 https://www.tagesschau.de/multimedia/podcast/11km/podcast-11km-2788.ht…     2\n 5 https://www.tagesschau.de/multimedia/podcast/15-minuten/audio-corona-s…     2\n 6 https://www.tagesschau.de/multimedia/podcast/15-minuten/audio-kontroll…     2\n 7 https://www.tagesschau.de/multimedia/podcast/15-minuten/audio-rauchen-…     2\n 8 https://www.tagesschau.de/multimedia/podcast/15-minuten/audio-streit-u…     2\n 9 https://www.tagesschau.de/multimedia/podcast/15-minuten/audio-tabubruc…     2\n10 https://www.tagesschau.de/multimedia/podcast/15-minuten/audio-weltglue…     2\n11 https://www.tagesschau.de/multimedia/podcast/15-minuten/audio-wer-mach…     2\n\n\nWenn du wissen willst, welche Datensätze dahinterstehen, kannst du dir einzelne Fälle anzeigen lassen. Das ist ein typischer Debugging-Schritt in der Datenbereinigung:\n\nts |&gt;\n  add_count(url, name = \"n_url\") |&gt;\n  filter(!is.na(url), n_url &gt; 1) |&gt;\n  select(url, date_time, ressort, title, n_url) |&gt;\n  arrange(desc(n_url), url, date_time)\n\n# A tibble: 78 × 5\n   url                                   date_time           ressort title n_url\n   &lt;chr&gt;                                 &lt;dttm&gt;              &lt;chr&gt;   &lt;chr&gt; &lt;int&gt;\n 1 https://www.tagesschau.de/multimedia… 2023-04-25 11:15:00 multim… 11KM…    53\n 2 https://www.tagesschau.de/multimedia… 2023-05-30 05:46:00 multim… 11KM…    53\n 3 https://www.tagesschau.de/multimedia… 2023-06-28 05:14:00 multim… 11KM…    53\n 4 https://www.tagesschau.de/multimedia… 2023-07-07 07:07:00 multim… 11KM…    53\n 5 https://www.tagesschau.de/multimedia… 2023-09-26 09:14:00 multim… 11KM…    53\n 6 https://www.tagesschau.de/multimedia… 2023-10-19 09:02:00 multim… 11KM…    53\n 7 https://www.tagesschau.de/multimedia… 2023-11-30 08:58:00 multim… 11KM…    53\n 8 https://www.tagesschau.de/multimedia… 2023-12-19 08:22:00 multim… 11KM…    53\n 9 https://www.tagesschau.de/multimedia… 2024-01-31 07:04:00 multim… 11KM…    53\n10 https://www.tagesschau.de/multimedia… 2024-02-28 06:29:00 multim… 11KM…    53\n# ℹ 68 more rows\n\n\nFür viele Analysen (z.B. Zählen, Zeitreihen) willst du Duplikate entfernen, damit Ergebnisse nicht „aufgeblasen“ werden. Wenn url eindeutig sein soll, kannst du eine deduplizierte Version erzeugen:\n\nts_dedup &lt;- ts |&gt;\n  arrange(date_time) |&gt;\n  distinct(url, .keep_all = TRUE)\n\nts |&gt;\n  summarise(n_rows = n()) |&gt;\n  bind_cols(ts_dedup |&gt; summarise(n_rows_dedup = n()))\n\n# A tibble: 1 × 2\n  n_rows n_rows_dedup\n   &lt;int&gt;        &lt;int&gt;\n1  59500        59433\n\n\nWichtig: Welche Zeile du bei Duplikaten behältst (erste/letzte, nach date_modified, nach Datenqualität) ist eine fachliche Entscheidung. arrange() vor distinct() macht diese Entscheidung explizit und reproduzierbar.",
    "crumbs": [
      "Projekt 2: News",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Übersicht der Variablen</span>"
    ]
  },
  {
    "objectID": "project-2-news/variables.html#wertebereiche",
    "href": "project-2-news/variables.html#wertebereiche",
    "title": "\n25  Variablen\n",
    "section": "\n25.4 Wertebereiche",
    "text": "25.4 Wertebereiche\nWertebereiche (ranges) sind ein schneller Plausibilitätscheck. Gerade numerische Variablen enthalten manchmal Ausreißer oder „kaputte“ Werte (z.B. negative Längen, extrem große Zählwerte), die aus Parsing- oder Scraping-Problemen stammen.\nIm Datensatz gibt es z.B. word_count (Wortanzahl) und oft auch paragraphs (Absatzanzahl). Wir schauen uns typische Kennzahlen und Ausreißer an:\n\nts |&gt;\n  summarise(\n    n = n(),\n    word_count_min = min(word_count, na.rm = TRUE),\n    word_count_p25 = quantile(word_count, 0.25, na.rm = TRUE),\n    word_count_median = median(word_count, na.rm = TRUE),\n    word_count_p75 = quantile(word_count, 0.75, na.rm = TRUE),\n    word_count_max = max(word_count, na.rm = TRUE),\n    paragraphs_min = min(paragraphs, na.rm = TRUE),\n    paragraphs_median = median(paragraphs, na.rm = TRUE),\n    paragraphs_max = max(paragraphs, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 9\n      n word_count_min word_count_p25 word_count_median word_count_p75\n  &lt;int&gt;          &lt;dbl&gt;          &lt;dbl&gt;             &lt;dbl&gt;          &lt;dbl&gt;\n1 59500              3            320               461            657\n# ℹ 4 more variables: word_count_max &lt;dbl&gt;, paragraphs_min &lt;chr&gt;,\n#   paragraphs_median &lt;chr&gt;, paragraphs_max &lt;chr&gt;\n\n\nEine Visualisierung macht Verteilungen und Ausreißer noch schneller greifbar. Ein Histogramm zeigt dir, wie „lang“ Tagesschau-Beiträge typischerweise sind:\n\nts |&gt;\n  ggplot(aes(x = word_count)) +\n  geom_histogram(bins = 50, na.rm = TRUE) +\n  theme_bw() +\n  labs(x = \"Wortanzahl\", y = \"Anzahl der Beiträge\")\n\n\n\n\n\n\n\nUnd ein Boxplot nach Ressort ist nützlich, um Unterschiede zwischen Kategorien sichtbar zu machen (z.B. sind Wirtschaftsartikel im Schnitt länger?):\n\nts |&gt;\n  filter(!is.na(ressort), !is.na(word_count)) |&gt;\n  mutate(ressort = fct_lump_n(ressort, n = 10)) |&gt;\n  ggplot(aes(x = ressort, y = word_count)) +\n  geom_boxplot(outlier.alpha = 0.2) +\n  coord_flip() +\n  theme_bw() +\n  labs(x = \"Ressort (Top 10 + Other)\", y = \"Wortanzahl\")\n\n\n\n\n\n\n\nWarum ist das für Data Analytics hilfreich?\n\nDu bekommst ein Gefühl für „typische“ Inhalte (Baseline), bevor du Modelle baust.\nAusreißer-Fälle sind oft inhaltlich spannend (Breaking News) oder Datenprobleme.\nKategorienvergleiche liefern schnell Hypothesen für tiefergehende Analysen (z.B. Trends je Ressort).",
    "crumbs": [
      "Projekt 2: News",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Übersicht der Variablen</span>"
    ]
  },
  {
    "objectID": "project-2-news/time.html",
    "href": "project-2-news/time.html",
    "title": "\n26  Zeit\n",
    "section": "",
    "text": "26.1 Verteilung der Beiträge über die Zeit\nNachrichten haben einen inhärenten zeitlichen Charakter, da sie sich auf aktuelle Ereignisse beziehen. Es ist daher interessant zu sehen, wie die Anzahl der veröffentlichten Nachrichtenbeiträge über die Zeit verteilt ist. Die entsprechende Spalte für den Zeitbezug erkennen wir in der Ausgabe der glimpse()-Funktion oben am Datentyp &lt;dttm&gt;, was für datetime steht. Schauen wir uns ein paar Beispiele an:\nts |&gt;\n  select(date_time)\n\n# A tibble: 59,500 × 1\n   date_time          \n   &lt;dttm&gt;             \n 1 2006-01-05 10:50:33\n 2 2006-01-13 13:47:00\n 3 2006-01-13 10:18:00\n 4 2006-01-14 14:24:00\n 5 2006-01-15 14:44:00\n 6 2006-01-18 19:30:00\n 7 2006-01-25 17:37:00\n 8 2006-02-02 10:52:26\n 9 2006-02-02 08:39:00\n10 2006-02-14 14:20:00\n# ℹ 59,490 more rows\nWir erkennen an der Ausgabe der ersten Zeilen wie genau ein Wert vom datetime-Datentyp aufgebaut ist. Es handelt sich um ein standardisiertes Format mit dem Namen ISO-8601, das einer festen Syntax folgt. Der erste Teil stellt das Datum mit seinen Bestandteilen Jahr, Monat und Tag dar, jeweils als vierstellige (Jahr) und zweistellige (Monat, Tag) Zahlen, getrennt mit einem Bindestrich. Danach folgt, getrennt durch ein Leerzeichen, die Uhrzeitangabe. Hier ist das Format wie gewohnt: HH:MM:ss, also jeweils zwei Ziffern für die Stunde, Minute und Sekunde, jeweils durch einen Doppelpunkt getrennt.\nWeil das Format standardisiert ist, gibt es entsprechende Funktionen, mit denen wir jeden Bestandteil extrahieren wollen. Mit der Funktion year() bekommen wir etwa nur das Jahr als Zahl. Ensprechende Funktionen gibt es auch für andere Datums- und Zeitbestandteile. Details zur Arbeit mit Datum und Zeit findet ihr im Kapitel Dates and times aus Wickham u. a. (2023).\nGleichzeitig können wir ein Datum abrunden - klingt komisch? Dabei schneiden wir einfach den Teil des Zeitstempels ab, der unseren gewünschten Detailgrad überschreitet. Wenn wir etwa eine Analyse auf Monatsbasis erstellen wollen, dann können wir jedes Datum auf den jeweils ersten des Monats runden, im dem sich der Zeitstempel befindet:\nts |&gt;\n  mutate(date_month = floor_date(date_time, unit = \"month\"), .keep = \"used\")\n\n# A tibble: 59,500 × 2\n   date_time           date_month         \n   &lt;dttm&gt;              &lt;dttm&gt;             \n 1 2006-01-05 10:50:33 2006-01-01 00:00:00\n 2 2006-01-13 13:47:00 2006-01-01 00:00:00\n 3 2006-01-13 10:18:00 2006-01-01 00:00:00\n 4 2006-01-14 14:24:00 2006-01-01 00:00:00\n 5 2006-01-15 14:44:00 2006-01-01 00:00:00\n 6 2006-01-18 19:30:00 2006-01-01 00:00:00\n 7 2006-01-25 17:37:00 2006-01-01 00:00:00\n 8 2006-02-02 10:52:26 2006-02-01 00:00:00\n 9 2006-02-02 08:39:00 2006-02-01 00:00:00\n10 2006-02-14 14:20:00 2006-02-01 00:00:00\n# ℹ 59,490 more rows\nIn der Ausgabe seht ihr links das Originaldatum mit allen Details und rechts das abgeschnittene und auf den ersten des jeweiligen Monats gerundete Datum. Das Schöne an floor_date() ist, dass es als Ergebnis einen Wert vom gleichen Datentyp erzeugt, also auch ein datetime. Warum ist das gut? Weil wir damit in der Visualisieurung gut klarkommen, wie ihr im nächsten Schritt sehen werdet:\nts |&gt;\n  mutate(date_month = floor_date(date_time, \"month\")) |&gt;\n  ggplot() +\n  aes(x = date_month) +\n  geom_bar() +\n  theme_bw() +\n  labs(x = \"Monat\", y = \"Anzahl der Beiträge\")\nSchaut mal auf die x-Achse. Fällt euch was auf?",
    "crumbs": [
      "Projekt 2: News",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Zeit</span>"
    ]
  },
  {
    "objectID": "project-2-news/time.html#verteilung-der-beiträge-über-die-zeit",
    "href": "project-2-news/time.html#verteilung-der-beiträge-über-die-zeit",
    "title": "\n26  Zeit\n",
    "section": "",
    "text": "Wickham, Hadley, Mine Çetinkaya-Rundel, und Garrett Grolemund. 2023. R for data science: import, tidy, transform, visualize, and model data. 2nd edition. O’Reilly Media, Inc.",
    "crumbs": [
      "Projekt 2: News",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Zeit</span>"
    ]
  },
  {
    "objectID": "appendix/appendix-a-scraping.html",
    "href": "appendix/appendix-a-scraping.html",
    "title": "Anhang A: Scraping",
    "section": "",
    "text": "In diesem Anhang findest du eine detaillierte Beschreibung der Python-Skripte, die für die Erstellung des Datensatzes aus Tagesschau-Beiträge verwendet wurden. Diese Skripte wurden entwickelt, um die Nachrichtenbeiträge von Tagesschau.de zu sammeln und in einem strukturierten Format zu speichern.",
    "crumbs": [
      "Anhang A: Scraping"
    ]
  },
  {
    "objectID": "appendix/appendix-b-supplemental.html",
    "href": "appendix/appendix-b-supplemental.html",
    "title": "Anhang A: Material",
    "section": "",
    "text": "Slides",
    "crumbs": [
      "Anhang A: Material"
    ]
  },
  {
    "objectID": "appendix/appendix-b-supplemental.html#slides",
    "href": "appendix/appendix-b-supplemental.html#slides",
    "title": "Anhang A: Material",
    "section": "",
    "text": "Projekt 1: Umfragen\n\nUmfragedaten\n\n\n\nGrundlagen\n\nDer Pipe-Operator",
    "crumbs": [
      "Anhang A: Material"
    ]
  },
  {
    "objectID": "appendix/appendix-b-supplemental.html#online",
    "href": "appendix/appendix-b-supplemental.html#online",
    "title": "Anhang A: Material",
    "section": "Online",
    "text": "Online\n\nPosit Cheatsheets",
    "crumbs": [
      "Anhang A: Material"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Quellen",
    "section": "",
    "text": "Grolemund, Garrett. 2014. Hands-on Programming with\nR. First edition. O’Reilly.\n\n\nHewitt, Stephen M. 2019. “Data, Information, and\nKnowledge.” Journal of Histochemistry &\nCytochemistry 67 (4): 227–28. https://doi.org/10.1369/0022155419836995.\n\n\nHuntington-Klein, Nick. 2026. The Effect: An Introduction to\nResearch Design and Causality. Second edition. A\nChapman & Hall Book. CRC\nPress.\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023.\nR for Data Science: Import, Tidy, Transform, Visualize, and Model\nData. 2nd edition. O’Reilly Media, Inc.\n\n\nWilke, C. 2019. Fundamentals of Data Visualization: A Primer on\nMaking Informative and Compelling Figures. First edition. O’Reilly\nMedia.",
    "crumbs": [
      "Quellen"
    ]
  }
]